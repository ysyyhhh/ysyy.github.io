[{"content":"记把深度学习项目装入docker 安装时出现选项\n1 2 3 # RUN apt-get install libglib2.0-dev -y # 由于安装libglib2.0-dev的时候，bash会有交互操作叫你选择对应的时区，在docker build的时候没有交互的，所以需要加上DEBIAN_FRONTEND=\u0026#34;noninteractive\u0026#34; RUN DEBIAN_FRONTEND=\u0026#34;noninteractive\u0026#34; apt -y install libglib2.0-dev docker清理 在win10下，docker是基于wsl2的，所以docker的镜像和容器都是在wsl2的文件系统中。 所以在清理完docker的镜像和容器后，需要对wsl的盘进行压缩。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 停止所有的容器 docker stop $(docker ps -aq) # 删除所有未使用的容器 docker volume prune # 删除所有未使用的镜像 docker image prune -a # 删除缓存 docker builder prune # 查看当前占用的空间 docker system df 对wsl2的盘进行压缩\n1 2 3 4 5 6 7 8 9 10 11 12 13 wsl --shutdown # 查看wsl2的盘 wsl --list -v # 使用diskpart压缩 diskpart # open window Diskpart select vdisk file=\u0026#34;D:\\ubuntu\\wsl\\docker-desktop-data\\ext4.vhdx\u0026#34; attach vdisk readonly compact vdisk detach vdisk exit docker中安装conda 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 安装conda RUN apt-get install -y wget # yhyu13 : donwload anaconda package \u0026amp; install RUN wget \u0026#34;https://repo.anaconda.com/archive/Anaconda3-2023.03-1-Linux-x86_64.sh\u0026#34; RUN sh Anaconda3-2023.03-1-Linux-x86_64.sh -b -p /opt/conda # RUN rm /anaconda.sh RUN ln -s /opt/conda/etc/profile.d/conda.sh /etc/profile.d/conda.sh RUN echo \u0026#34;. /opt/conda/etc/profile.d/conda.sh\u0026#34; \u0026gt;\u0026gt; ~/.bashrc # yhyu13 : add conda to path ENV PATH /opt/conda/bin:/opt/conda/condabin:$PATH docker-compose 使用gpu 1 2 3 4 5 6 7 8 9 10 11 12 13 14 version: \u0026#39;3.7\u0026#39; services: pytorch: build: . runtime: nvidia environment: - NVIDIA_VISIBLE_DEVICES=all - NVIDIA_DRIVER_CAPABILITIES=all volumes: - .:/workspace ports: - \u0026#34;8888:8888\u0026#34; - \u0026#34;6006:6006\u0026#34; command: bash -c \u0026#34;jupyter notebook --ip wsl 盘迁移到非系统盘 一般情况下 wsl盘的位置在 C:\\Users\\\u0026lt;用户名\u0026gt;\\AppData\\Local\\Docker\\wsl\ndocker的盘在 C:\\Users\\\u0026lt;用户名\u0026gt;\\AppData\\Local\\Docker\\wsl\\data\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 1. 停止wsl wsl --shutdown # 2. 查看wsl状态 wsl --list -v # 可以看到docker有两个wsl，一个是docker-desktop-data，一个是docker-desktop # 只需要迁移docker-desktop-data即可,另一个很小 # 3. 迁移wsl wsl --export Ubuntu-20.04 D:\\ubuntu\\wsl\\Ubuntu-20.04.tar # 4. 删除wsl wsl --unregister Ubuntu-20.04 # 5. 查看是否删除成功 wsl --list -v # 6. 导入wsl wsl --import Ubuntu-20.04 D:\\ubuntu\\wsl\\Ubuntu-20.04 D:\\ubuntu\\wsl\\Ubuntu-20.04.tar --version 2 # 7. 查看是否导入成功 wsl --list -v ","permalink":"/en/posts/tips/docker/","summary":"记把深度学习项目装入docker 安装时出现选项 1 2 3 # RUN apt-get install libglib2.0-dev -y # 由于安装libglib2.0-dev的时候，bash会有交互操作叫你选择对","title":"docker相关技巧"},{"content":"本规范用于在开发过程中，使得项目能够更好的部署，更好的维护。\n使用时间: 当项目开始开发时，就应该遵守本规范。\n核心要点:\n管理依赖库 使用docker 端口、ip地址等使用环境变量 路径不能写死！尤其是绝对路径和根目录等，需要放在环境变量中！！ 后端 python项目 python常见的依赖库管理有:\npoetry requirements.txt pipenv poetry 初始化\n1 poetry init 安装依赖\n1 poetry install 使用poetry运行项目\n1 poetry run python main.py 添加依赖\n1 poetry add \u0026lt;package\u0026gt; dockerfile示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 FROM python:3.8.5-slim-buster WORKDIR /app # 拷贝依赖文件 COPY pyproject.toml poetry.lock ./ # 设置国内源 RUN pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple # 安装poetry RUN pip install poetry # 安装依赖 RUN poetry config virtualenvs.create false \\ \u0026amp;\u0026amp; poetry install --no-dev --no-interaction --no-ansi # tips: 先只拷贝依赖文件，再安装依赖，可以利用docker的缓存机制，加快构建速度. # (防止只是项目文件改变，而依赖文件没有改变，导致重新安装依赖) # 拷贝项目文件 COPY . . # 运行项目 CMD [\u0026#34;poetry\u0026#34;, \u0026#34;run\u0026#34;, \u0026#34;python\u0026#34;, \u0026#34;main.py\u0026#34;] requirements.txt 导出依赖\n1 pip freeze \u0026gt; requirements.txt 安装依赖\n1 pip install -r requirements.txt dockerfile示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 FROM python:3.8.5-slim-buster WORKDIR /app # 拷贝依赖文件 COPY requirements.txt ./ # 设置国内源 RUN pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple # 安装依赖 RUN pip install -r requirements.txt # 拷贝项目文件 COPY . . # 运行项目 CMD [\u0026#34;python\u0026#34;, \u0026#34;main.py\u0026#34;] pipenv 初始化\n1 pipenv --python 3.8 安装依赖\n1 pipenv install 使用pipenv运行项目\n1 pipenv run python main.py 添加依赖\n1 pipenv install \u0026lt;package\u0026gt; dockerfile示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 FROM python:3.8.5-slim-buster WORKDIR /app # 设置国内源 RUN pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple # 拷贝依赖文件 COPY Pipfile Pipfile.lock ./ # 安装依赖 RUN pip install pipenv \\ \u0026amp;\u0026amp; pipenv install --system --deploy --ignore-pipfile # 拷贝项目文件 COPY . . # 运行项目 CMD [\u0026#34;pipenv\u0026#34;, \u0026#34;run\u0026#34;, \u0026#34;python\u0026#34;, \u0026#34;main.py\u0026#34;] SpringBoot项目 参考 这里都以maven作为依赖管理工具。\n主要保留pom.xml文件\ndockerfile示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 第一阶段: 构建jar包 FROM maven:3.6.3-jdk-8-slim AS build WORKDIR /app COPY pom.xml ./ # 设置国内源 RUN mvn -B -e -C -T 1C org.apache.maven.plugins:maven-dependency-plugin:3.1.2:go-offline # 拷贝项目文件 COPY . . # 构建jar包 RUN mvn clean install -DskipTests # 第二阶段: 运行jar包 FROM openjdk:8-jdk-alpine WORKDIR /app # 拷贝第一阶段构建的jar包 COPY --from=build /app/target/demo-0.0.1-SNAPSHOT.jar ./ # 运行项目 CMD [\u0026#34;java\u0026#34;, \u0026#34;-jar\u0026#34;, \u0026#34;target/demo-0.0.1-SNAPSHOT.jar\u0026#34;] 数据库 通常后端要连接数据库，这里只是简单的示例，实际项目中应该使用docker-compose来管理多个容器。\ndockerfile示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 FROM mysql:8.0.22 # 设置时区 ENV TZ=Asia/Shanghai # 设置root密码 ENV MYSQL_ROOT_PASSWORD=123456 # 设置数据库名 ENV MYSQL_DATABASE=test # 设置用户名 ENV MYSQL_USER=test # 设置密码 ENV MYSQL_PASSWORD=123456 # 设置端口 EXPOSE 3306 单独运行mysql\n1 docker run -d -p 3306:3306 --name mysql -v /path/to/mysql/data:/var/lib/mysql mysql:8.0.22 前端 前端使用npm作为依赖管理工具, 使用nginx作为web服务器。\n必要的文件:\npackage.json # 依赖文件 package-lock.json # 锁定依赖版本 nginx.conf # nginx配置文件 dockerfile npm npm初始化\n1 npm init 安装依赖\n1 npm install 添加依赖(默认添加到dependencies, 添加到devDependencies需要加上\u0026ndash;save-dev参数(或者-D)\n1 npm install \u0026lt;package\u0026gt; nginx nginx.conf示例\n1 2 3 4 5 6 7 8 9 server { listen 80; server_name localhost; root /usr/share/nginx/html; index index.html index.htm; location / { try_files $uri $uri/ /index.html; } } docker docker 使用多阶段构建\ndockerfile示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 第一阶段: 构建项目 FROM node:lts-alpine as build WORKDIR /app # 拷贝依赖文件 COPY package.json package-lock.json ./ # 安装依赖 RUN npm install # 拷贝项目文件 COPY . . # 构建项目 RUN npm run build # 第一段构建完成, 获得/app/build文件夹 # 使用nginx作为web服务器 FROM nginx:1.19.4-alpine # 拷贝nginx配置文件 COPY nginx.conf /etc/nginx/conf.d/default.conf # 拷贝第一阶段构建的项目文件 COPY --from=build /app/build /usr/share/nginx/html # 运行nginx CMD [\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;] 项目部署 TODO 封装整个项目(单个项目时) 经过上面的步骤已经将前后端 数据库封装到docker中了,但每次启动项目都需要手动启动三个容器, 这里使用docker-compose来管理多个容器。\ndocker-compose.yml示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 version: \u0026#39;3.8\u0026#39; services: mysql: image: mysql:8.0.22 environment: TZ: Asia/Shanghai MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: test MYSQL_USER: test MYSQL_PASSWORD: 123456 ports: - 3306:3306 volumes: - ./mysql/data:/var/lib/mysql backend: build: ./backend ports: - 8080:8080 depends_on: - mysql frontend: build: ./frontend ports: - 80:80 depends_on: - backend 整个项目作为k8s的一个服务(多个项目时) 上面是使用docker-compose来管理 一个项目的多个容器.\n但如果有多个项目, 每个项目都有多个容器, 这时候就需要使用k8s来管理了.\n我们把一个项目(多个容器)作为一个k8s的一个服务.\nk8s的配置文件示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 apiVersion: v1 kind: Service metadata: name: test labels: app: test spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: app: test type: NodePort --- apiVersion: apps/v1 kind: Deployment metadata: name: test labels: app: test spec: replicas: 1 selector: matchLabels: app: test template: metadata: labels: app: test spec: containers: - name: mysql image: mysql:8.0.22 env: - name: TZ value: Asia/Shanghai - name: MYSQL_ROOT_PASSWORD value: 123456 - name: MYSQL_DATABASE value: test - name: MYSQL_USER value: test - name: MYSQL_PASSWORD value: 123456 ports: - containerPort: 3306 volumeMounts: - name: mysql-data mountPath: /var/lib/mysql - name: backend image: backend:latest ports: - containerPort: 8080 env: - name: MYSQL_HOST value: mysql - name: MYSQL_PORT value: \u0026#34;3306\u0026#34; - name: MYSQL_DATABASE value: test - name: MYSQL_USER value: test - name: MYSQL_PASSWORD value: 123456 - name: frontend image: frontend:latest ports: - containerPort: 80 volumes: - name: mysql-data hostPath: path: /path/to/mysql/data ","permalink":"/en/posts/reference/%E5%88%A9%E4%BA%8E%E9%83%A8%E7%BD%B2%E7%9A%84%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/","summary":"本规范用于在开发过程中，使得项目能够更好的部署，更好的维护。 使用时间: 当项目开始开发时，就应该遵守本规范。 核心要点: 管理依赖库 使用docke","title":"利于部署的开发规范手册"},{"content":"GPU\n图形渲染 图像中的每个对象都有很自然的并行性。\n","permalink":"/en/posts/cmu-15418cs-618/l7/","summary":"GPU 图形渲染 图像中的每个对象都有很自然的并行性。","title":"L7"},{"content":"grep工具\n","permalink":"/en/posts/tools/grep/","summary":"grep工具","title":"grep"},{"content":"虚拟文件系统\n/proc/cpuinfo\nmodel name cpu MHz - 频率 cache size - 缓存大小 siblings - 逻辑cpu数量 processor - 逻辑cpu编号 cpu cores - 物理cpu数量 core id - 物理cpu编号 这样查看的cpu数量很多\nsiblings是逻辑cpu的数量\ncpu cores是物理cpu的数量\n为什么报告的processor数量是40而siblings是20呢? 因为报告的processor包括超线程的逻辑cpu. 这样操作系统就可以直接根据逻辑cpu的数量来分配任务.\nMemory bandwidth - 内存带宽 Power consumption - 功耗 能源消耗实际上是一个很大的问题. Intel code name - 代号 Functional units\nlatency - 延迟 issue time - 发射时间 capacity - 容量 微处理架构\nfunction units latency - 延迟，执行一个指令所需要的时钟周期数(不包括等待) issue time - 发射时间，指令发射到执行所需要的时钟周期数(包括等待) capacity - 容量 优化的地方:\n搞清楚到底哪些代码是执行次数最多的(内部循环)(对实际使用情况来说) 基本运算消耗时间: 除法 \u0026gt; 乘法 \u0026gt; 加法 \u0026gt; 位移 基本的程序: 合并重复计算的简单的提升: 将除法次数减少,(不依赖于内层循环的变量的计算拿出来)\n循环展开 loop unrolling\n如果每一次循环都要进行一次是否终止的测试,开销会很大.(尤其是一次循环的计算 相比于 循环次数来说很小 时)\n所以处理器从简单的策略开始,如预测循环的次数. 大部分都是基于统计预测的.\n如果可以预测循环的次数,就可以将循环展开. 每次循环多执行4 或 8 或\u0026hellip;次原来循环做的事情.\n但展开时不一定均匀,\nuniform可以使得循环展开的更好.\n为什么8维向量获得了超过8倍的加速呢? 因为uniform, 原本要做8次的判断,现在只需要做一次.\n常规优化提升了15倍 向量优化提升了5.4倍 总计提升了82倍\n向量化很好且是free的,但不能忽略了传统的优化\n传统的优化(213 program)使得速度提升了三倍\n要做到极致的优化,就比如要花3个星期的时间在编码风格上, 最后30分钟花在向量化上.\n但要看情况来决定编码风格的优化. 因为如果我们编写的代码不是执行次数最多(如内核,场景仿真,高频), 那么可能更需要的是可读性.\n可读性变差 可能会导致bug很容易被引入, 并且非常不容易被发现和维护.\n","permalink":"/en/posts/cmu-15418cs-618/l6/","summary":"虚拟文件系统 /proc/cpuinfo model name cpu MHz - 频率 cache size - 缓存大小 siblings - 逻辑cpu数量 processor - 逻辑cpu编号 cpu cores - 物理cpu数量 core id - 物理cpu编号 这样查看的cpu数量很","title":"L6"},{"content":"光标移动 h: 左移一个字符 j: 下移一行 k: 上移一行 l: 右移一个字符\nw: 移动到下一个单词的开头 e: 移动到当前单词末尾 b: 移动到上一个单词的开头\n0: 移动到行首 $: 移动到行尾\nn + 上面的命令: 移动n次\ngg: 移动到文件开头 G: 移动到文件末尾\n上面所有命令构成了一个移动命令，可以和d命令组合使用，删除从当前光标到移动命令所指的位置的内容\nctrl + f: 下翻一页 ctrl + b: 上翻一页 ctrl + G: 显示当前光标所在行的行号\nctrl + i: 跳转到上次位置· ctrl + o: 跳转到下次位置\nG + n: 移动到第n行\n插入 i: 在当前光标处插入 I: 在当前行首插入\na: 在当前光标后插入 A: 在当前行尾插入\no: 在当前行下方插入一行 O: 在当前行上方插入一行\n删除 x: 删除当前光标所在的字符 X: 删除当前光标所在的前一个字符\ndd: 删除当前行 D: 删除当前光标所在位置到行尾的内容\nd + 移动命令: 删除从当前光标到移动命令所指的位置的内容\n如: dw: 删除当前光标所在的单词 db: 删除当前光标所在的单词 d$: 删除当前光标所在位置到行尾的内容 dnG: 删除当前光标所在行到第n行的内容 dG: 删除当前光标所在行到文件末尾的内容\n剪切 上面删除的内容都会被保存到剪切板中\n删除并进入插入模式 s: 删除当前光标所在的字符并进入插入模式 S: 删除当前行并进入插入模式\nc + 移动命令: 删除从当前光标到移动命令所指的位置的内容并进入插入模式\n如: cw: 删除当前光标所在的单词并进入插入模式 c$: 删除当前光标所在位置到行尾的内容并进入插入模式 cnG: 删除当前光标所在行到第n行的内容并进入插入模式\n复制 y + 移动命令: 复制从当前光标到移动命令所指的位置的内容\n如: yw: 复制当前光标所在的单词 yb: 复制当前光标所在的单词 y$: 复制当前光标所在位置到行尾的内容 ynG: 复制当前光标所在行到第n行的内容\n粘贴 所有删除的内容都会被保存到剪切板中，可以使用p命令将剪切板中的内容粘贴到当前光标所在位置 p: 将剪切板中的内容粘贴到当前光标所在位置的后面 P: 将剪切板中的内容粘贴到当前光标所在位置的前面\n替换 r + 字符: 将当前光标所在的字符替换为指定的字符\nR + 字符串: 将当前光标所在位置开始的字符串替换为指定的字符串\n撤销 u: 撤销上一次操作 U: 撤销当前行的所有操作\nctrl + r: 恢复上一次撤销的操作\n重复 . : 重复上一次操作\n查找 / + 关键字: 从当前光标开始向下查找关键字 ? + 关键字: 从当前光标开始向上查找关键字\n输完后按回车，会跳转到第一个匹配的位置.\nn: 跳转到下一个匹配的位置 N: 跳转到上一个匹配的位置\n: 进阶命令 :w 保存文件 :q 退出 :q! 强制退出，不保存 :wq 保存并退出 :wq! 强制保存并退出\n上面的命令 + 文件名: 保存文件到指定的文件名\n:help 命令名: 查看命令的帮助文档\n替换 :%s/old/new/g 将所有的old替换为new :%s/old/new/gc 将所有的old替换为new，替换前询问是否替换\n:#,#s/old/new/g 将第#行到第#行的old替换为new\n外部命令 :! + 命令: 执行外部命令\n如: :!ls 执行ls命令 :!dir 执行dir命令\n","permalink":"/en/posts/tools/vim/%E6%8C%87%E4%BB%A4%E6%89%8B%E5%86%8C/","summary":"光标移动 h: 左移一个字符 j: 下移一行 k: 上移一行 l: 右移一个字符 w: 移动到下一个单词的开头 e: 移动到当前单词末尾 b: 移动到上一个单词的开头 0: 移动到行首 $: 移","title":"vim的使用"},{"content":"三种分配策略的总结 静态分配 优点:\n几乎没有运行时的开销(关于分配) 缺点:\n不总是均匀的分配任务 什么时候使用:\n(最简单的例子) 当知道每个任务的工作量相当的时候 当每个任务的工作量是可预测的,但不一定相等的时候 半静态分配\n场景: 当工作量会随时间发生改变,当变化比较慢时.(任务量不可预测) 做法: 定期的重新分配任务 动态分配 场景: 当每个任务的工作量或者任务的数量是不可预测的时候\n每个计算单元都要去获取任务\n但这样的实现, 每次的任务可能会很少, 会使得更多的开销在争夺锁(获取任务的锁)上面.\n有一个办法是一次性计算更多的任务.\n但分配更多的任务可能会导致负载不平衡.\n因此需要在分配任务数量上要找一个平衡, 不花费过多的时间在争夺锁上, 也不会导致负载不平衡.\nSchedule long tasks first 但如果有一个大任务在最后，将出现如下情况： 因此，如果知道有一个大任务，可以提前处理，而不是放到最后一个.\nWork stealing 当一个计算单元没有任务的时候, 从其他计算单元那里偷取任务.\n实现的一些问题:\n1.从哪个线程开始偷取任务呢? 有随机的, 也有从最后一个开始偷取的.\n2.应该偷取多少任务呢? 应该偷取尽可能多一些,这样可以减少偷取任务的次数.\n3.怎样检测一个计算单元是否有任务呢? 可能会循环遍历,\n4.使用本地队列(分布式队列)会更快(在有互斥锁的情况下)\n还有一种方式是使用特殊的数据结构来存储任务间的依赖关系, 从而可以在任务完成的时候, 自动的调度下一个任务. 缺点是额外开销 常见的并行编程模式 循环 创建显示线程 递归时的并行\n递归可以编写出简单的代码, 但是递归的并行化是比较困难的.\n因为递归的并行化需要在递归的每一层都要进行并行化, 并且需要在每一层都要进行同步.\n但只要有独立的子问题, 就可以创造很多潜在的并行性.\nFork-Join pattern cilk_spawn: 会创建一个新的线程, 并且在新的线程中执行函数, 并且不会阻塞当前的线程.\ncilk_sync: 会等待所有的子线程执行完毕, 并且会阻塞当前的线程.\n每个函数的结尾隐式的调用了cilk_sync.\nexample: 有一个主线程+fork的线程. 快排的例子: 在规模较小的时候, 使用串行的快排. 这样可以减少线程的创建和销毁的开销. 不要忽略了抽象和实现的区别. spawn不是生成一个具体的线程, 而是声明这里有一个可以并行的任务.\n任务的数量至少需要比硬件线程多,但也不能大于100倍. 8倍是一个比较好的选择. Cilk的实现 假设我们要去实现clik_spawn 和 cilk_sync 线程池的实现(CILB):\nthread1 需要找到一种方法来发现有新的任务可以执行. 所以thread 0不能简单的调用foo, 它的作用是执行foo.\n但需要在执行foo前,把特殊的东西放入工作队列中.\n此时如果另一个线程突然变得空闲, 它就可以从工作队列中获取任务.\n为什么不把foo放入队列, 直接执行bar呢?(上面是执行foo bar放入队列)\n这涉及到 continuation first(child stealing) 和 child first(continuation stealing) 的问题.\ncontinuation first会导致线程0的大量工作排队.(广度优先队列) child first会导致其他线程把下一个任务偷走时, 会导致线程0的工作队列为空.(深度优先队列)\n实际上child first是合理的.(在递归中是最合适的)\n在递归程序中,会先将所有深度的任务放入队列中.\n按照之前优先执行大任务的策略, 其他线程会优先从队列顶部(先入的)中偷取任务. 因为在分而治之的算法中, 大任务会被分解成小任务, 因此大任务会先被放入队列中.\n实际中使用了双端队列:\n从队列头部获取任务 从队列尾部放入任务 但之前有一个问题: 很多队列,该从哪个队列中获取任务呢? 也许是随机的. 偷取任务的时候, 不随机的更可能会引起负载不均衡.\n本地线程访问的是本地队列的尾部, 偷取时也是放入尾部.(偷其他队列的头部) 这样也有利于空间局部性.\n那么如何实现同步呢?\nExample1: stalling join policy 拖延政策: 所有我创建的任务都必须完成后, 我才能继续执行. Example2: greedy join policy(cilk的实现方法)\n有一个跟踪数据结构,但那个东西可以四处移动.\n最后一个完成的线程会偷走这个数据结构\n所以一旦最后一个任务完成, 就可以继续执行了.\n这样不会浪费时间等待同步.\n第一个方法实现起来更简单,但速度更慢. 因为它总是首线程只等待其他线程完成.\n总结 ","permalink":"/en/posts/cmu-15418cs-618/l5/","summary":"三种分配策略的总结 静态分配 优点: 几乎没有运行时的开销(关于分配) 缺点: 不总是均匀的分配任务 什么时候使用: (最简单的例子) 当知道每个任务的工作","title":"L5 Work distribution and scheduling"},{"content":"主要用三种方式实现并行程序(没有进行真正的优化)\n例子 n-body simulation\n创建并行程序的过程\n1. Decomposition 主要思想: 创造至少足够的任务让所有的处理单元都有事情做\nAmdahl\u0026rsquo;s Law: 串行部分的比例越大, 并行程序的加速比就越小,因为增加处理单元的数量并不能减少串行部分的时间\n分解的任务更多是程序员的工作, 编译器还无法很好的帮助我们\n2.Assignment 需要考虑让每个处理单元尽可能减少沟通.\n有一种方法是随机分配,但会最大化沟通 还有一个极端是全部由一个处理单元完成,但是这样就没有并行了\n这是另一个挑战\n分配可以静态也可以动态发生\n静态: 在程序开始时就确定好. 动态: 在程序运行时分配 静态分配的问题:\n无法适应不同的输入(如:工作量不均匀) 无法适应不同的处理单元数量 动态分配: 通过消息传递来实现, 每个处理单元都有一个队列, 用来存放需要处理的任务(tasks). 当一个处理单元完成了一个任务, 就从队列中取出一个任务来处理 缺点: 队列需要同步, 会有额外的开销\n3. Orchestration 编排阶段 编排的目标是: 减少沟通和同步的成本, preserve locality of data reference, reduce overhead.\n4.mapping 这是程序员最不需要关心的, 交给编译器就好了 example 顺序程序: 那么如何并行执行呢?\nStep1: identify dependencies(problem decomposition) 因为会迭代很多次,所以会引起不同迭代次数的数据竞争.\n有一种划分方法是沿着对角线: 不足之处是:\n有些对角线很短, 负载不均衡 需要额外的计算(对角线下标) 另一种方法是滚动数组: 用两个数组, 一个用来存放当前迭代的结果, 一个用来存放上一次迭代的结果\n这样计算时不会有数据竞争.\n但很多人不希望有额外的内存开销.\n事实上使用的是红黑排序.\n每次迭代只更新红色的部分, 然后再翻转. 这样就不需要复制数组了.\nStep2: assign tasks 我们不把每一个元素作为一个任务,而是把每一行作为一个任务.\n同时: 红黑排序有一个同步的步骤: 必须等待所有的红色部分都计算完毕, 才能开始计算黑色部分.\n为了最小化沟通, 相邻行作为捆包是更好的选择, 这样只在更新边界时需要沟通.\n三种实现方法 Data-parallel expression of solver 这个的特点是系统做了很多工作, 程序只需要指定哪里需要并行.\nshared-address-space code version1 : 但是有个锁会使得程序变慢 version2: 有三个barrier来保证红黑顺序 为什么是三个呢?\n每一部分都要被分割\n最后一个是为了diff的分割 第一个是为了myDiff的分割 第二个是为了diff的分割\n所以可以使用diff数组\nversion3: barrier的问题: barrier还是有点笨重, 这会强制所有线程到一个起跑线 但如果有更精确的信息, 只需要等待依赖的线程就好了\nmessage-passing code 需要有额外的划分,来存储相邻处理器的数据\n同时,在最后计算diff时,需要等待所有的处理器都计算完毕. 这里选中了一个processor zero来计算diff, 其他的处理器都发送自己的diff给它.\n但沟通时有可能发生死锁. 因为每个处理器都在等待其他处理器的消息, 但是自己的消息又没有发送出去.\n所以需要分奇偶来发送\n","permalink":"/en/posts/cmu-15418cs-618/l4/","summary":"主要用三种方式实现并行程序(没有进行真正的优化) 例子 n-body simulation 创建并行程序的过程 1. Decomposition 主要思想: 创造至少足够的任务让所有的处理单元都有事情做 Amdahl\u0026rsquo;s Law: 串行","title":"L4 Parallel Programing basics"},{"content":"ISPC language SPMD: Single Program Multiple Data 一种花哨的方式来说，就是一种并行编程的范式，它的特点是：在编程时，我们只需要写一个程序，然后在运行时，这个程序会被复制多份，每一份都会被分配到不同的处理器上去执行，这样就实现了并行。\n用ISPC实现sinx\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 export void sinx(uniform int N, uniform int terms,uniform float* x, uniform float* result){ //assume N % programCount == 0 for (uniform int i = 0; i \u0026lt; N;i += programCount){ int idx = i + programIndex; float value = x[idx]; float number = value * value * value; uniform int denom = 6; uniform int sign = -1; for (uniform int j = 0; j \u0026lt; terms; j++){ value += sign * number / denom; number *= value * value; denom *= (2 * j + 3) * (2 * j + 2); sign *= -1; } result[idx] = value; } } 使用C++来调用 调用ISPC的东西是个程序实例的集合, gang.\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026lt;iostream\u0026gt; #include \u0026#34;sinx.ispc.h\u0026#34; int N = 1000000; int terms = 10; float* x = new float[N]; float* result = new float[N]; //init x //execute ispc::sinx(N,terms,x,result); ispc中不需要手动设置programCount,programIndex\nprogramCount: number of simultaneous program instances in the gang (uniform value)\nprogramIndex: id of the current program instance in the gang(a non-uniform value)\nuniform value: 一个值在gang中的所有实例中都是一样的\n如果在ispc中直接使用sinx 并不会更快.\n因为有一些相同的工作会被重复做很多次. 通过分离他们,可以减少重复计算的次数,从而提高效率.\n一个设想的实现方法如下: ISPC是为了更容易编写SIMD代码而设计的, 只需要通过特殊的宏或编译指示就可以使用SIMD指令.\nprogramCount 就是 向量宽度\nSPMD programming abstraction\nISPC compiler generates SIMD implementation\nversion2版本的代码,这是分块进行而不是交错的.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 export void sinx(uniform int N, uniform int terms,uniform float* x, uniform float* result){ uniform int count = N / programCount; int start = programIndex * count; //assume N % programCount == 0 for (uniform int i = 0; i \u0026lt; count;i += 1){ int idx = start + i; float value = x[idx]; float number = value * value * value; uniform int denom = 6; uniform int sign = -1; for (uniform int j = 0; j \u0026lt; terms; j++){ value += sign * number / denom; number *= value * value; denom *= (2 * j + 3) * (2 * j + 2); sign *= -1; } result[idx] = value; } } 交错通常比分块更好,因为分块会导致数据的访问不连续. 当计算量不均匀时,分块会导致一些处理器的负载过重,而另一些处理器的负载过轻.\n并且因为是同时进行的, 交错可以访问邻近的数据,这样可以增加cache的命中率.\n根本原因: 矢量加载指令(寄存器)是一次加载多个数据,如果在很短的时间内,要加载的数据是连续的,那么就可以一次加载多个数据,如果数据是不连续的,那么就需要多次加载,这样就会降低效率. 如果有个聪明的编译器,它可以自动将分块的代码转换为交错的代码,这样就可以兼顾两者的优点.\nforeach就可以实现这个功能,让程序员不需要关心这些细节.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 export void sinx(uniform int N, uniform int terms,uniform float* x, uniform float* result){ foreach(i = 0 ... N){ float value = x[i]; float number = value * value * value; uniform int denom = 6; uniform int sign = -1; for (uniform int j = 0; j \u0026lt; terms; j++){ value += sign * number / denom; number *= value * value; denom *= (2 * j + 3) * (2 * j + 2); sign *= -1; } result[i] = value; } } ISPC的错误例子:\n1 2 3 4 5 6 7 export uniform float sumall(uniform int N, uniform float* x){ uniform float sum = 0; foreach(i = 0 ... N){ sum += x[i]; } return sum; } 错误:编译器会报错,因为sum是一个uniform value,它在所有的实例中都是一样的,但是在foreach中,每个实例都会对sum进行修改,这样就会导致错误.\n修正这个错误:\n1 2 3 4 5 6 7 8 9 export uniform float sumall(uniform int N, uniform float* x){ uniform float sum = 0; float partial_sum = 0; foreach(i = 0 ... N){ partial_sum += x[i]; } sum = reduce_add(partial_sum); return sum; } reduce_add原语: 允许将一组不同的值合并为一个值,这个值在所有的实例中都是一样的.\n编译后的细节 ISPC tasks: 基本上就是一个线程,但是它可以被分配到不同的处理器上去执行.\n三种并行编程范式 和 三种 machine architecture 聚焦于 communication 和 cooperation\n使用pthread时要call operate system 而在ISPC中,只需要call compiler\nThree models of communication(abstraction) 1.Shared address space asst3中会用到\n多个线程之间通过互斥锁来进行通信\n在硬件中, Dance-hall model 所有处理器在同一侧.\nSymmetric Multiprocessor(SMP) system 就是如此\n最简单的方式是总线, 但这样无法扩展,因为总线的带宽是有限的. 但实际中: 还有一种访问本地内存的方式,就是通过cache,这样就可以减少对总线的访问,从而提高效率. Non-Uniform Memory Access(NUMA) system 但它为程序员引入的复杂性是很大的,因为程序员需要手动的将数据放到本地内存中,这样才能提高效率.\nshared address space的优点:\n程序员不需要关心数据的传输 程序员不需要关心数据的分布 2.Message passing aasst4中会用到\n由于实现缓存一致性需要额外的成本，因此在大型系统中，共享内存的实现是不可行的。在这种情况下，消息传递是一种更好的选择。\n在消息传递中，每个处理器都有自己的私有内存，而且没有共享内存。要在处理器之间传递数据，必须使用显式的消息传递原语。\n不需要任何硬件支持，因此可以在任何系统上实现。只需要网络。\n可以构建大型系统，因为没有共享内存的限制。\n这些原语允许程序员在处理器之间传递数据，但是程序员必须显式地指定数据的传输。这种方式的缺点是，程序员需要关心数据的传输，这样就会增加程序员的负担。\n3.Data parallel asst2中会用到\n上面两种方式可以在任何硬件上实现。\nData parallel对程序员来说是最简单的，因为程序员不需要关心数据的传输，也不需要关心数据的分布。但是，它只能在特定的硬件上实现，因为它需要硬件支持。\n过去我们使用SIMD，现在使用SPMD。\n并行程序的问题\n这样的并行会得到不确定的结果。\n那么如何有原则性地使用并行呢？\n有一个抽象概念是stream，可以避免并行竞争问题。\n两个函数间的用法：\n当如果使用stream，就必须创建tmp。不得不把临时数据写入浪费的带宽中。\n所以我们希望也许有一些新的运算符可以做更加高级的操作。\ngather: 将数据从不同的stream中收集到一个stream中。 scatter: 将数据从一个stream中分散到不同的stream中。\nintel包括了gather，但不包括scatter。 总结 这些并不是完全独立的，而是可以组合使用的。\n通常在实践中为了得到最好的性能，会使用以上所有的方式。\n多核芯片内部通常是shared address space，但小规模情况下使用message passing。\n","permalink":"/en/posts/cmu-15418cs-618/l3/","summary":"ISPC language SPMD: Single Program Multiple Data 一种花哨的方式来说，就是一种并行编程的范式，它的特点是：在编程时，我们只需要写一个程序，然后在运行时，这个程序会被复制多份，每","title":"Abstraction vs implementation"},{"content":"1. 问题 ","permalink":"/en/posts/cmu-15418cs-618/asst2/","summary":"1. 问题","title":"asst2"},{"content":"使用\n","permalink":"/en/posts/tools/k8s/minikube/","summary":"使用","title":"minikube"},{"content":"markdown 快捷键\n删除线: alt + s\nview Run Run python file in terminal: Ctrl + F5\n","permalink":"/en/posts/tools/vscode%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%85%A8/","summary":"markdown 快捷键 删除线: alt + s view Run Run python file in terminal: Ctrl + F5","title":"工作学习流(vscode快捷键)"},{"content":"多阶段构建docker镜像 多阶段构建的修改不会保留到下一阶段，只有COPY和ADD命令会保留到下一阶段\nusages：\n第一阶段：编译/打包程序依赖 多阶段用途：\n缩小镜像体积 ","permalink":"/en/posts/tools/docker/docker/","summary":"多阶段构建docker镜像 多阶段构建的修改不会保留到下一阶段，只有COPY和ADD命令会保留到下一阶段 usages： 第一阶段：编译/打包程序","title":"docker Usage"},{"content":"1.镜像相关 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 拉取镜像 docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] # 查看镜像 docker images [选项] [仓库名] # 删除镜像 docker rmi [选项] \u0026lt;镜像1\u0026gt; [\u0026lt;镜像2\u0026gt; ...] # 查看镜像历史 docker history [选项] \u0026lt;镜像名\u0026gt; # 查看镜像详细信息 docker inspect [选项] \u0026lt;镜像名\u0026gt; 2.容器相关 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 # 创建容器 docker run [选项] \u0026lt;镜像名\u0026gt; [命令] #eg: docker run -d -p 8080:8080 --name tomcat tomcat:8.5.51 #选项 # -d 后台运行容器，并返回容器ID # -i 以交互模式运行容器，通常与 -t 同时使用 # -t 为容器重新分配一个伪输入终端，通常与 -i 同时使用 # -P 随机端口映射 # -p 指定端口映射，格式为：主机(宿主)端口:容器端口 # --name 指定容器名字 # --link 连接到其它容器 # --rm 容器退出后自动删除容器文件 # --volumes-from 从其它容器或数据卷挂载一些配置或其它文件 # --volume 挂载宿主机目录或文件，格式为：主机目录:容器目录 # --privileged=true 给容器内的root用户赋予最高权限，容器内的root用户就拥有了真正的root权限 # --restart # no 容器退出时不重启 # on-failure[:max-retries] 容器故障退出（返回值非零）时重启，最多重启max-retries次 # always 容器退出时总是重启 # unless-stopped 容器退出时总是重启，但是不考虑在Docker守护进程启动时就已经停止了的容器 # 查看容器 docker ps [选项] # 删除容器 docker rm [选项] \u0026lt;容器名\u0026gt; # 启动容器 # 启动和创建容器的区别在于，启动容器是针对已经创建好的容器进行启动，而创建容器则是针对镜像进行的操作 docker start [选项] \u0026lt;容器名\u0026gt; # 停止容器 docker stop [选项] \u0026lt;容器名\u0026gt; # 查看容器日志 docker logs [选项] \u0026lt;容器名\u0026gt; # 查看容器内进程 docker top [选项] \u0026lt;容器名\u0026gt; # 查看容器详细信息 docker inspect [选项] \u0026lt;容器名\u0026gt; # 进入容器 docker exec [选项] \u0026lt;容器名\u0026gt; [命令] # 导出容器 docker export [选项] \u0026lt;容器名\u0026gt; # 导入容器 docker import [选项] \u0026lt;容器名\u0026gt; # 重命名容器 docker rename [选项] \u0026lt;容器名\u0026gt; \u0026lt;新容器名\u0026gt; # 查看容器使用的资源 docker stats [选项] \u0026lt;容器名\u0026gt; # 查看容器端口映射 docker port [选项] \u0026lt;容器名\u0026gt; ","permalink":"/en/posts/tools/docker/docker%E5%91%BD%E4%BB%A4/","summary":"1.镜像相关 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 拉取镜像 docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] # 查看镜像 docker images [选项] [仓库名] # 删","title":"Docker命令"},{"content":"修改用户密码 1 alter user \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; identified with mysql_native_password by \u0026#39;123456\u0026#39;; 刷新权限 1 flush privileges; 添加一个远程用户 1 2 3 4 5 create user \u0026#39;remote\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;password\u0026#39; GRANT all ON *.* TO \u0026#39;remote\u0026#39;@\u0026#39;%\u0026#39;; grant all privileges on *.* to \u0026#39;remote\u0026#39;@\u0026#39;%\u0026#39; with grant option; *.*所有数据库下的所有表 创建数据库并设定中文编码 1 CREATE DATABASE `db_name` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; 登录格式 1 mysql -h #{数据库IP} -P 3306 -u #{用户名} -p -D #{数据库名} 自增id 不连续时 1 2 3 SET @auto_id = 0; UPDATE 表名 SET 自增字段名 = (@auto_id := @auto_id + 1); ALTER TABLE 表名 AUTO_INCREMENT = 1; 文件 1 source ","permalink":"/en/posts/tools/sql/mysql%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","summary":"修改用户密码 1 alter user \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; identified with mysql_native_password by \u0026#39;123456\u0026#39;; 刷新权限 1 flush privileges; 添加一个远程用户 1 2 3 4 5 create user \u0026#39;remote\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;password\u0026#39; GRANT all ON *.* TO \u0026#39;remote\u0026#39;@\u0026#39;%\u0026#39;; grant all privileges on *.* to \u0026#39;remote\u0026#39;@\u0026#39;%\u0026#39; with grant option; *.*所有数据库下的所有表","title":"MySql常用命令"},{"content":"参考\n任务\n提示: 需要先看CMU15-418/CS149的L2再完成Pro1\n任务描述: 用多线程画mandelbrot fractal.\n代码中给出了串行的实现, 你需要实现多线程的版本.\n多线程版本中只需要修改 workerThreadStart函数. 不需要手动创建线程, 也不需要手动join线程. 直接调用mandelbrotThread().\n1.1 \u0026amp; 1.2, 计算在2,3,4,5,6,7,8,16,32个线程下的加速比 编写并观察 workerThreadStart函数的实现:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 345void workerThreadStart(WorkerArgs *const args) { // TODO FOR CS149 STUDENTS: Implement the body of the worker // thread here. Each thread should make a call to mandelbrotSerial() // to compute a part of the output image. For example, in a // program that uses two threads, thread 0 could compute the top // half of the image and thread 1 could compute the bottom half. // printf(\u0026#34;Hello world from thread %d\\n\u0026#34;, args-\u0026gt;threadId); double startTime = CycleTimer::currentSeconds(); // 每个线程负责的行数(除不尽的部分由最后一个线程负责) int height = args-\u0026gt;height / args-\u0026gt;numThreads; int startRow = args-\u0026gt;threadId * height; int numRows = height; if (args-\u0026gt;threadId == args-\u0026gt;numThreads - 1) { // 如果是最后一个线程，那么就要把除不尽的部分也算上 numRows = height + args-\u0026gt;height % args-\u0026gt;numThreads; } printf(\u0026#34;Thread %d startRow: %d, numRows: %d\\n\u0026#34;, args-\u0026gt;threadId, startRow, numRows); mandelbrotSerial(args-\u0026gt;x0, args-\u0026gt;y0, args-\u0026gt;x1, args-\u0026gt;y1, args-\u0026gt;width, args-\u0026gt;height, startRow, numRows, args-\u0026gt;maxIterations, args-\u0026gt;output); double endTime = CycleTimer::currentSeconds(); printf(\u0026#34;Thread %d time: %.3f ms\\n\u0026#34;, args-\u0026gt;threadId, (endTime - startTime) * 1000); } 结果:\n线程数 加速比 2 1.97 3 1.63 4 2.31 5 2.37 6 3.08 7 3.15 8 3.74 16 5.14 可以观察到，加速比和线程数并不是线性相关.\n猜测原因 猜测可能的原因有:\n线程通信的开销 每个线程分配的任务不均匀 1.3 查看每个线程的执行时间,验证猜想 当线程数为4时, 每个线程的执行时间如下: Thread 0 time: 63.974 ms Thread 3 time: 65.563 ms Thread 2 time: 259.972 ms Thread 1 time: 260.669 ms\n当线程数为8时, 每个线程的执行时间如下: Thread 0 time: 13.702 ms Thread 7 time: 16.831 ms Thread 1 time: 57.324 ms Thread 6 time: 61.069 ms Thread 5 time: 113.431 ms Thread 2 time: 115.753 ms Thread 4 time: 164.736 ms Thread 3 time: 166.306 ms\n可以看到,中间线程分配的任务更多,执行时间更长. 因此在增加线程数时,加速比并不是线性增加的.\n1.4 任务描述:\n解决上面的问题,使得加速比更接近线性. 如: 8线程时的加速比需要在7~8之间. 解决方法需要具有适用性, 适用所有的线程数. tips: 有一个非常简单的静态赋值可以实现这个目标，并且线程之间不需要通信/同步.\n解决方案 思路: 根据代码可知, 每行的计算是独立的, 因此可以将每行分配给不同的线程. 但由上面的实验可知,中间行的计算量比较大.\n因此我们不应该直接平均切分行, 而是以线程数量为步长,线程交叉依次分配行. 即 第i个线程分配k*n+i行.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 void workerThreadStart(WorkerArgs *const args) { // TODO FOR CS149 STUDENTS: Implement the body of the worker // thread here. Each thread should make a call to mandelbrotSerial() // to compute a part of the output image. For example, in a // program that uses two threads, thread 0 could compute the top // half of the image and thread 1 could compute the bottom half. // printf(\u0026#34;Hello world from thread %d\\n\u0026#34;, args-\u0026gt;threadId); double startTime = CycleTimer::currentSeconds(); /* 方案1 // 每个线程负责的行数(除不尽的部分由最后一个线程负责) int baseHeight = args-\u0026gt;height / args-\u0026gt;numThreads; int startRow = args-\u0026gt;threadId * baseHeight; int numRows = baseHeight; int yu = args-\u0026gt;height % args-\u0026gt;numThreads; // 均匀分配剩余行 if (args-\u0026gt;threadId \u0026lt; yu) { numRows++; } startRow += std::min(args-\u0026gt;threadId, yu); printf(\u0026#34;Thread %d startRow: %d, numRows: %d\\n\u0026#34;, args-\u0026gt;threadId, startRow, numRows); mandelbrotSerial(args-\u0026gt;x0, args-\u0026gt;y0, args-\u0026gt;x1, args-\u0026gt;y1, args-\u0026gt;width, args-\u0026gt;height, startRow, numRows, args-\u0026gt;maxIterations, args-\u0026gt;output); */ // 方案2, 依次分配行 int height = args-\u0026gt;height; for (int i = args-\u0026gt;threadId; i \u0026lt; height; i += args-\u0026gt;numThreads) { mandelbrotSerial(args-\u0026gt;x0, args-\u0026gt;y0, args-\u0026gt;x1, args-\u0026gt;y1, args-\u0026gt;width, args-\u0026gt;height, i, 1, args-\u0026gt;maxIterations, args-\u0026gt;output); } double endTime = CycleTimer::currentSeconds(); printf(\u0026#34;Thread %d time: %.3f ms\\n\u0026#34;, args-\u0026gt;threadId, (endTime - startTime) * 1000); } 输出结果:\nThread 3 time: 88.842 ms Thread 1 time: 89.680 ms Thread 0 time: 89.717 ms Thread 7 time: 90.280 ms Thread 5 time: 90.715 ms Thread 6 time: 90.743 ms Thread 2 time: 91.049 ms Thread 4 time: 92.982 ms [mandelbrot thread]: [93.318] ms Wrote image file mandelbrot-thread.ppm (7.10x speedup from 8 threads)\n上面的解决方案使得每个线程的执行时间基本相同,因此加速比接近线性. 在8线程时,加速比为7.1.\n1.5 16线程和8线程的加速比 现在16线程是否明显优于8线程? 给出是或否的原因. (6.45x speedup from 16 threads) 16线程并没有明显由于8线程,反而还更慢. 原因:\n电脑本身是4核, 超线程后是8线程. 16线程时线程切换反而导致开销增加. 总结 pro1的目的是为了认识到并行计算的overhead, 以及多线程在计算上也应该是依次交替分配的. 不能简单的平均分配.\npro1是通过垂直分割来实现并行计算. 而向量化是通过水平分割来实现并行计算.\nprogram-2-vectorizing-code-using-simd-intrinsics 前提: L2 任务描述： 使用SIMD指令(CS149intrin.h提供的),来实现clampedExpVector函数.\n示例函数:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 void absVector(float* values, float* output, int N) { __cs149_vec_float x; __cs149_vec_float result; __cs149_vec_float zero = _cs149_vset_float(0.f); __cs149_mask maskAll, maskIsNegative, maskIsNotNegative; // Note: Take a careful look at this loop indexing. This example // code is not guaranteed to work when (N % VECTOR_WIDTH) != 0. // Why is that the case? for (int i=0; i\u0026lt;N; i+=VECTOR_WIDTH) { // All ones maskAll = _cs149_init_ones(); // All zeros maskIsNegative = _cs149_init_ones(0); // Load vector of values from contiguous memory addresses _cs149_vload_float(x, values+i, maskAll); // x = values[i]; // Set mask according to predicate _cs149_vlt_float(maskIsNegative, x, zero, maskAll); // if (x \u0026lt; 0) { // Execute instruction using mask (\u0026#34;if\u0026#34; clause) _cs149_vsub_float(result, zero, x, maskIsNegative); // output[i] = -x; // Inverse maskIsNegative to generate \u0026#34;else\u0026#34; mask maskIsNotNegative = _cs149_mask_not(maskIsNegative); // } else { // Execute instruction (\u0026#34;else\u0026#34; clause) _cs149_vload_float(result, values+i, maskIsNotNegative); // output[i] = x; } // Write results back to memory _cs149_vstore_float(output+i, result, maskAll); } } 示例函数absVector并不能适用于所有情况,原因如下: 当n%VECTOR_WIDTH != 0时, 会越界.\n1\u0026amp;2 实现clampedExpVector函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 void clampedExpVector(float *values, int *exponents, float *output, int N) { // // CS149 STUDENTS TODO: Implement your vectorized version of // clampedExpSerial() here. // // Your solution should work for any value of // N and VECTOR_WIDTH, not just when VECTOR_WIDTH divides N // __cs149_vec_float one, nine; __cs149_vec_int zeroInt, oneInt; oneInt = _cs149_vset_int(1); zeroInt = _cs149_vset_int(0); one = _cs149_vset_float(1.f); nine = _cs149_vset_float(9.999999f); for (int i = 0; i \u0026lt; N; i += VECTOR_WIDTH) { __cs149_mask maskAll, maskIsZero, maskIsNotZero; __cs149_vec_float x; __cs149_vec_int y; // All ones maskAll = _cs149_init_ones(); // All zeros maskIsZero = _cs149_init_ones(0); // 防止在最后一次循环时，i+VECTOR_WIDTH超出N if (i + VECTOR_WIDTH \u0026gt; N) { maskAll = _cs149_init_ones(N - i); } // float x = values[i]; _cs149_vload_float(x, values + i, maskAll); // int y = exponents[i]; _cs149_vload_int(y, exponents + i, maskAll); // if (y == 0) _cs149_veq_int(maskIsZero, y, zeroInt, maskAll); // { // output[i] = 1.f; // } _cs149_vstore_float(output + i, one, maskIsZero); // else maskIsNotZero = _cs149_mask_not(maskIsZero); // 消除最后一次循环时，i+VECTOR_WIDTH超出N的情况 maskIsNotZero = _cs149_mask_and(maskIsNotZero, maskAll); { // float result = x; __cs149_vec_float result = x; // int count = y - 1; __cs149_vec_int count; _cs149_vsub_int(count, y, oneInt, maskIsNotZero); // 哪些count\u0026gt;0 __cs149_mask countMark; _cs149_vgt_int(countMark, count, zeroInt, maskIsNotZero); // while (count \u0026gt; 0) while (_cs149_cntbits(countMark) \u0026gt; 0) { // result *= x; _cs149_vmult_float(result, result, x, countMark); // count--; _cs149_vsub_int(count, count, oneInt, countMark); // 哪些count\u0026gt;0 _cs149_vgt_int(countMark, count, zeroInt, countMark); } // if (result \u0026gt; 9.999999f) __cs149_mask gtNineMask; _cs149_vgt_float(gtNineMask, result, nine, maskIsNotZero); // { reult = 9.999999f;} _cs149_vmove_float(result, nine, gtNineMask); // output[i] = result; _cs149_vstore_float(output + i, result, maskIsNotZero); } } } 通过init_ones来防止在有n%vectorWith!=0时 越界.\n在最开始的maskAll时设置 在取反码后也要设置一次 count循环: 通过设置一个mask来标记哪些count\u0026gt;0, 从而实现循环.\n修改vectorWidth为2, 4, 8, to 16来回答: Does the vector utilization increase, decrease or stay the same as VECTOR_WIDTH changes? Why?\nvectorWidth为2时, 结果如下: ****************** Printing Vector Unit Statistics ******************* Vector Width: 2 Total Vector Instructions: 162728 Vector Utilization: 77.0% Utilized Vector Lanes: 250653 Total Vector Lanes: 325456\nvectorWidth为4时, 结果如下: ****************** Printing Vector Unit Statistics ******************* Vector Width: 3 Total Vector Instructions: 119440 Vector Utilization: 72.2% Utilized Vector Lanes: 258879 Total Vector Lanes: 358320\nvectorWidth为8时, 结果如下: ****************** Printing Vector Unit Statistics ******************* Vector Width: 8 Total Vector Instructions: 51628 Vector Utilization: 66.0% Utilized Vector Lanes: 272539 Total Vector Lanes: 413024\nvectorWidth为16时, 结果如下: ****************** Printing Vector Unit Statistics ******************* Vector Width: 16 Total Vector Instructions: 26968 Vector Utilization: 64.2% Utilized Vector Lanes: 277188 Total Vector Lanes: 431488\n可以发现, 随着vectorWidth的增加, vectorUtilization也在减少.\n原因: 有多个条件语句,当vectorWidth增加时, 每次在某个条件中不执行的指令也会增加.\n3 实现arraySumVector 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 float arraySumVector(float *values, int N) { // // CS149 STUDENTS TODO: Implement your vectorized version of arraySumSerial here // __cs149_vec_float sum = _cs149_vset_float(0.f); for (int i = 0; i \u0026lt; N; i += VECTOR_WIDTH) { __cs149_mask maskAll; __cs149_vec_float x; // All ones maskAll = _cs149_init_ones(); // 防止在最后一次循环时，i+VECTOR_WIDTH超出N if (i + VECTOR_WIDTH \u0026gt; N) { maskAll = _cs149_init_ones(N - i); } // float x = values[i]; _cs149_vload_float(x, values + i, maskAll); // sum += x; _cs149_vadd_float(sum, sum, x, maskAll); } float result = 0.f; // log2(VECTOR_WIDTH)内解决 for (int i = 0; i \u0026lt; log2(VECTOR_WIDTH); i++) { // 使用_cs149_hadd_float函数，将sum中的每两个元素相加 // 再使用_cs149_interleave_float函数，将sum中的每两个元素交叉放置 // 重复log2(VECTOR_WIDTH)次 _cs149_hadd_float(sum, sum); _cs149_interleave_float(sum, sum); } // 将sum中的第一个元素赋值给result result = sum.value[0]; return result; } 假设VECTOR_WIDTHs始终是N的因子.\n可以实现在O(N/VECTOR_WIDTH + log2(VECTOR_WIDTH))的时间内完成计算.\n最后的log2实现方式. 提示中给了两个函数 hadd: 将每两个元素相加 interleave: 将每两个元素交叉放置\n因此我们可以类似与归并排序的方式,将sum中的每两个元素相加,再将每两个元素交叉放置. 重复log2(VECTOR_WIDTH)次后,第一个元素就是结果.\nprogram-3 ISPC 前提: L3\npart1 ISPC basic 任务:学习ISPC基本概念和编写.\nISPC是一种编译器,可以将C代码编译为SIMD指令.\npart2 ISPC task 任务描述: 观察ISPCtask执行的结果\n1 启动mandelbrot_ispc \u0026ndash;tasks\n结果: [mandelbrot serial]: [424.881] ms Wrote image file mandelbrot-serial.ppm [mandelbrot ispc]: [97.180] ms Wrote image file mandelbrot-ispc.ppm [mandelbrot multicore ispc]: [48.986] ms Wrote image file mandelbrot-task-ispc.ppm (4.37x speedup from ISPC) (8.67x speedup from task ISPC)\n因为设置了两个task所以大约是两倍的加速比 对于 ISPC\n2 修改mandelbrot_ispc_withtasks()中的task数量, you should be able to achieve performance that exceeds the sequential version of the code by over 32 times! How did you determine how many tasks to create? Why does the number you chose work best?\n根据机器的最大超线程数量设置 我设置了16个task, 因为我的机器是4核8线程, 16个task可以使得每个线程都有两个task.\n3 what happens when you launch 10,000 ISPC tasks? What happens when you launch 10,000 threads?\n向量加速\n思考题: Q: Why are there two different mechanisms (foreach and launch) for expressing independent, parallelizable work to the ISPC system? A:foreach是将一个任务分配给多个线程,而launch是将多个任务分配给多个线程.\nQ: Couldn\u0026rsquo;t the system just partition the many iterations of foreach across all cores and also emit the appropriate SIMD code for the cores? A:\nprogram-4 Iterative sqrt (15 points) 用sqrt复习ISPC的基本概念\n1 运行结果: [sqrt serial]: [1316.793] ms [sqrt ispc]: [301.134] ms [sqrt task ispc]: [52.439] ms (4.37x speedup from ISPC) (25.11x speedup from task ISPC) 4.37x speedup due to SIMD 25.11 / 4.37 = 5.74x speedup due to multi-core\n2 构造数组使得加速比最大.\n全部数为2.998. 思路: 因为每个元素相同可以让计算更均匀,2.998可以充分调动cpu 结构: (5.60x speedup from ISPC) (30.39x speedup from task ISPC)\n3 构造数组使得加速比最小.\n全部数为1 思路: 1的sqrt计算迭代最少.\n结果: (2.50x speedup from ISPC) (3.08x speedup from task ISPC)\nprogram-5 BLAS saxpy (10 points) 1 运行观察加速比 [saxpy ispc]: [25.098] ms [11.874] GB/s [1.594] GFLOPS [saxpy task ispc]: [18.438] ms [16.164] GB/s [2.169] GFLOPS (1.36x speedup from use of tasks)\n因为需要访问内存所以加速比不高.\n2 Even though saxpy loads one element from X, one element from Y, and writes one element to result the multiplier by 4 is correct. Why is this the case? (Hint, think about how CPU caches work.)\n当程序写入结果的一个元素时，它首先将包含这个元素的缓存行提取到缓存中。这需要一个内存操作。然后，当不需要这个缓存行时，它将从缓存中闪现出来，这需要另一个内存操作。\n","permalink":"/en/posts/cmu-15418cs-618/asst1-performance-analysis-on-a-quad-core-cpu/","summary":"参考 任务 提示: 需要先看CMU15-418/CS149的L2再完成Pro1 任务描述: 用多线程画mandelbrot fractal. 代码中给出了串行的实现, 你","title":""},{"content":"并行程序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void sinx(int N, int terms, float* x, float* result) { for (int i = 0; i \u0026lt; N; i++) { float value = x[i]; float number = x[i] * x[i] * x[i]; int sign = -1; int denom = 6; for (int j = 0; j \u0026lt; terms; j++) { value += sign * number / denom; sign *= -1; denom *= (2*j+3)*(2*j+2); number *= x[i] * x[i]; } result[i] = value; } } 转换成汇编后大致如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 ld r0, addr[r1] mul ri, r0, r0 mul r1, r1, r0 可以看到每次循环都是独立的。 对于最简单的是顺序执行。 通过超线程(超标量处理器具有从单个指令流中提取多个指令的能力)可以提高性能。有时称指令级并行性。(ILP, Instruction Level Parallelism) 但在这些汇编指令中必须顺序执行。 因此实现指令级并行性是一个挑战。 但即使是纯顺序执行的代码,也有很多方式使其运行更快(基于写代码的方式和编译器的智能程度). Pentium 4 比如先取多条指令等. (有个黑匣子会预测分支,预测错误的话就会清空流水线,浪费时间) 解决方法: 1. 通过pthread编写并行性的程序 2. 假设有一种语言可以表示并行性,编译器可以自动并行化程序 如: forall(int i from 0 to n-1){} 自动并行化可能的解决方法: 1. 直接分为k个线程,每个线程处理n/k个循环. 然后将结果合并 2. 在硬件上执行. 有一堆性能较低但具有并行性的处理器时, 也需要更多电力/时间来驱动很多信号从一端到另一端. ## CPU \u0026amp;\u0026amp; GPU GPU将核心的概念带到了极致, 抛弃了所有的分支预测, 只是控制逻辑而不完成计算. 对于上面的程序有垂直和水平两种分割方式: - 垂直: 每个线程处理一个循环 - 水平: 同时处理多个循环, 如先同时进行所有的第一个乘法... ## SIMD Single Instruction Multiple Data 假设我正在执行的多次操作之间没有依赖关系,都能够并行运行. a single instruction is applied to multiple data elements simultaneously. 即: 同时对8个数值和另一个地方的8个数值取出并进行加法. 有时这些数值可以被称作向量. 使用AVX intrinsics的向量化程序: ```c++ void sinx(int N, int terms, float* x, float* result) { for (int i = 0; i \u0026lt; N; i+=8) { __m256 origx = _mm256_load_ps(\u0026amp;x[i]); __m256 value = origx; __m256 number = _mm256_mul_ps(origx, _mm256_mul_ps(origx, origx)); float sign = -1; __m256 denom = _mm256_set1_ps(6); for (int j = 0; j \u0026lt; terms; j++) { //value += sign * number / denom; __m256 tmp = _mm256_div_ps(number, denom); tmp = _mm256_mul_ps(tmp, _mm256_set1_ps(sign)); value = _mm256_add_ps(value, tmp); sign *= -1; //denom *= (2*j+3)*(2*j+2); denom = _mm256_mul_ps(denom, _mm256_set1_ps((2*j+3)*(2*j+2))); //number *= x[i] * x[i]; number = _mm256_mul_ps(number, _mm256_mul_ps(origx, origx)); } _mm256_store_ps(\u0026amp;result[i], value); //result[i] = value; } } 编译成汇编后大致如下:\n1 2 3 4 5 6 7 vloadps xmm0, addr[r1] vmulps xmm1, xmm0, xmm0 vmulps xmm2, xmm1, xmm0 ... ... ... vstoreps addr[xmm2], xmm0 AVX代表高级矢量扩展, 256代表每次可以处理256位的数据, 也就是8个float. 有多个版本:\n1 2 3 AVX: 128位 = 4 * 4 * 8 = 32字节 AVX2: 256位 = 8 * 4 * 8 = 32字节 AVX512: 512位 = 16 * 4 * 8 = 64字节 XMM寄存器是特殊的32字节 256位寄存器, 有16个, 从xmm0到xmm15. 用于支持vectorized SIMD指令.\n那么有没有办法让编译器自动将代码向量化呢?\n有,GCC的-O3选项可以自动向量化代码. 但只有非常结构化,精心编写的代码才能被自动向量化.\n条件 如果加入条件判断,如何向量化?\n1 2 3 4 5 if(x \u0026lt; 0){ x = -x; }else{ x = x; } SIMD可能的做法: 设置一个掩码, 用于标记哪些元素需要执行哪些不需要执行.\n1 2 3 4 x \u0026lt; 0: 1 1 0 0 1 0 0 0 x = -x: 1 1 0 0 1 0 0 0 翻转: 0 0 1 1 0 1 1 1 x = x: 0 0 1 1 0 1 1 1 但大多时候只保留了一半的效率,因为每次有可能只有一半的数据需要执行. 不过这很好的保证了一致性,因为分支结束后又回到了同一个执行路径. 即保持一致性,远离分歧.\ncoherent execution: 所有的线程都执行相同的指令.\ndivergent: a lack of instruction stream coherence.\n对于生成这些矢量操作,要么有聪明的编译器,要么就是有耐心的程序员.\nSIMD execution on many modern GPUs SPMD: Single Program Multiple Data\nGPU给的不是SIMD,而是SPMD. 单个程序,多个数据. 意味着程序的不同部分可以执行不同的指令.\n在这之下,还是用SIMD来实现大部分逻辑,采用异构的方式来实现并行.\n但有n个加法, 即两个包含n个值的向量相加. 实际上不是所有单位都在等待计算.而是会先计算出如何分配到块中,底层块的实际大小是32, 32values而不是32byte. 这个被称作SIMD宽度,一般是8-32.\nGPU和CPU的差别 CPU i7:\n4核 8 SIMD ALUs per core 每秒大概几千次浮点运算 GPU: RTX 1080\n20 cores 32 SIMD ALUs per core 每秒大概8m次浮点运算 GPU的核心摒弃了分支预测等只用做control,因此可以有更多的ALU.填充进来.\n大概是80:1的原始计算能力差异.\n总结 三种方法实现并行计算\n多核CPU:\n线程级实现并行 SIMD:\n指令级并行 通过向量化指令实现 但依赖于事先知道执行的指令优先级顺序 Superscaler: exploit ILP within an instruction stream\npaart2 accessing memory Memory latency: 从CPU到内存的时间\nexample: DRAM访问时间 100 cycles, 100ns Memory bandwidth: 从内存到CPU的时间\nexample: 20GB/s 其实不是很快 Stall: CPU等待内存的时间 当cpu试图进行读取而内存不可用时，就会停等知道内存可用.\n缓存就是为了解决Stall的问题.\n在多级缓存中,靠近核心的缓存是私有的. 这样可以通过写入读出L2缓存的数据来实现通讯,而不需要经过DRAM.\n缓存对延迟和带宽都有帮助.\nPrefecthing reduces stalls 硬件通常通过预取来减少延迟. 即预测下一次可能会访问的数据,并将其提前读取到缓存中. 不过可能会造成信息泄露\n使用预取的效果: Multi-threading reduces stalls 让多个线程交替进行, 如asst1/prog2的实现\n这也是超线程的实现,在一个核心中多路复用多个指令流. 对于CPU\u0026amp;GPU, 谁来组织线程是不同的做法.(操作系统 or 硬件)\n通常情况下内存要比其他因素更加限制速度\n","permalink":"/en/posts/cmu-15418cs-618/l2/","summary":"并行程序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void sinx(int N, int terms, float* x, float* result) { for (int i = 0; i \u0026lt; N; i++) { float value = x[i]; float number = x[i] * x[i] * x[i]; int sign = -1; int denom = 6; for (int j = 0; j \u0026lt; terms; j++) { value","title":"L2"},{"content":"Parallelism 加速比 Speed up 是指： 程序在单处理器上运行的时间 / 程序在多处理器上运行的时间\n我们一般会期望用两倍的硬件得到两倍的速度提升,但是实际上并不是这样的。\n制约性能提升可能的因素有:\n资源分配不均匀 通信开销 短板效应 共享资源读写冲突 为什么要去了解硬件？\n什么是限制性能的因素？ 导致性能瓶颈的原因是什么？ Efficiency fast != efficient\n什么是效率？ 尽可能地利用资源，减少浪费 比如按时间租用服务器。\n总结 并行程序的挑战：\n负载均衡 Load balance 通信延迟 Communication latency 集体工作时，真正用于计算的时间很少 ","permalink":"/en/posts/cmu-15418cs-618/l1-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%92%8C%E9%AB%98%E6%95%88/","summary":"Parallelism 加速比 Speed up 是指： 程序在单处理器上运行的时间 / 程序在多处理器上运行的时间 我们一般会期望用两倍的硬件得到两倍的速度提升,但是实际上并不是这样的","title":"Why parallelism? Why efficiency?"},{"content":" ","permalink":"/en/posts/c++/modern-c++/","summary":"","title":"测试 blog2313"},{"content":"TL;DR 背景: 已使用nextcloud和typora写笔记 需求: 将笔记转换为博客.(且因为本人太懒,😂 所以需要全自动化) 在nextcloud中, 专门设置一个文件夹\u0026quot;笔记\u0026quot; 转换为博客文件夹 不能改变原来记笔记的方式 不能有任何新增的操作 方案: 使用hugo搭建博客 使用Github pages部署博客 使用Github Actions自动化部署 使用py脚本将笔记转换为博客 使用任务计划程序定时执行py脚本 使用hugo搭建博客 参考: hugo官网 Hugo+Github Pages+Github Action博客方案之二 Hugo+Github Pages+Github Action博客方案之三 PaperMod主题\n创建github仓库 要创建两个仓库\n一个仓库用于存放博客源码 一个仓库用于存放博客静态文件 创建博客静态文件仓库 设置仓库名为: 用户名.github.io 我的博客仓库\n创建博客源码仓库 设置仓库名为: hugo-blog // 仓库名可以自定义 我的博客源码仓库\n安装hugo 1 scoop install hugo 创建hugo博客 1 hugo new site hugo-blog 安装主题 1 2 3 4 cd hugo-blog ## 进入博客目录, 这个是博客源码仓库 git init git submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod git submodule update --init --recursive ## needed when you reclone your repo (submodules may not get cloned automatically) 配置主题 这里使用yaml格式的配置文件, 也可以使用toml格式的配置文件 所以需要删除config.toml文件, 并创建config.yaml文件\nconfig.yaml:\n1 2 3 4 baseURL: / title: ysyy\u0026#39;s blog theme: PaperMod languageCode: zh-cn 剩余配置参考\n创建文章 1 hugo new posts/first/hello-world.md 本地预览 1 hugo server -D 生成静态文件 生成静态文件, 生成的静态文件在 public文件夹中。 之后我们将这个文件夹中复制到博客静态文件仓库中\n1 hugo 部署到github pages 创建静态文件夹\n1 2 3 4 5 git clone git@用户名.github.io.git cd 用户名.github.io cp -r hugo-blog/public/* ./ 提交到github\n1 2 3 git add . git commit -m \u0026#34;first commit\u0026#34; git push origin main 配置github pages 在github中的 用户名.github.io仓库中, 点击 Settings选项卡, 找到 GitHub Pages选项, 将 Source选项设置为 main分支, 点击 Save按钮, 这样就可以通过 https://用户名.github.io访问博客了\n使用Github Actions自动化部署 参考\n如果每一次更新/发布新博客都需要手动执行上面的步骤, 那么就太麻烦了, 所以我们需要自动化部署\n在博客源码仓库的根目录下创建 .github/workflows/deploy.yml文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 name: ysyyblog on: push: branches: - main jobs: build-deploy: runs-on: ubuntu-20.04 # runs-on: macos-latest steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;latest\u0026#39; # extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: personal_token: ${{ secrets.PERSONAL_TOKEN }} # 另外还支持 deploy_token 和 github_token external_repository: ysyyhhh/ysyyhhh.github.io # 修改为你的 静态文件GitHub Pages 仓库 publish_dir: ./public # keep_files: false publish_branch: main # 如果使用自定义域名，还需要添加下面一行配置 # cname: www 创建personal_token 在github主页的右上角点击头像, 点击 Settings选项卡, 找到 Developer settings选项,\n找到 Personal access tokens选项, 点击 Generate new token按钮, 创建一个新的token\n配置personal_token 在hugo-blog仓库中, 点击 Settings选项卡, 找到 Secrets选项, 点击 New repository secret按钮,\n新增一个名为 PERSONAL_TOKEN的secret, 值为上面创建的personal_token\n测试自动化部署 在本地的hugo-blog仓库中, 修改 content/posts/first/hello-world.md文件, 然后提交到github\n可以在 Actions选项卡中查看自动化部署的状态\n如果在 Actions选项卡中看到了 build-deploy任务, 且状态为 success, 那么就说明自动化部署成功了\n可以在 用户名.github.io仓库中查看是否已经更新.\n使用任务计划程序和py脚本实现全自动化 上面的步骤已经让我们发布笔记的过程变成:\n使用hugo new / 直接编辑 content的文件 来创建笔记 提交到hugo-blog仓库 然后hugo-blog仓库就会自动部署到用户名.github.io仓库中\n虽然已经只剩两步了,但遵循能自动化就自动化的原则, 我们还是要把这两步也自动化\n使用py脚本将笔记转换为博客 安装python这些步骤就省去了,这里直接给出py脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 \u0026#39;\u0026#39;\u0026#39; 每天定时更新博客内容 1.进入项目根目录: D:/program_about/hugo/hugo-blog 2. 将D:/nextcloud/笔记/下的文件同步到 ./content/posts/下 3. 执行./push.bat 或 git add . \u0026amp;\u0026amp; git commit -m \u0026#34;update\u0026#34; \u0026amp;\u0026amp; git push \u0026#39;\u0026#39;\u0026#39; import os import shutil def create_index(root, name): \u0026#39;\u0026#39;\u0026#39; name = A.md 在root下生成\u0026#39;A\u0026#39;文件夹 将A.md移动到A文件夹下，并重命名为index.md 如果 存在 root + \u0026#39;/img\u0026#39; 的文件夹 将 root + \u0026#39;/img\u0026#39; 复制到 root + \u0026#39;/A/img\u0026#39; 下 \u0026#39;\u0026#39;\u0026#39; # 生成文件夹 dir_name = name.split(\u0026#39;.\u0026#39;)[0] print(root, name, dir_name) os.mkdir(os.path.join(root, dir_name)) # 移动文件 shutil.move(os.path.join(root, name), os.path.join(root, dir_name, \u0026#39;index.md\u0026#39;)) # 处理img if os.path.exists(os.path.join(root, \u0026#39;img\u0026#39;)): shutil.copytree(os.path.join(root, \u0026#39;img\u0026#39;), os.path.join(root, dir_name, \u0026#39;img\u0026#39;)) def adjust(dir): os.chdir(dir) \u0026#39;\u0026#39;\u0026#39; 将所有下面的格式 - A.md - img - A-1.png 转换成 - A - index.md - img - A-1.png 如果遇到\u0026#34;.md\u0026#34;文件,直接删除 \u0026#39;\u0026#39;\u0026#39; for(root, dirs, files) in os.walk(\u0026#34;.\u0026#34;): root = os.path.join(dir, root) for name in files: if name == \u0026#39;.md\u0026#39;: os.remove(os.path.join(root, name)) continue if name.endswith(\u0026#39;.md\u0026#39;): create_index(root, name) for name in dirs: # 递归调用 adjust(os.path.join(root, name)) def sync(): root_path = \u0026#39;D:/program_about/hugo/hugo-blog\u0026#39; os.chdir(root_path) # 当文件已存在时，无法创建该文件。: \u0026#39;./content/posts/\u0026#39; shutil.rmtree(\u0026#39;./content/posts/\u0026#39;) # git中也要删除 os.system(\u0026#39;git rm -r ./content/posts/\u0026#39;) shutil.copytree(\u0026#39;D:/nextcloud/笔记/\u0026#39;, \u0026#39;./content/posts/\u0026#39;) # 把所有文件夹和文件的名称大写转换为小写 os.chdir(\u0026#39;./content/posts/\u0026#39;) for root, dirs, files in os.walk(\u0026#34;.\u0026#34;): for name in files: new_name = name.lower() os.rename(os.path.join(root, name), os.path.join(root, new_name)) for name in dirs: new_name = name.lower() os.rename(os.path.join(root, name), os.path.join(root, new_name)) # 调整文件夹结构 adjust(root_path+\u0026#39;./content/posts/\u0026#39;) # 上传到git # os.chdir(\u0026#39;./content/posts/\u0026#39;) os.chdir(\u0026#39;D:/program_about/hugo/hugo-blog\u0026#39;) os.system(\u0026#39;git add ./content/posts/\u0026#39;) os.system(\u0026#39;git commit -m \u0026#34;update\u0026#34;\u0026#39;) os.system(\u0026#39;git push\u0026#39;) os.chdir(\u0026#39;D:/program_about/hugo/hugo-blog\u0026#39;) print(\u0026#39;sync done\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: sync() 将上面的路径修改为自己的路径, 然后保存为 sync.py文件 可以执行py脚本,测试一下\n关于图片路径问题 参考方案\n因为我平时的图片路径是\n1 2 3 - A.md - img - A-1.png 但是hugo会将A.md文件转换为A文件夹, 所以此时是无法访问A-1.png的.\n这里是通过改变相对路径关系来解决的, 即代码中的adjust()\n当然如果你有图床就不需要这么麻烦了\n使用任务计划程序定时执行py脚本 参考 这里我使用的是win10自带的任务计划程序, 其他系统的任务计划程序也是类似的\n以下步骤由Claude生成\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 下面是如何使用Windows任务计划程序来配置定时每天执行Python脚本的步骤: 打开任务计划程序(Windows + R 输入taskschd.msc回车) 点击\u0026#34;操作\u0026#34;栏中的\u0026#34;创建基本任务\u0026#34; 输入任务名称,选择触发器为每天定时,设置执行时间 在操作栏中,点击“新建” 选择“启动一个程序” 在“程序/脚本”框中输入Python解释器的路径,例如C:\\Python37\\python.exe 在“添加参数(可选)”中输入python脚本文件的完整路径,例如C:\\Users\\username\\script.py 点击“确定”保存此操作 在下一页中选择用户账号,例如“当前用户” 点击“确定”完成创建任务 根据需要配置触发器记录和其他选项 点击“确定”保存任务 任务将在设定的时间自动执行python脚本文件 每次修改脚本后需要停止原有任务,然后再新建一个相同的任务来加载修改后的脚本代码。 需要注意python interpreter路径和脚本路径的正确性。定时执行格式也需要正确,这样就可以实现Windows系统中的自动定时任务执行Python脚本了。 ","permalink":"/en/posts/tools/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","summary":"TL;DR 背景: 已使用nextcloud和typora写笔记 需求: 将笔记转换为博客.(且因为本人太懒,😂 所以需要全自动化) 在nextcloud中, 专","title":"用Hugo + Github Pages/Action + py + 任务计划程序 搭建 全自动化markdown笔记转博客"},{"content":"","permalink":"/en/search/","summary":"","title":""}]