[{"content":"view Run Run python file in terminal: Ctrl + F5\n","permalink":"/en/posts/tools/vscode%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%85%A8/","summary":"view Run Run python file in terminal: Ctrl + F5","title":"工作学习流(vscode快捷键)"},{"content":"参考\n任务\n提示: 需要先看CMU15-418/CS149的L2再完成Pro1\n任务描述: 用多线程画mandelbrot fractal.\n代码中给出了串行的实现, 你需要实现多线程的版本.\n多线程版本中只需要修改 workerThreadStart函数. 不需要手动创建线程, 也不需要手动join线程. 直接调用mandelbrotThread().\n1.1 \u0026amp; 1.2, 计算在2,3,4,5,6,7,8,16,32个线程下的加速比 编写并观察 workerThreadStart函数的实现:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 345void workerThreadStart(WorkerArgs *const args) { // TODO FOR CS149 STUDENTS: Implement the body of the worker // thread here. Each thread should make a call to mandelbrotSerial() // to compute a part of the output image. For example, in a // program that uses two threads, thread 0 could compute the top // half of the image and thread 1 could compute the bottom half. // printf(\u0026#34;Hello world from thread %d\\n\u0026#34;, args-\u0026gt;threadId); double startTime = CycleTimer::currentSeconds(); // 每个线程负责的行数(除不尽的部分由最后一个线程负责) int height = args-\u0026gt;height / args-\u0026gt;numThreads; int startRow = args-\u0026gt;threadId * height; int numRows = height; if (args-\u0026gt;threadId == args-\u0026gt;numThreads - 1) { // 如果是最后一个线程，那么就要把除不尽的部分也算上 numRows = height + args-\u0026gt;height % args-\u0026gt;numThreads; } printf(\u0026#34;Thread %d startRow: %d, numRows: %d\\n\u0026#34;, args-\u0026gt;threadId, startRow, numRows); mandelbrotSerial(args-\u0026gt;x0, args-\u0026gt;y0, args-\u0026gt;x1, args-\u0026gt;y1, args-\u0026gt;width, args-\u0026gt;height, startRow, numRows, args-\u0026gt;maxIterations, args-\u0026gt;output); double endTime = CycleTimer::currentSeconds(); printf(\u0026#34;Thread %d time: %.3f ms\\n\u0026#34;, args-\u0026gt;threadId, (endTime - startTime) * 1000); } 结果:\n线程数 加速比 2 1.97 3 1.63 4 2.31 5 2.37 6 3.08 7 3.15 8 3.74 16 5.14 可以观察到，加速比和线程数并不是线性相关.\n猜测原因 猜测可能的原因有:\n线程通信的开销 每个线程分配的任务不均匀 1.3 查看每个线程的执行时间,验证猜想 当线程数为4时, 每个线程的执行时间如下: Thread 0 time: 63.974 ms Thread 3 time: 65.563 ms Thread 2 time: 259.972 ms Thread 1 time: 260.669 ms\n当线程数为8时, 每个线程的执行时间如下: Thread 0 time: 13.702 ms Thread 7 time: 16.831 ms Thread 1 time: 57.324 ms Thread 6 time: 61.069 ms Thread 5 time: 113.431 ms Thread 2 time: 115.753 ms Thread 4 time: 164.736 ms Thread 3 time: 166.306 ms\n可以看到,中间线程分配的任务更多,执行时间更长. 因此在增加线程数时,加速比并不是线性增加的.\n1.4 任务描述:\n解决上面的问题,使得加速比更接近线性. 如: 8线程时的加速比需要在7~8之间. 解决方法需要具有适用性, 适用所有的线程数. tips: 有一个非常简单的静态赋值可以实现这个目标，并且线程之间不需要通信/同步.\n解决方案 思路: 根据代码可知, 每行的计算是独立的, 因此可以将每行分配给不同的线程. 但由上面的实验可知,中间行的计算量比较大.\n因此我们不应该直接平均切分行, 而是以线程数量为步长,线程交叉依次分配行. 即 第i个线程分配k*n+i行.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 void workerThreadStart(WorkerArgs *const args) { // TODO FOR CS149 STUDENTS: Implement the body of the worker // thread here. Each thread should make a call to mandelbrotSerial() // to compute a part of the output image. For example, in a // program that uses two threads, thread 0 could compute the top // half of the image and thread 1 could compute the bottom half. // printf(\u0026#34;Hello world from thread %d\\n\u0026#34;, args-\u0026gt;threadId); double startTime = CycleTimer::currentSeconds(); /* 方案1 // 每个线程负责的行数(除不尽的部分由最后一个线程负责) int baseHeight = args-\u0026gt;height / args-\u0026gt;numThreads; int startRow = args-\u0026gt;threadId * baseHeight; int numRows = baseHeight; int yu = args-\u0026gt;height % args-\u0026gt;numThreads; // 均匀分配剩余行 if (args-\u0026gt;threadId \u0026lt; yu) { numRows++; } startRow += std::min(args-\u0026gt;threadId, yu); printf(\u0026#34;Thread %d startRow: %d, numRows: %d\\n\u0026#34;, args-\u0026gt;threadId, startRow, numRows); mandelbrotSerial(args-\u0026gt;x0, args-\u0026gt;y0, args-\u0026gt;x1, args-\u0026gt;y1, args-\u0026gt;width, args-\u0026gt;height, startRow, numRows, args-\u0026gt;maxIterations, args-\u0026gt;output); */ // 方案2, 依次分配行 int height = args-\u0026gt;height; for (int i = args-\u0026gt;threadId; i \u0026lt; height; i += args-\u0026gt;numThreads) { mandelbrotSerial(args-\u0026gt;x0, args-\u0026gt;y0, args-\u0026gt;x1, args-\u0026gt;y1, args-\u0026gt;width, args-\u0026gt;height, i, 1, args-\u0026gt;maxIterations, args-\u0026gt;output); } double endTime = CycleTimer::currentSeconds(); printf(\u0026#34;Thread %d time: %.3f ms\\n\u0026#34;, args-\u0026gt;threadId, (endTime - startTime) * 1000); } 输出结果:\nThread 3 time: 88.842 ms Thread 1 time: 89.680 ms Thread 0 time: 89.717 ms Thread 7 time: 90.280 ms Thread 5 time: 90.715 ms Thread 6 time: 90.743 ms Thread 2 time: 91.049 ms Thread 4 time: 92.982 ms [mandelbrot thread]: [93.318] ms Wrote image file mandelbrot-thread.ppm (7.10x speedup from 8 threads)\n上面的解决方案使得每个线程的执行时间基本相同,因此加速比接近线性. 在8线程时,加速比为7.1.\n1.5 16线程和8线程的加速比 现在16线程是否明显优于8线程? 给出是或否的原因. (6.45x speedup from 16 threads) 16线程并没有明显由于8线程,反而还更慢. 原因:\n电脑本身是4核, 超线程后是8线程. 16线程时线程切换反而导致开销增加. 总结 pro1的目的是为了认识到并行计算的overhead, 以及多线程在计算上也应该是依次交替分配的. 不能简单的平均分配.\npro1是通过垂直分割来实现并行计算. 而向量化是通过水平分割来实现并行计算.\nprogram-2-vectorizing-code-using-simd-intrinsics 前提: L2 任务描述： 使用SIMD指令(CS149intrin.h提供的),来实现clampedExpVector函数.\n示例函数:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 void absVector(float* values, float* output, int N) { __cs149_vec_float x; __cs149_vec_float result; __cs149_vec_float zero = _cs149_vset_float(0.f); __cs149_mask maskAll, maskIsNegative, maskIsNotNegative; // Note: Take a careful look at this loop indexing. This example // code is not guaranteed to work when (N % VECTOR_WIDTH) != 0. // Why is that the case? for (int i=0; i\u0026lt;N; i+=VECTOR_WIDTH) { // All ones maskAll = _cs149_init_ones(); // All zeros maskIsNegative = _cs149_init_ones(0); // Load vector of values from contiguous memory addresses _cs149_vload_float(x, values+i, maskAll); // x = values[i]; // Set mask according to predicate _cs149_vlt_float(maskIsNegative, x, zero, maskAll); // if (x \u0026lt; 0) { // Execute instruction using mask (\u0026#34;if\u0026#34; clause) _cs149_vsub_float(result, zero, x, maskIsNegative); // output[i] = -x; // Inverse maskIsNegative to generate \u0026#34;else\u0026#34; mask maskIsNotNegative = _cs149_mask_not(maskIsNegative); // } else { // Execute instruction (\u0026#34;else\u0026#34; clause) _cs149_vload_float(result, values+i, maskIsNotNegative); // output[i] = x; } // Write results back to memory _cs149_vstore_float(output+i, result, maskAll); } } 示例函数absVector并不能适用于所有情况,原因如下: 当n%VECTOR_WIDTH != 0时, 会越界.\n1\u0026amp;2 实现clampedExpVector函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 void clampedExpVector(float *values, int *exponents, float *output, int N) { // // CS149 STUDENTS TODO: Implement your vectorized version of // clampedExpSerial() here. // // Your solution should work for any value of // N and VECTOR_WIDTH, not just when VECTOR_WIDTH divides N // __cs149_vec_float one, nine; __cs149_vec_int zeroInt, oneInt; oneInt = _cs149_vset_int(1); zeroInt = _cs149_vset_int(0); one = _cs149_vset_float(1.f); nine = _cs149_vset_float(9.999999f); for (int i = 0; i \u0026lt; N; i += VECTOR_WIDTH) { __cs149_mask maskAll, maskIsZero, maskIsNotZero; __cs149_vec_float x; __cs149_vec_int y; // All ones maskAll = _cs149_init_ones(); // All zeros maskIsZero = _cs149_init_ones(0); // 防止在最后一次循环时，i+VECTOR_WIDTH超出N if (i + VECTOR_WIDTH \u0026gt; N) { maskAll = _cs149_init_ones(N - i); } // float x = values[i]; _cs149_vload_float(x, values + i, maskAll); // int y = exponents[i]; _cs149_vload_int(y, exponents + i, maskAll); // if (y == 0) _cs149_veq_int(maskIsZero, y, zeroInt, maskAll); // { // output[i] = 1.f; // } _cs149_vstore_float(output + i, one, maskIsZero); // else maskIsNotZero = _cs149_mask_not(maskIsZero); // 消除最后一次循环时，i+VECTOR_WIDTH超出N的情况 maskIsNotZero = _cs149_mask_and(maskIsNotZero, maskAll); { // float result = x; __cs149_vec_float result = x; // int count = y - 1; __cs149_vec_int count; _cs149_vsub_int(count, y, oneInt, maskIsNotZero); // 哪些count\u0026gt;0 __cs149_mask countMark; _cs149_vgt_int(countMark, count, zeroInt, maskIsNotZero); // while (count \u0026gt; 0) while (_cs149_cntbits(countMark) \u0026gt; 0) { // result *= x; _cs149_vmult_float(result, result, x, countMark); // count--; _cs149_vsub_int(count, count, oneInt, countMark); // 哪些count\u0026gt;0 _cs149_vgt_int(countMark, count, zeroInt, countMark); } // if (result \u0026gt; 9.999999f) __cs149_mask gtNineMask; _cs149_vgt_float(gtNineMask, result, nine, maskIsNotZero); // { reult = 9.999999f;} _cs149_vmove_float(result, nine, gtNineMask); // output[i] = result; _cs149_vstore_float(output + i, result, maskIsNotZero); } } } 通过init_ones来防止在有n%vectorWith!=0时 越界.\n在最开始的maskAll时设置 在取反码后也要设置一次 count循环: 通过设置一个mask来标记哪些count\u0026gt;0, 从而实现循环.\n修改vectorWidth为2, 4, 8, to 16来回答: Does the vector utilization increase, decrease or stay the same as VECTOR_WIDTH changes? Why?\nvectorWidth为2时, 结果如下: ****************** Printing Vector Unit Statistics ******************* Vector Width: 2 Total Vector Instructions: 162728 Vector Utilization: 77.0% Utilized Vector Lanes: 250653 Total Vector Lanes: 325456\nvectorWidth为4时, 结果如下: ****************** Printing Vector Unit Statistics ******************* Vector Width: 3 Total Vector Instructions: 119440 Vector Utilization: 72.2% Utilized Vector Lanes: 258879 Total Vector Lanes: 358320\nvectorWidth为8时, 结果如下: ****************** Printing Vector Unit Statistics ******************* Vector Width: 8 Total Vector Instructions: 51628 Vector Utilization: 66.0% Utilized Vector Lanes: 272539 Total Vector Lanes: 413024\nvectorWidth为16时, 结果如下: ****************** Printing Vector Unit Statistics ******************* Vector Width: 16 Total Vector Instructions: 26968 Vector Utilization: 64.2% Utilized Vector Lanes: 277188 Total Vector Lanes: 431488\n可以发现, 随着vectorWidth的增加, vectorUtilization也在减少.\n原因: 有多个条件语句,当vectorWidth增加时, 每次在某个条件中不执行的指令也会增加.\n3 实现arraySumVector 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 float arraySumVector(float *values, int N) { // // CS149 STUDENTS TODO: Implement your vectorized version of arraySumSerial here // __cs149_vec_float sum = _cs149_vset_float(0.f); for (int i = 0; i \u0026lt; N; i += VECTOR_WIDTH) { __cs149_mask maskAll; __cs149_vec_float x; // All ones maskAll = _cs149_init_ones(); // 防止在最后一次循环时，i+VECTOR_WIDTH超出N if (i + VECTOR_WIDTH \u0026gt; N) { maskAll = _cs149_init_ones(N - i); } // float x = values[i]; _cs149_vload_float(x, values + i, maskAll); // sum += x; _cs149_vadd_float(sum, sum, x, maskAll); } float result = 0.f; // log2(VECTOR_WIDTH)内解决 for (int i = 0; i \u0026lt; log2(VECTOR_WIDTH); i++) { // 使用_cs149_hadd_float函数，将sum中的每两个元素相加 // 再使用_cs149_interleave_float函数，将sum中的每两个元素交叉放置 // 重复log2(VECTOR_WIDTH)次 _cs149_hadd_float(sum, sum); _cs149_interleave_float(sum, sum); } // 将sum中的第一个元素赋值给result result = sum.value[0]; return result; } 假设VECTOR_WIDTHs始终是N的因子.\n可以实现在O(N/VECTOR_WIDTH + log2(VECTOR_WIDTH))的时间内完成计算.\n最后的log2实现方式. 提示中给了两个函数 hadd: 将每两个元素相加 interleave: 将每两个元素交叉放置\n因此我们可以类似与归并排序的方式,将sum中的每两个元素相加,再将每两个元素交叉放置. 重复log2(VECTOR_WIDTH)次后,第一个元素就是结果.\nprogram-3 前提: L3\n","permalink":"/en/posts/cmu-15418618/asst1-performance-analysis-on-a-quad-core-cpu/","summary":"参考 任务 提示: 需要先看CMU15-418/CS149的L2再完成Pro1 任务描述: 用多线程画mandelbrot fractal. 代码中给出了串行的实现, 你","title":""},{"content":"并行程序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void sinx(int N, int terms, float* x, float* result) { for (int i = 0; i \u0026lt; N; i++) { float value = x[i]; float number = x[i] * x[i] * x[i]; int sign = -1; int denom = 6; for (int j = 0; j \u0026lt; terms; j++) { value += sign * number / denom; sign *= -1; denom *= (2*j+3)*(2*j+2); number *= x[i] * x[i]; } result[i] = value; } } 转换成汇编后大致如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 ld r0, addr[r1] mul ri, r0, r0 mul r1, r1, r0 可以看到每次循环都是独立的。 对于最简单的是顺序执行。 通过超线程(超标量处理器具有从单个指令流中提取多个指令的能力)可以提高性能。有时称指令级并行性。(ILP, Instruction Level Parallelism) 但在这些汇编指令中必须顺序执行。 因此实现指令级并行性是一个挑战。 但即使是纯顺序执行的代码,也有很多方式使其运行更快(基于写代码的方式和编译器的智能程度). Pentium 4 比如先取多条指令等. (有个黑匣子会预测分支,预测错误的话就会清空流水线,浪费时间) 解决方法: 1. 通过pthread编写并行性的程序 2. 假设有一种语言可以表示并行性,编译器可以自动并行化程序 如: forall(int i from 0 to n-1){} 自动并行化可能的解决方法: 1. 直接分为k个线程,每个线程处理n/k个循环. 然后将结果合并 2. 在硬件上执行. 有一堆性能较低但具有并行性的处理器时, 也需要更多电力/时间来驱动很多信号从一端到另一端. ## CPU \u0026amp;\u0026amp; GPU GPU将核心的概念带到了极致, 抛弃了所有的分支预测, 只是控制逻辑而不完成计算. 对于上面的程序有垂直和水平两种分割方式: - 垂直: 每个线程处理一个循环 - 水平: 同时处理多个循环, 如先同时进行所有的第一个乘法... ## SIMD Single Instruction Multiple Data 假设我正在执行的多次操作之间没有依赖关系,都能够并行运行. a single instruction is applied to multiple data elements simultaneously. 即: 同时对8个数值和另一个地方的8个数值取出并进行加法. 有时这些数值可以被称作向量. 使用AVX intrinsics的向量化程序: ```c++ void sinx(int N, int terms, float* x, float* result) { for (int i = 0; i \u0026lt; N; i+=8) { __m256 origx = _mm256_load_ps(\u0026amp;x[i]); __m256 value = origx; __m256 number = _mm256_mul_ps(origx, _mm256_mul_ps(origx, origx)); float sign = -1; __m256 denom = _mm256_set1_ps(6); for (int j = 0; j \u0026lt; terms; j++) { //value += sign * number / denom; __m256 tmp = _mm256_div_ps(number, denom); tmp = _mm256_mul_ps(tmp, _mm256_set1_ps(sign)); value = _mm256_add_ps(value, tmp); sign *= -1; //denom *= (2*j+3)*(2*j+2); denom = _mm256_mul_ps(denom, _mm256_set1_ps((2*j+3)*(2*j+2))); //number *= x[i] * x[i]; number = _mm256_mul_ps(number, _mm256_mul_ps(origx, origx)); } _mm256_store_ps(\u0026amp;result[i], value); //result[i] = value; } } 编译成汇编后大致如下:\n1 2 3 4 5 6 7 vloadps xmm0, addr[r1] vmulps xmm1, xmm0, xmm0 vmulps xmm2, xmm1, xmm0 ... ... ... vstoreps addr[xmm2], xmm0 AVX代表高级矢量扩展, 256代表每次可以处理256位的数据, 也就是8个float. 有多个版本:\n1 2 3 AVX: 128位 = 4 * 4 * 8 = 32字节 AVX2: 256位 = 8 * 4 * 8 = 32字节 AVX512: 512位 = 16 * 4 * 8 = 64字节 XMM寄存器是特殊的32字节 256位寄存器, 有16个, 从xmm0到xmm15. 用于支持vectorized SIMD指令.\n那么有没有办法让编译器自动将代码向量化呢?\n有,GCC的-O3选项可以自动向量化代码. 但只有非常结构化,精心编写的代码才能被自动向量化.\n条件 如果加入条件判断,如何向量化?\n1 2 3 4 5 if(x \u0026lt; 0){ x = -x; }else{ x = x; } SIMD可能的做法: 设置一个掩码, 用于标记哪些元素需要执行哪些不需要执行.\n1 2 3 4 x \u0026lt; 0: 1 1 0 0 1 0 0 0 x = -x: 1 1 0 0 1 0 0 0 翻转: 0 0 1 1 0 1 1 1 x = x: 0 0 1 1 0 1 1 1 但大多时候只保留了一半的效率,因为每次有可能只有一半的数据需要执行. 不过这很好的保证了一致性,因为分支结束后又回到了同一个执行路径. 即保持一致性,远离分歧.\ncoherent execution: 所有的线程都执行相同的指令.\ndivergent: a lack of instruction stream coherence.\n对于生成这些矢量操作,要么有聪明的编译器,要么就是有耐心的程序员.\nSIMD execution on many modern GPUs SPMD: Single Program Multiple Data\nGPU给的不是SIMD,而是SPMD. 单个程序,多个数据. 意味着程序的不同部分可以执行不同的指令.\n在这之下,还是用SIMD来实现大部分逻辑,采用异构的方式来实现并行.\n但有n个加法, 即两个包含n个值的向量相加. 实际上不是所有单位都在等待计算.而是会先计算出如何分配到块中,底层块的实际大小是32, 32values而不是32byte. 这个被称作SIMD宽度,一般是8-32.\nGPU和CPU的差别 CPU i7:\n4核 8 SIMD ALUs per core 每秒大概几千次浮点运算 GPU: RTX 1080\n20 cores 32 SIMD ALUs per core 每秒大概8m次浮点运算 GPU的核心摒弃了分支预测等只用做control,因此可以有更多的ALU.填充进来.\n大概是80:1的原始计算能力差异.\n总结 三种方法实现并行计算\n多核CPU:\n线程级实现并行 SIMD:\n指令级并行 通过向量化指令实现 但依赖于事先知道执行的指令优先级顺序 Superscaler: exploit ILP within an instruction stream\npaart2 accessing memory Memory latency: 从CPU到内存的时间\nexample: DRAM访问时间 100 cycles, 100ns Memory bandwidth: 从内存到CPU的时间\nexample: 20GB/s 其实不是很快 Stall: CPU等待内存的时间 当cpu试图进行读取而内存不可用时，就会停等知道内存可用.\n缓存就是为了解决Stall的问题.\n在多级缓存中,靠近核心的缓存是私有的. 这样可以通过写入读出L2缓存的数据来实现通讯,而不需要经过DRAM.\n缓存对延迟和带宽都有帮助.\nPrefecthing reduces stalls 硬件通常通过预取来减少延迟. 即预测下一次可能会访问的数据,并将其提前读取到缓存中. 不过可能会造成信息泄露\n使用预取的效果: Multi-threading reduces stalls 让多个线程交替进行, 如asst1/prog2的实现\n这也是超线程的实现,在一个核心中多路复用多个指令流. 对于CPU\u0026amp;GPU, 谁来组织线程是不同的做法.(操作系统 or 硬件)\n通常情况下内存要比其他因素更加限制速度\n","permalink":"/en/posts/cmu-15418618/l2/","summary":"并行程序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void sinx(int N, int terms, float* x, float* result) { for (int i = 0; i \u0026lt; N; i++) { float value = x[i]; float number = x[i] * x[i] * x[i]; int sign = -1; int denom = 6; for (int j = 0; j \u0026lt; terms; j++) { value","title":"L2"},{"content":"Parallelism 加速比 Speed up 是指： 程序在单处理器上运行的时间 / 程序在多处理器上运行的时间\n我们一般会期望用两倍的硬件得到两倍的速度提升,但是实际上并不是这样的。\n制约性能提升可能的因素有:\n资源分配不均匀 通信开销 短板效应 共享资源读写冲突 为什么要去了解硬件？\n什么是限制性能的因素？ 导致性能瓶颈的原因是什么？ Efficiency fast != efficient\n什么是效率？ 尽可能地利用资源，减少浪费 比如按时间租用服务器。\n总结 并行程序的挑战：\n负载均衡 Load balance 通信延迟 Communication latency 集体工作时，真正用于计算的时间很少 ","permalink":"/en/posts/cmu-15418618/l1-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%92%8C%E9%AB%98%E6%95%88/","summary":"Parallelism 加速比 Speed up 是指： 程序在单处理器上运行的时间 / 程序在多处理器上运行的时间 我们一般会期望用两倍的硬件得到两倍的速度提升,但是实际上并不是这样的","title":"Why parallelism? Why efficiency?"},{"content":"光标移动 h: 左移一个字符 j: 下移一行 k: 上移一行 l: 右移一个字符\nw: 移动到下一个单词的开头 e: 移动到当前单词末尾 b: 移动到上一个单词的开头\n0: 移动到行首 $: 移动到行尾\nn + 上面的命令: 移动n次\ngg: 移动到文件开头 G: 移动到文件末尾\n上面所有命令构成了一个移动命令，可以和d命令组合使用，删除从当前光标到移动命令所指的位置的内容\nctrl + f: 下翻一页 ctrl + b: 上翻一页 ctrl + G: 显示当前光标所在行的行号\nctrl + i: 跳转到上次位置· ctrl + o: 跳转到下次位置\nG + n: 移动到第n行\n插入 i: 在当前光标处插入 I: 在当前行首插入\na: 在当前光标后插入 A: 在当前行尾插入\no: 在当前行下方插入一行 O: 在当前行上方插入一行\n删除 x: 删除当前光标所在的字符 X: 删除当前光标所在的前一个字符\ndd: 删除当前行 D: 删除当前光标所在位置到行尾的内容\nd + 移动命令: 删除从当前光标到移动命令所指的位置的内容\n如: dw: 删除当前光标所在的单词 db: 删除当前光标所在的单词 d$: 删除当前光标所在位置到行尾的内容 dnG: 删除当前光标所在行到第n行的内容 dG: 删除当前光标所在行到文件末尾的内容\n剪切 上面删除的内容都会被保存到剪切板中\n删除并进入插入模式 s: 删除当前光标所在的字符并进入插入模式 S: 删除当前行并进入插入模式\nc + 移动命令: 删除从当前光标到移动命令所指的位置的内容并进入插入模式\n如: cw: 删除当前光标所在的单词并进入插入模式 c$: 删除当前光标所在位置到行尾的内容并进入插入模式 cnG: 删除当前光标所在行到第n行的内容并进入插入模式\n复制 y + 移动命令: 复制从当前光标到移动命令所指的位置的内容\n如: yw: 复制当前光标所在的单词 yb: 复制当前光标所在的单词 y$: 复制当前光标所在位置到行尾的内容 ynG: 复制当前光标所在行到第n行的内容\n粘贴 所有删除的内容都会被保存到剪切板中，可以使用p命令将剪切板中的内容粘贴到当前光标所在位置 p: 将剪切板中的内容粘贴到当前光标所在位置的后面 P: 将剪切板中的内容粘贴到当前光标所在位置的前面\n替换 r + 字符: 将当前光标所在的字符替换为指定的字符\nR + 字符串: 将当前光标所在位置开始的字符串替换为指定的字符串\n撤销 u: 撤销上一次操作 U: 撤销当前行的所有操作\nctrl + r: 恢复上一次撤销的操作\n重复 . : 重复上一次操作\n查找 / + 关键字: 从当前光标开始向下查找关键字 ? + 关键字: 从当前光标开始向上查找关键字\n输完后按回车，会跳转到第一个匹配的位置.\nn: 跳转到下一个匹配的位置 N: 跳转到上一个匹配的位置\n: 进阶命令 :w 保存文件 :q 退出 :q! 强制退出，不保存 :wq 保存并退出 :wq! 强制保存并退出\n上面的命令 + 文件名: 保存文件到指定的文件名\n:help 命令名: 查看命令的帮助文档\n替换 :%s/old/new/g 将所有的old替换为new :%s/old/new/gc 将所有的old替换为new，替换前询问是否替换\n:#,#s/old/new/g 将第#行到第#行的old替换为new\n外部命令 :! + 命令: 执行外部命令\n如: :!ls 执行ls命令 :!dir 执行dir命令\n","permalink":"/en/posts/tools/vim/%E6%8C%87%E4%BB%A4%E6%89%8B%E5%86%8C/","summary":"光标移动 h: 左移一个字符 j: 下移一行 k: 上移一行 l: 右移一个字符 w: 移动到下一个单词的开头 e: 移动到当前单词末尾 b: 移动到上一个单词的开头 0: 移动到行首 $: 移","title":"vim的使用"},{"content":" ","permalink":"/en/posts/c++/modern-c++/","summary":"","title":"测试 blog2313"},{"content":"TL;DR 背景: 已使用nextcloud和typora写笔记 需求: 将笔记转换为博客.(且因为本人太懒,😂 所以需要全自动化) 在nextcloud中, 专门设置一个文件夹\u0026quot;笔记\u0026quot; 转换为博客文件夹 不能改变原来记笔记的方式 不能有任何新增的操作 方案: 使用hugo搭建博客 使用Github pages部署博客 使用Github Actions自动化部署 使用py脚本将笔记转换为博客 使用任务计划程序定时执行py脚本 使用hugo搭建博客 参考: hugo官网 Hugo+Github Pages+Github Action博客方案之二 Hugo+Github Pages+Github Action博客方案之三 PaperMod主题\n创建github仓库 要创建两个仓库\n一个仓库用于存放博客源码 一个仓库用于存放博客静态文件 创建博客静态文件仓库 设置仓库名为: 用户名.github.io 我的博客仓库\n创建博客源码仓库 设置仓库名为: hugo-blog // 仓库名可以自定义 我的博客源码仓库\n安装hugo 1 scoop install hugo 创建hugo博客 1 hugo new site hugo-blog 安装主题 1 2 3 4 cd hugo-blog ## 进入博客目录, 这个是博客源码仓库 git init git submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod git submodule update --init --recursive ## needed when you reclone your repo (submodules may not get cloned automatically) 配置主题 这里使用yaml格式的配置文件, 也可以使用toml格式的配置文件 所以需要删除config.toml文件, 并创建config.yaml文件\nconfig.yaml:\n1 2 3 4 baseURL: / title: ysyy\u0026#39;s blog theme: PaperMod languageCode: zh-cn 剩余配置参考\n创建文章 1 hugo new posts/first/hello-world.md 本地预览 1 hugo server -D 生成静态文件 生成静态文件, 生成的静态文件在 public文件夹中。 之后我们将这个文件夹中复制到博客静态文件仓库中\n1 hugo 部署到github pages 创建静态文件夹\n1 2 3 4 5 git clone git@用户名.github.io.git cd 用户名.github.io cp -r hugo-blog/public/* ./ 提交到github\n1 2 3 git add . git commit -m \u0026#34;first commit\u0026#34; git push origin main 配置github pages 在github中的 用户名.github.io仓库中, 点击 Settings选项卡, 找到 GitHub Pages选项, 将 Source选项设置为 main分支, 点击 Save按钮, 这样就可以通过 https://用户名.github.io访问博客了\n使用Github Actions自动化部署 参考\n如果每一次更新/发布新博客都需要手动执行上面的步骤, 那么就太麻烦了, 所以我们需要自动化部署\n在博客源码仓库的根目录下创建 .github/workflows/deploy.yml文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 name: ysyyblog on: push: branches: - main jobs: build-deploy: runs-on: ubuntu-20.04 # runs-on: macos-latest steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;latest\u0026#39; # extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: personal_token: ${{ secrets.PERSONAL_TOKEN }} # 另外还支持 deploy_token 和 github_token external_repository: ysyyhhh/ysyyhhh.github.io # 修改为你的 静态文件GitHub Pages 仓库 publish_dir: ./public # keep_files: false publish_branch: main # 如果使用自定义域名，还需要添加下面一行配置 # cname: www 创建personal_token 在github主页的右上角点击头像, 点击 Settings选项卡, 找到 Developer settings选项,\n找到 Personal access tokens选项, 点击 Generate new token按钮, 创建一个新的token\n配置personal_token 在hugo-blog仓库中, 点击 Settings选项卡, 找到 Secrets选项, 点击 New repository secret按钮,\n新增一个名为 PERSONAL_TOKEN的secret, 值为上面创建的personal_token\n测试自动化部署 在本地的hugo-blog仓库中, 修改 content/posts/first/hello-world.md文件, 然后提交到github\n可以在 Actions选项卡中查看自动化部署的状态\n如果在 Actions选项卡中看到了 build-deploy任务, 且状态为 success, 那么就说明自动化部署成功了\n可以在 用户名.github.io仓库中查看是否已经更新.\n使用任务计划程序和py脚本实现全自动化 上面的步骤已经让我们发布笔记的过程变成:\n使用hugo new / 直接编辑 content的文件 来创建笔记 提交到hugo-blog仓库 然后hugo-blog仓库就会自动部署到用户名.github.io仓库中\n虽然已经只剩两步了,但遵循能自动化就自动化的原则, 我们还是要把这两步也自动化\n使用py脚本将笔记转换为博客 安装python这些步骤就省去了,这里直接给出py脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 \u0026#39;\u0026#39;\u0026#39; 每天定时更新博客内容 1.进入项目根目录: D:/program_about/hugo/hugo-blog 2. 将D:/nextcloud/笔记/下的文件同步到 ./content/posts/下 3. 执行./push.bat 或 git add . \u0026amp;\u0026amp; git commit -m \u0026#34;update\u0026#34; \u0026amp;\u0026amp; git push \u0026#39;\u0026#39;\u0026#39; import os import shutil def create_index(root, name): \u0026#39;\u0026#39;\u0026#39; name = A.md 在root下生成\u0026#39;A\u0026#39;文件夹 将A.md移动到A文件夹下，并重命名为index.md 如果 存在 root + \u0026#39;/img\u0026#39; 的文件夹 将 root + \u0026#39;/img\u0026#39; 复制到 root + \u0026#39;/A/img\u0026#39; 下 \u0026#39;\u0026#39;\u0026#39; # 生成文件夹 dir_name = name.split(\u0026#39;.\u0026#39;)[0] print(root, name, dir_name) os.mkdir(os.path.join(root, dir_name)) # 移动文件 shutil.move(os.path.join(root, name), os.path.join(root, dir_name, \u0026#39;index.md\u0026#39;)) # 处理img if os.path.exists(os.path.join(root, \u0026#39;img\u0026#39;)): shutil.copytree(os.path.join(root, \u0026#39;img\u0026#39;), os.path.join(root, dir_name, \u0026#39;img\u0026#39;)) def adjust(dir): os.chdir(dir) \u0026#39;\u0026#39;\u0026#39; 将所有下面的格式 - A.md - img - A-1.png 转换成 - A - index.md - img - A-1.png 如果遇到\u0026#34;.md\u0026#34;文件,直接删除 \u0026#39;\u0026#39;\u0026#39; for(root, dirs, files) in os.walk(\u0026#34;.\u0026#34;): root = os.path.join(dir, root) for name in files: if name == \u0026#39;.md\u0026#39;: os.remove(os.path.join(root, name)) continue if name.endswith(\u0026#39;.md\u0026#39;): create_index(root, name) for name in dirs: # 递归调用 adjust(os.path.join(root, name)) def sync(): root_path = \u0026#39;D:/program_about/hugo/hugo-blog\u0026#39; os.chdir(root_path) # 当文件已存在时，无法创建该文件。: \u0026#39;./content/posts/\u0026#39; shutil.rmtree(\u0026#39;./content/posts/\u0026#39;) # git中也要删除 os.system(\u0026#39;git rm -r ./content/posts/\u0026#39;) shutil.copytree(\u0026#39;D:/nextcloud/笔记/\u0026#39;, \u0026#39;./content/posts/\u0026#39;) # 把所有文件夹和文件的名称大写转换为小写 os.chdir(\u0026#39;./content/posts/\u0026#39;) for root, dirs, files in os.walk(\u0026#34;.\u0026#34;): for name in files: new_name = name.lower() os.rename(os.path.join(root, name), os.path.join(root, new_name)) for name in dirs: new_name = name.lower() os.rename(os.path.join(root, name), os.path.join(root, new_name)) # 调整文件夹结构 adjust(root_path+\u0026#39;./content/posts/\u0026#39;) # 上传到git # os.chdir(\u0026#39;./content/posts/\u0026#39;) os.chdir(\u0026#39;D:/program_about/hugo/hugo-blog\u0026#39;) os.system(\u0026#39;git add ./content/posts/\u0026#39;) os.system(\u0026#39;git commit -m \u0026#34;update\u0026#34;\u0026#39;) os.system(\u0026#39;git push\u0026#39;) os.chdir(\u0026#39;D:/program_about/hugo/hugo-blog\u0026#39;) print(\u0026#39;sync done\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: sync() 将上面的路径修改为自己的路径, 然后保存为 sync.py文件 可以执行py脚本,测试一下\n关于图片路径问题 参考方案\n因为我平时的图片路径是\n1 2 3 - A.md - img - A-1.png 但是hugo会将A.md文件转换为A文件夹, 所以此时是无法访问A-1.png的.\n这里是通过改变相对路径关系来解决的, 即代码中的adjust()\n当然如果你有图床就不需要这么麻烦了\n使用任务计划程序定时执行py脚本 参考 这里我使用的是win10自带的任务计划程序, 其他系统的任务计划程序也是类似的\n以下步骤由Claude生成\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 下面是如何使用Windows任务计划程序来配置定时每天执行Python脚本的步骤: 打开任务计划程序(Windows + R 输入taskschd.msc回车) 点击\u0026#34;操作\u0026#34;栏中的\u0026#34;创建基本任务\u0026#34; 输入任务名称,选择触发器为每天定时,设置执行时间 在操作栏中,点击“新建” 选择“启动一个程序” 在“程序/脚本”框中输入Python解释器的路径,例如C:\\Python37\\python.exe 在“添加参数(可选)”中输入python脚本文件的完整路径,例如C:\\Users\\username\\script.py 点击“确定”保存此操作 在下一页中选择用户账号,例如“当前用户” 点击“确定”完成创建任务 根据需要配置触发器记录和其他选项 点击“确定”保存任务 任务将在设定的时间自动执行python脚本文件 每次修改脚本后需要停止原有任务,然后再新建一个相同的任务来加载修改后的脚本代码。 需要注意python interpreter路径和脚本路径的正确性。定时执行格式也需要正确,这样就可以实现Windows系统中的自动定时任务执行Python脚本了。 ","permalink":"/en/posts/tools/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","summary":"TL;DR 背景: 已使用nextcloud和typora写笔记 需求: 将笔记转换为博客.(且因为本人太懒,😂 所以需要全自动化) 在nextcloud中, 专","title":"用Hugo + Github Pages/Action + py + 任务计划程序 搭建 全自动化markdown笔记转博客"},{"content":"","permalink":"/en/search/","summary":"","title":""}]