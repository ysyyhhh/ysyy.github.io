[{"content":"无法连接 Q:\nopenai.error.APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host=\u0026#39;api.openai.com\u0026#39;, port=443): Max retries exceeded with url: /v1/chat/completions (Caused by ProxyError(\u0026#39;Unable to connect to proxy\u0026#39;, SSLError(SSLZeroReturnError(6, \u0026#39;TLS/SSL connection has been closed (EOF) (_ssl.c:1131)\u0026#39;)))) A:\n问题出在模块 urllib3 的版本，报错的是 1.26.3，没报错的是 1.25.11 在原报错环境中使用下面命令重装低版本 urllib3： pip install urllib3==1.25.11 然后测试果然就没问题了。 ","permalink":"/posts/qa/python/openai/","summary":"无法连接 Q: openai.error.APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host=\u0026#39;api.openai.com\u0026#39;, port=443): Max retries exceeded with url: /v1/chat/completions (Caused by ProxyError(\u0026#39;Unable to connect to proxy\u0026#39;, SSLError(SSLZeroReturnError(6, \u0026#39;TLS/SSL connection has been closed (EOF) (_ssl.c:1131)\u0026#39;)))) A: 问题出在模块 urllib3 的版本，报错的是 1.26.3，没报错的是 1.25.11 在原报错环境中使","title":"openai 相关QA"},{"content":"markdown 快捷键 删除线: alt + s\n待办事项勾选/取消勾选: alt + c\nterminal 命令行创建: Ctrl + Shift + ~\n命令行切换: Ctrl + fn + upArrow/downArrow\nview Run Run python file in terminal: Ctrl + F5\n","permalink":"/posts/tools/vscode%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%85%A8/","summary":"markdown 快捷键 删除线: alt + s 待办事项勾选/取消勾选: alt + c terminal 命令行创建: Ctrl + Shift + ~ 命令行切换: Ctrl + fn + upArrow/downArrow view Run Run python file in terminal: Ctrl + F5","title":"工作学习流(vscode快捷键)"},{"content":"git 常用命令 git 基本配置 git config --global user.name \u0026#34;your name\u0026#34; git config --global user.email \u0026#34;your email\u0026#34; git 基本操作 git init # 初始化仓库 git add . # 添加所有文件到暂存区 git commit -m \u0026#34;commit message\u0026#34; # 提交到本地仓库 git remote add origin git push -u origin master # 推送到远程仓库 git pull origin master # 拉取远程仓库 git clone # 克隆远程仓库 git status # 查看当前状态 git log # 查看提交日志 git diff # 查看修改内容 git branch # 查看分支 git checkout -b branch_name # 创建并切换到新分支 git checkout branch_name # 切换分支 git merge branch_name # 合并分支 git branch -d branch_name # 删除分支 git reset --hard HEAD^ # 回退到上一个版本 git reset --hard commit_id # 回退到指定版本 git reflog # 查看命令历史 git rm file_name # 删除文件 git stash # 暂存当前修改 git stash list # 查看暂存列表 git stash apply # 恢复暂存 git stash drop # 删除暂存 git stash pop # 恢复并删除暂存 git remote -v # 查看远程仓库地址 git remote set-url origin new_url # 修改远程仓库地址 git push origin --delete branch_name # 删除远程分支 git push origin :branch_name # 删除远程分支 git tag # 查看标签 git tag tag_name # 创建标签 git tag tag_name commit_id # 指定提交创建标签 git tag -a tag_name -m \u0026#34;tag message\u0026#34; # 创建带有说明的标签 git tag -d tag_name # 删除标签 git push origin tag_name # 推送标签到远程 git push origin --tags # 推送所有标签到远程 git push origin :refs/tags/tag_name # 删除远程标签 git push origin --delete tag tag_name # 删除远程标签 git checkout -- file_name # 撤销工作区修改 git reset HEAD file_name # 撤销暂存区修改 git reset --hard HEAD^ # 撤销本地提交 git reset --hard commit_id # 撤销本地提交 git config --global alias.st status # 设置别名 git config --global alias.co checkout # 设置别名 git config --global alias.ci commit # 设置别名 git config --global alias.br branch # 设置别名 git config --global alias.unstage \u0026#39;reset HEAD\u0026#39; # 设置别名 git config --global alias.last \u0026#39;log -1\u0026#39; # 设置别名 git config --global alias.lg \u0026#34;log --color --graph --pretty=format:\u0026#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)\u0026lt;%an\u0026gt;%Creset\u0026#39; --abbrev-commit\u0026#34; # 设置别名 git 子模块 git submodule add # 添加子模块 git submodule init # 初始化子模块 git submodule update # 更新子模块 git submodule foreach git pull # 更新所有子模块 # 删除子模块 # 1. 删除.gitmodules中对应子模块的条目 # 2. 删除.git/config中对应子模块的条目 # 3. 执行git rm --cached path/to/submodule # 4. 执行rm -rf .git/modules/path/to/submodule # 5. 执行rm -rf path/to/submodule �����������������������������������������\n","permalink":"/posts/tools/git/git/","summary":"git 常用命令 git 基本配置 git config --global user.name \u0026#34;your name\u0026#34; git config --global user.email \u0026#34;your email\u0026#34; git 基本操作 git init # 初始化仓库 git add . # 添加所有文件到暂存区 git commit -m \u0026#34;commit message\u0026#34; # 提交到本地仓库 git remote add origin git push -u origin","title":"git"},{"content":"打包 mvn clean package -Dmaven.test.skip=true 常见问题 找不到主类 Error: Could not find or load main class com.xxx.xxx.xxx Caused by: java.lang.ClassNotFoundException: com.xxx.xxx.xxx 解决方法：在pom.xml中添加如下配置\n","permalink":"/posts/tools/maven/maven/","summary":"打包 mvn clean package -Dmaven.test.skip=true 常见问题 找不到主类 Error: Could not find or load main class com.xxx.xxx.xxx Caused by: java.lang.ClassNotFoundException: com.xxx.xxx.xxx 解决方法：在pom.xml中添加如下配置","title":"maven"},{"content":"nginx安装 1. 安装依赖 yum install -y gcc gcc-c++ autoconf automake make yum install -y pcre pcre-devel yum install -y zlib zlib-devel yum install -y openssl openssl-devel 2. 转发后端图片 # 1. 创建目录 mkdir -p /data/nginx/cache # 2. 修改目录权限 chown -R nginx:nginx /data/nginx/cache ","permalink":"/posts/tools/nginx/nginx/","summary":"nginx安装 1. 安装依赖 yum install -y gcc gcc-c++ autoconf automake make yum install -y pcre pcre-devel yum install -y zlib zlib-devel yum install -y openssl openssl-devel 2. 转发后端图片 # 1. 创建目录 mkdir -p /data/nginx/cache # 2. 修改目录权限 chown -R nginx:nginx /data/nginx/cache","title":"nginx"},{"content":"常用命令 # 连接 mongosh ip[:port]/database -u username -p password # 查看数据库 show dbs # 切换数据库 use database # 查看集合 show collections # file # 查看集合数据 db.{collection}.find() # 按条件查看集合数据 ## pid=1 db.{collection}.find({pid:1}) ## 限制4条 db.{collection}.find().limit(4) ## 只显示其中一个字段 db.{collection}.find({}, {name:1}) ## 统计数量 db.{collection}.find().count() ## 全部删除 db.{collection}.remove({}) ## 插入或更新数据 ","permalink":"/posts/tools/sql/mongodb/","summary":"常用命令 # 连接 mongosh ip[:port]/database -u username -p password # 查看数据库 show dbs # 切换数据库 use database # 查看集合 show collections # file # 查看集合数据 db.{collection}.find() # 按条件查看集合数据 ## pid=1 db.{collection}.find({pid:1}) ## 限制4条 db.{collection}.find().limit(4) ## 只显示其","title":"mongoDB"},{"content":"一、什么是I/O模型 及 I/O模型的分类 二、I/O 多路复用 三、实际应用 Reactor模式 Proactor模式 事件驱动模式 ","permalink":"/posts/knowledge/%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%BC%96%E7%A8%8B/io%E6%A8%A1%E5%9E%8B/","summary":"一、什么是I/O模型 及 I/O模型的分类 二、I/O 多路复用 三、实际应用 Reactor模式 Proactor模式 事件驱动模式","title":"I/O模型"},{"content":"系统资源相关 # 查看内存 free -h # 查看cpu cat /proc/cpuinfo # 查看cpu使用情况 top # 查看GPU使用情况 nvidia-smi # 查看磁盘 df -h # 查看系统版本 cat /etc/os-release # 查看系统信息 uname -a 用户相关 # 创建用户 useradd -m -s /bin/bash -d /home/username username ## 解释: -m 创建用户目录, -s 指定shell, -d 指定用户目录 # 设置密码 passwd username # 删除用户 userdel -r username # 添加用户的sudo权限 ## 编辑sudoers文件 vi /etc/sudoers ## 在root ALL=(ALL) ALL下面添加 username ALL=(ALL) ALL # 查看用户组 groups username # 修改用户组 usermod -g groupname username # 查看所有用户 cat /etc/passwd 目录挂载 # 查看挂载 df -h # 挂载目录 mount /dev/sdb1 /home/username/data # 卸载目录 umount /home/username/data # 挂载硬盘 ## 查看硬盘 fdisk -l ## 格式化硬盘 fdisk /dev/sdb ## 格式化为ext4 mkfs.ext4 /dev/sdb1 挂载目录并立即生效\n# 挂载目录 mount /dev/sdb1 /home/username/data # 立即生效 mount -a 文件 # 带权限复制 cp -rp source dest 工具 curl # 下载文件 curl -o filename url 系统路径/变量 持久化添加/改变系统路径/变量\n# 添加到系统路径 echo \u0026#39;export PATH=$PATH:/home/username/bin\u0026#39; \u0026gt;\u0026gt; /etc/profile # 立即生效 source /etc/profi\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 ","permalink":"/posts/tips/linux/","summary":"系统资源相关 # 查看内存 free -h # 查看cpu cat /proc/cpuinfo # 查看cpu使用情况 top # 查看GPU使用情况 nvidia-smi # 查看磁盘 df -h # 查看系统版本 cat /etc/os-release # 查看系统信息 uname -a 用户","title":"Linux"},{"content":"# 查看环境 conda env list # 创建环境 conda create -n py3 python=3.6 # 通过yml文件创建环境 conda env create -f environment.yml # 激活环境 conda activate py3 # 退出环境 conda deactivate # 删除环境 conda remove -n py3 --all 迁移时可能会出现pip问题 可以在yml的pip:上面加上pip\nname: py3 channels: - defaults dependencies: - python=3.6 - pip - pip: - -r requirements.txt ","permalink":"/posts/tools/python/conda/","summary":"# 查看环境 conda env list # 创建环境 conda create -n py3 python=3.6 # 通过yml文件创建环境 conda env create -f environment.yml # 激活环境 conda activate py3 # 退出环境 conda deactivate # 删除环境 conda remove -n py3 --all 迁移时可能会出现pi","title":"conda"},{"content":"记把深度学习项目装入docker 安装时出现选项\n# RUN apt-get install libglib2.0-dev -y # 由于安装libglib2.0-dev的时候，bash会有交互操作叫你选择对应的时区，在docker build的时候没有交互的，所以需要加上DEBIAN_FRONTEND=\u0026#34;noninteractive\u0026#34; RUN DEBIAN_FRONTEND=\u0026#34;noninteractive\u0026#34; apt -y install libglib2.0-dev docker清理 在win10下，docker是基于wsl2的，所以docker的镜像和容器都是在wsl2的文件系统中。 所以在清理完docker的镜像和容器后，需要对wsl的盘进行压缩。\n# 停止所有的容器 docker stop $(docker ps -aq) # 删除所有未使用的容器 docker volume prune # 删除所有未使用的镜像 docker image prune -a # 删除缓存 docker builder prune # 查看当前占用的空间 docker system df 对wsl2的盘进行压缩\nwsl --shutdown # 查看wsl2的盘 wsl --list -v # 使用diskpart压缩 diskpart # open window Diskpart select vdisk file=\u0026#34;D:\\ubuntu\\wsl\\docker-desktop-data\\ext4.vhdx\u0026#34; attach vdisk readonly compact vdisk detach vdisk exit docker中安装conda # 安装conda RUN apt-get install -y wget # yhyu13 : donwload anaconda package \u0026amp; install RUN wget \u0026#34;https://repo.anaconda.com/archive/Anaconda3-2023.03-1-Linux-x86_64.sh\u0026#34; RUN sh Anaconda3-2023.03-1-Linux-x86_64.sh -b -p /opt/conda # RUN rm /anaconda.sh RUN ln -s /opt/conda/etc/profile.d/conda.sh /etc/profile.d/conda.sh RUN echo \u0026#34;. /opt/conda/etc/profile.d/conda.sh\u0026#34; \u0026gt;\u0026gt; ~/.bashrc # yhyu13 : add conda to path ENV PATH /opt/conda/bin:/opt/conda/condabin:$PATH docker-compose 使用gpu version: \u0026#39;3.7\u0026#39; services: pytorch: build: . runtime: nvidia environment: - NVIDIA_VISIBLE_DEVICES=all - NVIDIA_DRIVER_CAPABILITIES=all volumes: - .:/workspace ports: - \u0026#34;8888:8888\u0026#34; - \u0026#34;6006:6006\u0026#34; command: bash -c \u0026#34;jupyter notebook --ip wsl 盘迁移到非系统盘 一般情况下 wsl盘的位置在 C:\\Users\\\u0026lt;用户名\u0026gt;\\AppData\\Local\\Docker\\wsl\ndocker的盘在 C:\\Users\\\u0026lt;用户名\u0026gt;\\AppData\\Local\\Docker\\wsl\\data\n# 1. 停止wsl wsl --shutdown # 2. 查看wsl状态 wsl --list -v # 可以看到docker有两个wsl，一个是docker-desktop-data，一个是docker-desktop # 只需要迁移docker-desktop-data即可,另一个很小 # 3. 迁移wsl wsl --export Ubuntu-20.04 D:\\ubuntu\\wsl\\Ubuntu-20.04.tar # 4. 删除wsl wsl --unregister Ubuntu-20.04 # 5. 查看是否删除成功 wsl --list -v # 6. 导入wsl wsl --import Ubuntu-20.04 D:\\ubuntu\\wsl\\Ubuntu-20.04 D:\\ubuntu\\wsl\\Ubuntu-20.04.tar --version 2 # 7. 查看是否导入成功 wsl --list -v docker 中设置特定版本的python # 创建一个基础镜像 FROM ubuntu:20.04 # 重置apt-get RUN rm -rf /etc/apt/sources.list # 安装conda # yhyu13 : install additional packages # 设置apt的源为tsinghua镜像源 RUN sed -i \u0026#39;s/archive.ubuntu.com/mirrors.tuna.tsinghua.edu.cn/g\u0026#39; /etc/apt/sources.list RUN apt-get update \u0026amp;\u0026amp; apt-get install -y curl wget # 安装conda RUN curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh \\ \u0026amp;\u0026amp; bash Miniconda3-latest-Linux-x86_64.sh -b -p /opt/conda \\ \u0026amp;\u0026amp; rm Miniconda3-latest-Linux-x86_64.sh # 创建conda环境并安装python RUN /opt/conda/bin/conda create -n py38 python=3.8.5 ENV PATH /opt/conda/envs/py38/bin:$PATH docker中使用display 在启动时需要设置环境变量DISPLAY\nwin下的情况 参考在Docker for Windows中运行GUI程序\n前后端项目静态资源转发 后端 springboot时： 把静态资源放在static目录下，然后在application中配置\nspring: mvc: static-path-pattern: /static/** resources: static-locations: classpath:/static/ 如果设置了拦截器，需要在拦截器上加入\n@Configuration public class WebMvcConfig implements WebMvcConfigurer { @Bean public CorsInterceptor corsInterceptor() { return new CorsInterceptor(); } @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(corsInterceptor()) .addPathPatterns(\u0026#34;/**\u0026#34;); } @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\u0026#34;/static/**\u0026#34;).addResourceLocations(\u0026#34;classpath:/static/\u0026#34;, \u0026#34;file:static/\u0026#34;); } } jar 包和静态路径关系\n- .jar - static 前端，需要在nginx上加入转发后访问静态路径后缀。\nlocation /api { rewrite ^/api(.*) $1 break; proxy_pass $SERVER_URL; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Photo $scheme; location ~*.+\\.(jpg|jpeg|gif|png|ico|css|js|pdf|txt|swf|xml|woff|woff2|ttf|eot|svg)$ { rewrite ^/api(.*) $1 break; proxy_pass $SERVER_URL; proxy_redirect off; } } ","permalink":"/posts/tips/docker/","summary":"记把深度学习项目装入docker 安装时出现选项 # RUN apt-get install libglib2.0-dev -y # 由于安装libglib2.0-dev的时候，bash会有交互操作叫你选择对应的时","title":"docker相关技巧"},{"content":"安装docker sudo apt -y update sudo apt -y upgrade sudo apt -y full-upgrade # 安装依赖 sudo apt install -y apt-transport-https ca-certificates curl software-properties-common gnupg lsb-release # 添加官方GPG密钥 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg #添加仓库 echo \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\u0026#34; | sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null # 更新apt sudo apt -y update # 安装docker sudo apt install docker-ce docker-ce-cli containerd.io docker-compose-plugin # 安装docker-compose sudo apt install docker-compose 1.镜像相关 # 拉取镜像 docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] # 查看镜像 docker images [选项] [仓库名] # 删除镜像 docker rmi [选项] \u0026lt;镜像1\u0026gt; [\u0026lt;镜像2\u0026gt; ...] # 查看镜像历史 docker history [选项] \u0026lt;镜像名\u0026gt; # 查看镜像详细信息 docker inspect [选项] \u0026lt;镜像名\u0026gt; 2.容器相关 # 创建容器 docker run [选项] \u0026lt;镜像名\u0026gt; [命令] #eg: docker run -d -p 8080:8080 --name tomcat tomcat:8.5.51 #选项 # -d 后台运行容器，并返回容器ID # -i 以交互模式运行容器，通常与 -t 同时使用 # -t 为容器重新分配一个伪输入终端，通常与 -i 同时使用 # -P 随机端口映射 # -p 指定端口映射，格式为：主机(宿主)端口:容器端口 # --name 指定容器名字 # --link 连接到其它容器 # --rm 容器退出后自动删除容器文件 # --volumes-from 从其它容器或数据卷挂载一些配置或其它文件 # --volume 挂载宿主机目录或文件，格式为：主机目录:容器目录 # --privileged=true 给容器内的root用户赋予最高权限，容器内的root用户就拥有了真正的root权限 # --restart # no 容器退出时不重启 # on-failure[:max-retries] 容器故障退出（返回值非零）时重启，最多重启max-retries次 # always 容器退出时总是重启 # unless-stopped 容器退出时总是重启，但是不考虑在Docker守护进程启动时就已经停止了的容器 # --env-file 从指定文件读入环境变量 # eg: # docker run -d -p 8080:8080 --name tomcat tomcat:8.5.51 --env-file ./env.list # 查看容器 docker ps [选项] # 删除容器 docker rm [选项] \u0026lt;容器名\u0026gt; # 启动容器 # 启动和创建容器的区别在于，启动容器是针对已经创建好的容器进行启动，而创建容器则是针对镜像进行的操作 docker start [选项] \u0026lt;容器名\u0026gt; # 停止容器 docker stop [选项] \u0026lt;容器名\u0026gt; # 查看容器日志 docker logs [选项] \u0026lt;容器名\u0026gt; # 查看容器内进程 docker top [选项] \u0026lt;容器名\u0026gt; # 查看容器详细信息 docker inspect [选项] \u0026lt;容器名\u0026gt; # 进入容器 docker exec [选项] \u0026lt;容器名\u0026gt; [命令] # 导出容器 docker export [选项] \u0026lt;容器名\u0026gt; # 导入容器 docker import [选项] \u0026lt;容器名\u0026gt; # 重命名容器 docker rename [选项] \u0026lt;容器名\u0026gt; \u0026lt;新容器名\u0026gt; # 查看容器使用的资源 docker stats [选项] \u0026lt;容器名\u0026gt; # 查看容器端口映射 docker port [选项] \u0026lt;容器名\u0026gt; # 导出容器中的文件 docker cp [选项] \u0026lt;容器名\u0026gt;:\u0026lt;容器内路径\u0026gt; \u0026lt;宿主机路径\u0026gt; # 选项: -a, --archive=false # 归档模式(默认) # -L, --follow-link=false # 总是解析符号链接 # -d, --device=false # 复制字符和块设备 # -r, --recursive=false # 递归复制整个目录 # -p, --pause=true # 暂停容器中的所有进程 docker 检查与排错 docker logs [选项] \u0026lt;容器名\u0026gt; # 选项: -f, --follow=false # 跟踪日志输出 # --since=\u0026#34;\u0026#34; # 显示自某个timestamp之后的日志，或相对时间，如42m（即42分钟） # --tail=\u0026#34;all\u0026#34; # 从日志末尾显示多少行日志， 默认是all # -t, --timestamps=false # 显示时间戳 # --until=\u0026#34;\u0026#34; # 显示自某个timestamp之前的日志，或相对时间，如42m（即42分钟） # 查看容器占用 docker stats [选项] \u0026lt;容器名\u0026gt; # 选项: --all=false # 显示所有容器（默认显示运行中的容器） # --format=\u0026#34;\u0026#34; # 使用Go模板显示 # --no-stream=false # 不显示实时流容器的统计信息 # --no-trunc=false # 不截断输出 # 停止所有容器 docker stop $(docker ps -a -q) # 移除所有容器 docker rm $(docker ps -a -q) # 移除所有镜像 docker image rmi $(docker images -q) # 清空docker中所有的东西 docker system prune -a # 清空缓存 docker system prune -f # 清空未使用的镜像 docker image prune -a # 清空未使用的容器 docker container prune # 清空未使用的卷 docker volume prune # 清空未使用的网络 docker network prune # 清空未使用的构建缓存 docker builder prune # 清空未使用的数据 docker system prune -a --volumes # 清空所有未使用的数据 docker system prune -a --volumes --force docker submodule # 获取子模块 git submodule update --init --recursive docker-compose # 启动命令 docker-compose up [选项] [服务名] # 选项 # -d 后台运行 # --build 构建镜像 # --force-recreate 强制重新创建容器 # --no-deps 不启动依赖的服务 # --no-recreate 不重新创建容器 ` ","permalink":"/posts/tools/docker/docker%E5%91%BD%E4%BB%A4/","summary":"安装docker sudo apt -y update sudo apt -y upgrade sudo apt -y full-upgrade # 安装依赖 sudo apt install -y apt-transport-https ca-certificates curl software-properties-common gnupg lsb-release # 添加官方GPG密钥 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg #添加仓库 echo \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\u0026#34; | sudo","title":"Docker命令"},{"content":"ISPC language SPMD: Single Program Multiple Data 一种花哨的方式来说，就是一种并行编程的范式，它的特点是：在编程时，我们只需要写一个程序，然后在运行时，这个程序会被复制多份，每一份都会被分配到不同的处理器上去执行，这样就实现了并行。\n用ISPC实现sinx\nexport void sinx(uniform int N, uniform int terms,uniform float* x, uniform float* result){ //assume N % programCount == 0 for (uniform int i = 0; i \u0026lt; N;i += programCount){ int idx = i + programIndex; float value = x[idx]; float number = value * value * value; uniform int denom = 6; uniform int sign = -1; for (uniform int j = 0; j \u0026lt; terms; j++){ value += sign * number / denom; number *= value * value; denom *= (2 * j + 3) * (2 * j + 2); sign *= -1; } result[idx] = value; } } 使用C++来调用 调用ISPC的东西是个程序实例的集合, gang.\n#include \u0026lt;iostream\u0026gt; #include \u0026#34;sinx.ispc.h\u0026#34; int N = 1000000; int terms = 10; float* x = new float[N]; float* result = new float[N]; //init x //execute ispc::sinx(N,terms,x,result); ispc中不需要手动设置programCount,programIndex\nprogramCount: number of simultaneous program instances in the gang (uniform value)\nprogramIndex: id of the current program instance in the gang(a non-uniform value)\nuniform value: 一个值在gang中的所有实例中都是一样的\n如果在ispc中直接使用sinx 并不会更快.\n因为有一些相同的工作会被重复做很多次. 通过分离他们,可以减少重复计算的次数,从而提高效率.\n一个设想的实现方法如下: ISPC是为了更容易编写SIMD代码而设计的, 只需要通过特殊的宏或编译指示就可以使用SIMD指令.\nprogramCount 就是 向量宽度\nSPMD programming abstraction\nISPC compiler generates SIMD implementation\nversion2版本的代码,这是分块进行而不是交错的.\nexport void sinx(uniform int N, uniform int terms,uniform float* x, uniform float* result){ uniform int count = N / programCount; int start = programIndex * count; //assume N % programCount == 0 for (uniform int i = 0; i \u0026lt; count;i += 1){ int idx = start + i; float value = x[idx]; float number = value * value * value; uniform int denom = 6; uniform int sign = -1; for (uniform int j = 0; j \u0026lt; terms; j++){ value += sign * number / denom; number *= value * value; denom *= (2 * j + 3) * (2 * j + 2); sign *= -1; } result[idx] = value; } } 交错通常比分块更好,因为分块会导致数据的访问不连续. 当计算量不均匀时,分块会导致一些处理器的负载过重,而另一些处理器的负载过轻.\n并且因为是同时进行的, 交错可以访问邻近的数据,这样可以增加cache的命中率.\n根本原因: 矢量加载指令(寄存器)是一次加载多个数据,如果在很短的时间内,要加载的数据是连续的,那么就可以一次加载多个数据,如果数据是不连续的,那么就需要多次加载,这样就会降低效率. 如果有个聪明的编译器,它可以自动将分块的代码转换为交错的代码,这样就可以兼顾两者的优点.\nforeach就可以实现这个功能,让程序员不需要关心这些细节.\nexport void sinx(uniform int N, uniform int terms,uniform float* x, uniform float* result){ foreach(i = 0 ... N){ float value = x[i]; float number = value * value * value; uniform int denom = 6; uniform int sign = -1; for (uniform int j = 0; j \u0026lt; terms; j++){ value += sign * number / denom; number *= value * value; denom *= (2 * j + 3) * (2 * j + 2); sign *= -1; } result[i] = value; } } ISPC的错误例子:\nexport uniform float sumall(uniform int N, uniform float* x){ uniform float sum = 0; foreach(i = 0 ... N){ sum += x[i]; } return sum; } 错误:编译器会报错,因为sum是一个uniform value,它在所有的实例中都是一样的,但是在foreach中,每个实例都会对sum进行修改,这样就会导致错误.\n修正这个错误:\nexport uniform float sumall(uniform int N, uniform float* x){ uniform float sum = 0; float partial_sum = 0; foreach(i = 0 ... N){ partial_sum += x[i]; } sum = reduce_add(partial_sum); return sum; } reduce_add原语: 允许将一组不同的值合并为一个值,这个值在所有的实例中都是一样的.\n编译后的细节 ISPC tasks: 基本上就是一个线程,但是它可以被分配到不同的处理器上去执行.\n三种并行编程范式 和 三种 machine architecture 聚焦于 communication 和 cooperation\n使用pthread时要call operate system 而在ISPC中,只需要call compiler\nThree models of communication(abstraction) 1.Shared address space asst3中会用到\n多个线程之间通过互斥锁来进行通信\n在硬件中, Dance-hall model 所有处理器在同一侧.\nSymmetric Multiprocessor(SMP) system 就是如此\n最简单的方式是总线, 但这样无法扩展,因为总线的带宽是有限的. 但实际中: 还有一种访问本地内存的方式,就是通过cache,这样就可以减少对总线的访问,从而提高效率. Non-Uniform Memory Access(NUMA) system 但它为程序员引入的复杂性是很大的,因为程序员需要手动的将数据放到本地内存中,这样才能提高效率.\nshared address space的优点:\n程序员不需要关心数据的传输 程序员不需要关心数据的分布 2.Message passing aasst4中会用到\n由于实现缓存一致性需要额外的成本，因此在大型系统中，共享内存的实现是不可行的。在这种情况下，消息传递是一种更好的选择。\n在消息传递中，每个处理器都有自己的私有内存，而且没有共享内存。要在处理器之间传递数据，必须使用显式的消息传递原语。\n不需要任何硬件支持，因此可以在任何系统上实现。只需要网络。\n可以构建大型系统，因为没有共享内存的限制。\n这些原语允许程序员在处理器之间传递数据，但是程序员必须显式地指定数据的传输。这种方式的缺点是，程序员需要关心数据的传输，这样就会增加程序员的负担。\n3.Data parallel asst2中会用到\n上面两种方式可以在任何硬件上实现。\nData parallel对程序员来说是最简单的，因为程序员不需要关心数据的传输，也不需要关心数据的分布。但是，它只能在特定的硬件上实现，因为它需要硬件支持。\n过去我们使用SIMD，现在使用SPMD。\n并行程序的问题\n这样的并行会得到不确定的结果。\n那么如何有原则性地使用并行呢？\n有一个抽象概念是stream，可以避免并行竞争问题。\n两个函数间的用法：\n当如果使用stream，就必须创建tmp。不得不把临时数据写入浪费的带宽中。\n所以我们希望也许有一些新的运算符可以做更加高级的操作。\ngather: 将数据从不同的stream中收集到一个stream中。 scatter: 将数据从一个stream中分散到不同的stream中。\nintel包括了gather，但不包括scatter。 总结 这些并不是完全独立的，而是可以组合使用的。\n通常在实践中为了得到最好的性能，会使用以上所有的方式。\n多核芯片内部通常是shared address space，但小规模情况下使用message passing。\n","permalink":"/posts/cmu-15418cs-618/l3/","summary":"ISPC language SPMD: Single Program Multiple Data 一种花哨的方式来说，就是一种并行编程的范式，它的特点是：在编程时，我们只需要写一个程序，然后在运行时，这个程序会被复制多份，每","title":"Abstraction vs implementation"},{"content":"并行程序 void sinx(int N, int terms, float* x, float* result) { for (int i = 0; i \u0026lt; N; i++) { float value = x[i]; float number = x[i] * x[i] * x[i]; int sign = -1; int denom = 6; for (int j = 0; j \u0026lt; terms; j++) { value += sign * number / denom; sign *= -1; denom *= (2*j+3)*(2*j+2); number *= x[i] * x[i]; } result[i] = value; } } 转换成汇编后大致如下:\nld r0, addr[r1] mul ri, r0, r0 mul r1, r1, r0 可以看到每次循环都是独立的。 对于最简单的是顺序执行。 通过超线程(超标量处理器具有从单个指令流中提取多个指令的能力)可以提高性能。有时称指令级并行性。(ILP, Instruction Level Parallelism) 但在这些汇编指令中必须顺序执行。 因此实现指令级并行性是一个挑战。 但即使是纯顺序执行的代码,也有很多方式使其运行更快(基于写代码的方式和编译器的智能程度). Pentium 4 比如先取多条指令等. (有个黑匣子会预测分支,预测错误的话就会清空流水线,浪费时间) 解决方法: 1. 通过pthread编写并行性的程序 2. 假设有一种语言可以表示并行性,编译器可以自动并行化程序 如: forall(int i from 0 to n-1){} 自动并行化可能的解决方法: 1. 直接分为k个线程,每个线程处理n/k个循环. 然后将结果合并 2. 在硬件上执行. 有一堆性能较低但具有并行性的处理器时, 也需要更多电力/时间来驱动很多信号从一端到另一端. ## CPU \u0026amp;\u0026amp; GPU GPU将核心的概念带到了极致, 抛弃了所有的分支预测, 只是控制逻辑而不完成计算. 对于上面的程序有垂直和水平两种分割方式: - 垂直: 每个线程处理一个循环 - 水平: 同时处理多个循环, 如先同时进行所有的第一个乘法... ## SIMD Single Instruction Multiple Data 假设我正在执行的多次操作之间没有依赖关系,都能够并行运行. a single instruction is applied to multiple data elements simultaneously. 即: 同时对8个数值和另一个地方的8个数值取出并进行加法. 有时这些数值可以被称作向量. 使用AVX intrinsics的向量化程序: ```c++ void sinx(int N, int terms, float* x, float* result) { for (int i = 0; i \u0026lt; N; i+=8) { __m256 origx = _mm256_load_ps(\u0026amp;x[i]); __m256 value = origx; __m256 number = _mm256_mul_ps(origx, _mm256_mul_ps(origx, origx)); float sign = -1; __m256 denom = _mm256_set1_ps(6); for (int j = 0; j \u0026lt; terms; j++) { //value += sign * number / denom; __m256 tmp = _mm256_div_ps(number, denom); tmp = _mm256_mul_ps(tmp, _mm256_set1_ps(sign)); value = _mm256_add_ps(value, tmp); sign *= -1; //denom *= (2*j+3)*(2*j+2); denom = _mm256_mul_ps(denom, _mm256_set1_ps((2*j+3)*(2*j+2))); //number *= x[i] * x[i]; number = _mm256_mul_ps(number, _mm256_mul_ps(origx, origx)); } _mm256_store_ps(\u0026amp;result[i], value); //result[i] = value; } } 编译成汇编后大致如下:\nvloadps xmm0, addr[r1] vmulps xmm1, xmm0, xmm0 vmulps xmm2, xmm1, xmm0 ... ... ... vstoreps addr[xmm2], xmm0 AVX代表高级矢量扩展, 256代表每次可以处理256位的数据, 也就是8个float. 有多个版本:\nAVX: 128位 = 4 * 4 * 8 = 32字节 AVX2: 256位 = 8 * 4 * 8 = 32字节 AVX512: 512位 = 16 * 4 * 8 = 64字节 XMM寄存器是特殊的32字节 256位寄存器, 有16个, 从xmm0到xmm15. 用于支持vectorized SIMD指令.\n那么有没有办法让编译器自动将代码向量化呢?\n有,GCC的-O3选项可以自动向量化代码. 但只有非常结构化,精心编写的代码才能被自动向量化.\n条件 如果加入条件判断,如何向量化?\nif(x \u0026lt; 0){ x = -x; }else{ x = x; } SIMD可能的做法: 设置一个掩码, 用于标记哪些元素需要执行哪些不需要执行.\nx \u0026lt; 0: 1 1 0 0 1 0 0 0 x = -x: 1 1 0 0 1 0 0 0 翻转: 0 0 1 1 0 1 1 1 x = x: 0 0 1 1 0 1 1 1 但大多时候只保留了一半的效率,因为每次有可能只有一半的数据需要执行. 不过这很好的保证了一致性,因为分支结束后又回到了同一个执行路径. 即保持一致性,远离分歧.\ncoherent execution: 所有的线程都执行相同的指令.\ndivergent: a lack of instruction stream coherence.\n对于生成这些矢量操作,要么有聪明的编译器,要么就是有耐心的程序员.\nSIMD execution on many modern GPUs SPMD: Single Program Multiple Data\nGPU给的不是SIMD,而是SPMD. 单个程序,多个数据. 意味着程序的不同部分可以执行不同的指令.\n在这之下,还是用SIMD来实现大部分逻辑,采用异构的方式来实现并行.\n但有n个加法, 即两个包含n个值的向量相加. 实际上不是所有单位都在等待计算.而是会先计算出如何分配到块中,底层块的实际大小是32, 32values而不是32byte. 这个被称作SIMD宽度,一般是8-32.\nGPU和CPU的差别 CPU i7:\n4核 8 SIMD ALUs per core 每秒大概几千次浮点运算 GPU: RTX 1080\n20 cores 32 SIMD ALUs per core 每秒大概8m次浮点运算 GPU的核心摒弃了分支预测等只用做control,因此可以有更多的ALU.填充进来.\n大概是80:1的原始计算能力差异.\n总结 三种方法实现并行计算\n多核CPU:\n线程级实现并行 SIMD:\n指令级并行 通过向量化指令实现 但依赖于事先知道执行的指令优先级顺序 Superscaler: exploit ILP within an instruction stream\npaart2 accessing memory Memory latency: 从CPU到内存的时间\nexample: DRAM访问时间 100 cycles, 100ns Memory bandwidth: 从内存到CPU的时间\nexample: 20GB/s 其实不是很快 Stall: CPU等待内存的时间 当cpu试图进行读取而内存不可用时，就会停等知道内存可用.\n缓存就是为了解决Stall的问题.\n在多级缓存中,靠近核心的缓存是私有的. 这样可以通过写入读出L2缓存的数据来实现通讯,而不需要经过DRAM.\n缓存对延迟和带宽都有帮助.\nPrefecthing reduces stalls 硬件通常通过预取来减少延迟. 即预测下一次可能会访问的数据,并将其提前读取到缓存中. 不过可能会造成信息泄露\n使用预取的效果: Multi-threading reduces stalls 让多个线程交替进行, 如asst1/prog2的实现\n这也是超线程的实现,在一个核心中多路复用多个指令流. 对于CPU\u0026amp;GPU, 谁来组织线程是不同的做法.(操作系统 or 硬件)\n通常情况下内存要比其他因素更加限制速度\n","permalink":"/posts/cmu-15418cs-618/l2/","summary":"并行程序 void sinx(int N, int terms, float* x, float* result) { for (int i = 0; i \u0026lt; N; i++) { float value = x[i]; float number = x[i] * x[i] * x[i]; int sign = -1; int denom = 6; for (int j = 0; j \u0026lt; terms; j++) { value += sign * number / denom; sign *= -1; denom *= (2*j+3)*(2*j+2); number *= x[i]","title":"L2"},{"content":"poetry 出现的错误及解决方法 poetry install 时Failed to create the collection: Prompt dismissed 解决方案: 关闭keyring\npython3 -m keyring --disable 原因: https://github.com/python-poetry/poetry/issues/1917\n","permalink":"/posts/tools/python/poetry/","summary":"poetry 出现的错误及解决方法 poetry install 时Failed to create the collection: Prompt dismissed 解决方案: 关闭keyring python3 -m keyring --disable 原因: https://github.com/python-poetry/poetry/issues/1917","title":"poetry"},{"content":"使用\n进入pods的容器\nkubectl exec -it \u0026lt;pod-name\u0026gt; -c \u0026lt;container-name\u0026gt; -- /bin/bash # 查看对应容器的日志 kubectl logs -f \u0026lt;pod-name\u0026gt; -c \u0026lt;container-name\u0026gt; 错误和解决方案 minikube 挂载 本地目录进minikube时,作为mysql的数据目录,但是mysql无法启动 挂载方式: 在minikube正常启动后, 使用\nminikube mount \u0026lt;本地目录\u0026gt;:\u0026lt;minikube目录\u0026gt; 进行挂载\n检查问题\n# 进入pod 的 db容器内查看日志 kubectl logs -f \u0026lt;pod-name\u0026gt; -c \u0026lt;container-name\u0026gt; 输出为\nfind: File system loop detected; \u0026#39;/var/lib/mysql/test\u0026#39; is part of the same file system loop as \u0026#39;/var/lib/mysql/\u0026#39;. 原因是挂载时发现循环\n解决方案:\n关闭并删除minikube minikube stop minikube delete 在minikube启动时就挂载 minikube start --mount --mount-string=\u0026#34;\u0026lt;本地目录\u0026gt;:\u0026lt;minikube目录\u0026gt;\u0026#34; 问题解决\nminikube 中 设置ingress未转发的问题 参考Could not access Kubernetes Ingress in Browser on Windows Home with Minikube?\n问题1： 当使用minikube时，设置ingress后，minikube ssh 内部可以通过ingress转发的服务端口访问。 但127.0.0.1 或 minikube ip 在主机上无法访问。\n解决方法：\nSet custom domain IP to 127.0.01 in %WINDIR%\\System32\\drivers\\etc\\hosts file, i.e. by adding line 127.0.0.1 my-k8s.com Get ingress pod name: kubectl get pods -n ingress-nginx Start port forwarding: kubectl -n ingress-nginx port-forward pod/ingress-nginx-controller-5d88495688-dxxgw --address 0.0.0.0 80:80 443:443, where you should replace ingress-nginx-controller-5d88495688-dxxgw with your ingress pod name. Enjoy using ingress on custom domain in any browser (but only when port forwarding is active) 问题2: ingress中使用prefix的转发规则时,无法获取路径中的query\n解决方法:\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: minimal-ingress annotations: nginx.ingress.kubernetes.io/use-regex: \u0026#34;true\u0026#34; # 需要添加这个 nginx.ingress.kubernetes.io/rewrite-target: /$2 spec: defaultBackend: service: name: default-http-backend port: number: 80 rules: - host: fuzzs-scene-sim-test.localhost http: paths: - path: /FuzzsSceneSimTest(/|$)(.*) # 后缀加上(/|$)(.*) 用于获取query pathType: ImplementationSpecific backend: service: name: fuzzs-scene-sim-test port: number: 8089 ","permalink":"/posts/tools/k8s/minikube/","summary":"使用 进入pods的容器 kubectl exec -it \u0026lt;pod-name\u0026gt; -c \u0026lt;container-name\u0026gt; -- /bin/bash # 查看对应容器的日志 kubectl logs -f \u0026lt;pod-name\u0026gt; -c \u0026lt;container-name\u0026gt; 错误和解决方案 minikube 挂载 本地目录进minikube时,作为mysql的数据","title":"minikube"},{"content":"本规范用于在开发过程中，使得项目能够更好的部署，更好的维护。\n使用时间: 当项目开始开发时，就应该遵守本规范。\n核心要点:\n管理依赖库 使用docker 端口、ip地址等使用环境变量 路径不能写死！尤其是绝对路径和根目录等，需要放在环境变量中！！ 后端 python项目 python常见的依赖库管理有:\npoetry requirements.txt pipenv poetry 初始化\npoetry init 安装依赖\npoetry install 使用poetry运行项目\npoetry run python main.py 添加依赖\npoetry add \u0026lt;package\u0026gt; dockerfile示例\nFROM python:3.8.5-slim-buster WORKDIR /app # 拷贝依赖文件 COPY pyproject.toml poetry.lock ./ # 设置国内源 RUN pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple # 安装poetry RUN pip install poetry # 安装依赖 RUN poetry config virtualenvs.create false \\ \u0026amp;\u0026amp; poetry install --no-dev --no-interaction --no-ansi # tips: 先只拷贝依赖文件，再安装依赖，可以利用docker的缓存机制，加快构建速度. # (防止只是项目文件改变，而依赖文件没有改变，导致重新安装依赖) # 拷贝项目文件 COPY . . # 运行项目 CMD [\u0026#34;poetry\u0026#34;, \u0026#34;run\u0026#34;, \u0026#34;python\u0026#34;, \u0026#34;main.py\u0026#34;] requirements.txt 导出依赖\npip freeze \u0026gt; requirements.txt 安装依赖\npip install -r requirements.txt dockerfile示例\nFROM python:3.8.5-slim-buster WORKDIR /app # 拷贝依赖文件 COPY requirements.txt ./ # 设置国内源 RUN pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple # 安装依赖 RUN pip install -r requirements.txt # 拷贝项目文件 COPY . . # 运行项目 CMD [\u0026#34;python\u0026#34;, \u0026#34;main.py\u0026#34;] pipenv 初始化\npipenv --python 3.8 安装依赖\npipenv install 使用pipenv运行项目\npipenv run python main.py 添加依赖\npipenv install \u0026lt;package\u0026gt; dockerfile示例\nFROM python:3.8.5-slim-buster WORKDIR /app # 设置国内源 RUN pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple # 拷贝依赖文件 COPY Pipfile Pipfile.lock ./ # 安装依赖 RUN pip install pipenv \\ \u0026amp;\u0026amp; pipenv install --system --deploy --ignore-pipfile # 拷贝项目文件 COPY . . # 运行项目 CMD [\u0026#34;pipenv\u0026#34;, \u0026#34;run\u0026#34;, \u0026#34;python\u0026#34;, \u0026#34;main.py\u0026#34;] SpringBoot项目 参考 这里都以maven作为依赖管理工具。\n主要保留pom.xml文件\ndockerfile示例\n# 第一阶段: 构建jar包 FROM maven:3.6.3-jdk-8-slim AS build WORKDIR /app COPY pom.xml ./ # 设置国内源 RUN mvn -B -e -C -T 1C org.apache.maven.plugins:maven-dependency-plugin:3.1.2:go-offline # 拷贝项目文件 COPY . . # 构建jar包 RUN mvn clean install -DskipTests # 第二阶段: 运行jar包 FROM openjdk:8-jdk-alpine WORKDIR /app # 拷贝第一阶段构建的jar包 COPY --from=build /app/target/demo-0.0.1-SNAPSHOT.jar ./ # 运行项目 CMD [\u0026#34;java\u0026#34;, \u0026#34;-jar\u0026#34;, \u0026#34;target/demo-0.0.1-SNAPSHOT.jar\u0026#34;] 数据库 通常后端要连接数据库，这里只是简单的示例，实际项目中应该使用docker-compose来管理多个容器。\ndockerfile示例\nFROM mysql:8.0.22 # 设置时区 ENV TZ=Asia/Shanghai # 设置root密码 ENV MYSQL_ROOT_PASSWORD=123456 # 设置数据库名 ENV MYSQL_DATABASE=test # 设置用户名 ENV MYSQL_USER=test # 设置密码 ENV MYSQL_PASSWORD=123456 # 设置端口 EXPOSE 3306 单独运行mysql\ndocker run -d -p 3306:3306 --name mysql -v /path/to/mysql/data:/var/lib/mysql mysql:8.0.22 前端 前端使用npm作为依赖管理工具, 使用nginx作为web服务器。\n必要的文件:\npackage.json # 依赖文件 package-lock.json # 锁定依赖版本 nginx.conf # nginx配置文件 dockerfile npm npm初始化\nnpm init 安装依赖\nnpm install 添加依赖(默认添加到dependencies, 添加到devDependencies需要加上\u0026ndash;save-dev参数(或者-D)\nnpm install \u0026lt;package\u0026gt; nginx nginx.conf示例\nserver { listen 80; server_name localhost; root /usr/share/nginx/html; index index.html index.htm; location / { try_files $uri $uri/ /index.html; } } docker docker 使用多阶段构建\ndockerfile示例\n# 第一阶段: 构建项目 FROM node:lts-alpine as build WORKDIR /app # 拷贝依赖文件 COPY package.json package-lock.json ./ # 安装依赖 RUN npm install # 拷贝项目文件 COPY . . # 构建项目 RUN npm run build # 第一段构建完成, 获得/app/build文件夹 # 使用nginx作为web服务器 FROM nginx:1.19.4-alpine # 拷贝nginx配置文件 COPY nginx.conf /etc/nginx/conf.d/default.conf # 拷贝第一阶段构建的项目文件 COPY --from=build /app/build /usr/share/nginx/html # 运行nginx CMD [\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;] 项目部署 TODO 封装整个项目(单个项目时) 经过上面的步骤已经将前后端 数据库封装到docker中了,但每次启动项目都需要手动启动三个容器, 这里使用docker-compose来管理多个容器。\ndocker-compose.yml示例\nversion: \u0026#39;3.8\u0026#39; services: mysql: image: mysql:8.0.22 environment: TZ: Asia/Shanghai MYSQL_ROOT_PASSWORD: 123456 MYSQL_DATABASE: test MYSQL_USER: test MYSQL_PASSWORD: 123456 ports: - 3306:3306 volumes: - ./mysql/data:/var/lib/mysql backend: build: ./backend ports: - 8080:8080 depends_on: - mysql frontend: build: ./frontend ports: - 80:80 depends_on: - backend 整个项目作为k8s的一个服务(多个项目时) 上面是使用docker-compose来管理 一个项目的多个容器.\n但如果有多个项目, 每个项目都有多个容器, 这时候就需要使用k8s来管理了.\n我们把一个项目(多个容器)作为一个k8s的一个服务.\nk8s的配置文件示例\napiVersion: v1 kind: Service metadata: name: test labels: app: test spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: app: test type: NodePort --- apiVersion: apps/v1 kind: Deployment metadata: name: test labels: app: test spec: replicas: 1 selector: matchLabels: app: test template: metadata: labels: app: test spec: containers: - name: mysql image: mysql:8.0.22 env: - name: TZ value: Asia/Shanghai - name: MYSQL_ROOT_PASSWORD value: 123456 - name: MYSQL_DATABASE value: test - name: MYSQL_USER value: test - name: MYSQL_PASSWORD value: 123456 ports: - containerPort: 3306 volumeMounts: - name: mysql-data mountPath: /var/lib/mysql - name: backend image: backend:latest ports: - containerPort: 8080 env: - name: MYSQL_HOST value: mysql - name: MYSQL_PORT value: \u0026#34;3306\u0026#34; - name: MYSQL_DATABASE value: test - name: MYSQL_USER value: test - name: MYSQL_PASSWORD value: 123456 - name: frontend image: frontend:latest ports: - containerPort: 80 volumes: - name: mysql-data hostPath: path: /path/to/mysql/data ","permalink":"/posts/reference/%E5%88%A9%E4%BA%8E%E9%83%A8%E7%BD%B2%E7%9A%84%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/","summary":"本规范用于在开发过程中，使得项目能够更好的部署，更好的维护。 使用时间: 当项目开始开发时，就应该遵守本规范。 核心要点: 管理依赖库 使用docke","title":"利于部署的开发规范手册"},{"content":"GPU\n图形渲染 图像中的每个对象都有很自然的并行性。\n","permalink":"/posts/cmu-15418cs-618/l7/","summary":"GPU 图形渲染 图像中的每个对象都有很自然的并行性。","title":"L7"},{"content":"grep工具\n","permalink":"/posts/tools/grep/","summary":"grep工具","title":"grep"},{"content":"虚拟文件系统\n/proc/cpuinfo\nmodel name cpu MHz - 频率 cache size - 缓存大小 siblings - 逻辑cpu数量 processor - 逻辑cpu编号 cpu cores - 物理cpu数量 core id - 物理cpu编号 这样查看的cpu数量很多\nsiblings是逻辑cpu的数量\ncpu cores是物理cpu的数量\n为什么报告的processor数量是40而siblings是20呢? 因为报告的processor包括超线程的逻辑cpu. 这样操作系统就可以直接根据逻辑cpu的数量来分配任务.\nMemory bandwidth - 内存带宽 Power consumption - 功耗 能源消耗实际上是一个很大的问题. Intel code name - 代号 Functional units\nlatency - 延迟 issue time - 发射时间 capacity - 容量 微处理架构\nfunction units latency - 延迟，执行一个指令所需要的时钟周期数(不包括等待) issue time - 发射时间，指令发射到执行所需要的时钟周期数(包括等待) capacity - 容量 优化的地方:\n搞清楚到底哪些代码是执行次数最多的(内部循环)(对实际使用情况来说) 基本运算消耗时间: 除法 \u0026gt; 乘法 \u0026gt; 加法 \u0026gt; 位移 基本的程序: 合并重复计算的简单的提升: 将除法次数减少,(不依赖于内层循环的变量的计算拿出来)\n循环展开 loop unrolling\n如果每一次循环都要进行一次是否终止的测试,开销会很大.(尤其是一次循环的计算 相比于 循环次数来说很小 时)\n所以处理器从简单的策略开始,如预测循环的次数. 大部分都是基于统计预测的.\n如果可以预测循环的次数,就可以将循环展开. 每次循环多执行4 或 8 或\u0026hellip;次原来循环做的事情.\n但展开时不一定均匀,\nuniform可以使得循环展开的更好.\n为什么8维向量获得了超过8倍的加速呢? 因为uniform, 原本要做8次的判断,现在只需要做一次.\n常规优化提升了15倍 向量优化提升了5.4倍 总计提升了82倍\n向量化很好且是free的,但不能忽略了传统的优化\n传统的优化(213 program)使得速度提升了三倍\n要做到极致的优化,就比如要花3个星期的时间在编码风格上, 最后30分钟花在向量化上.\n但要看情况来决定编码风格的优化. 因为如果我们编写的代码不是执行次数最多(如内核,场景仿真,高频), 那么可能更需要的是可读性.\n可读性变差 可能会导致bug很容易被引入, 并且非常不容易被发现和维护.\n","permalink":"/posts/cmu-15418cs-618/l6/","summary":"虚拟文件系统 /proc/cpuinfo model name cpu MHz - 频率 cache size - 缓存大小 siblings - 逻辑cpu数量 processor - 逻辑cpu编号 cpu cores - 物理cpu数量 core id - 物理cpu编号 这样查看的cpu数量很","title":"L6"},{"content":"光标移动 h: 左移一个字符 j: 下移一行 k: 上移一行 l: 右移一个字符\nw: 移动到下一个单词的开头 e: 移动到当前单词末尾 b: 移动到上一个单词的开头\n0: 移动到行首 $: 移动到行尾\nn + 上面的命令: 移动n次\ngg: 移动到文件开头 G: 移动到文件末尾\n上面所有命令构成了一个移动命令，可以和d命令组合使用，删除从当前光标到移动命令所指的位置的内容\nctrl + f: 下翻一页 ctrl + b: 上翻一页 ctrl + G: 显示当前光标所在行的行号\nctrl + i: 跳转到上次位置· ctrl + o: 跳转到下次位置\nG + n: 移动到第n行\n插入 i: 在当前光标处插入 I: 在当前行首插入\na: 在当前光标后插入 A: 在当前行尾插入\no: 在当前行下方插入一行 O: 在当前行上方插入一行\n删除 x: 删除当前光标所在的字符 X: 删除当前光标所在的前一个字符\ndd: 删除当前行 D: 删除当前光标所在位置到行尾的内容\nd + 移动命令: 删除从当前光标到移动命令所指的位置的内容\n如: dw: 删除当前光标所在的单词 db: 删除当前光标所在的单词 d$: 删除当前光标所在位置到行尾的内容 dnG: 删除当前光标所在行到第n行的内容 dG: 删除当前光标所在行到文件末尾的内容\n剪切 上面删除的内容都会被保存到剪切板中\n删除并进入插入模式 s: 删除当前光标所在的字符并进入插入模式 S: 删除当前行并进入插入模式\nc + 移动命令: 删除从当前光标到移动命令所指的位置的内容并进入插入模式\n如: cw: 删除当前光标所在的单词并进入插入模式 c$: 删除当前光标所在位置到行尾的内容并进入插入模式 cnG: 删除当前光标所在行到第n行的内容并进入插入模式\n复制 y + 移动命令: 复制从当前光标到移动命令所指的位置的内容\n如: yw: 复制当前光标所在的单词 yb: 复制当前光标所在的单词 y$: 复制当前光标所在位置到行尾的内容 ynG: 复制当前光标所在行到第n行的内容\n粘贴 所有删除的内容都会被保存到剪切板中，可以使用p命令将剪切板中的内容粘贴到当前光标所在位置 p: 将剪切板中的内容粘贴到当前光标所在位置的后面 P: 将剪切板中的内容粘贴到当前光标所在位置的前面\n替换 r + 字符: 将当前光标所在的字符替换为指定的字符\nR + 字符串: 将当前光标所在位置开始的字符串替换为指定的字符串\n撤销 u: 撤销上一次操作 U: 撤销当前行的所有操作\nctrl + r: 恢复上一次撤销的操作\n重复 . : 重复上一次操作\n查找 / + 关键字: 从当前光标开始向下查找关键字 ? + 关键字: 从当前光标开始向上查找关键字\n输完后按回车，会跳转到第一个匹配的位置.\nn: 跳转到下一个匹配的位置 N: 跳转到上一个匹配的位置\n: 进阶命令 :w 保存文件 :q 退出 :q! 强制退出，不保存 :wq 保存并退出 :wq! 强制保存并退出\n上面的命令 + 文件名: 保存文件到指定的文件名\n:help 命令名: 查看命令的帮助文档\n替换 :%s/old/new/g 将所有的old替换为new :%s/old/new/gc 将所有的old替换为new，替换前询问是否替换\n:#,#s/old/new/g 将第#行到第#行的old替换为new\n外部命令 :! + 命令: 执行外部命令\n如: :!ls 执行ls命令 :!dir 执行dir命令\n","permalink":"/posts/tools/vim/%E6%8C%87%E4%BB%A4%E6%89%8B%E5%86%8C/","summary":"光标移动 h: 左移一个字符 j: 下移一行 k: 上移一行 l: 右移一个字符 w: 移动到下一个单词的开头 e: 移动到当前单词末尾 b: 移动到上一个单词的开头 0: 移动到行首 $: 移","title":"vim的使用"},{"content":"三种分配策略的总结 静态分配 优点:\n几乎没有运行时的开销(关于分配) 缺点:\n不总是均匀的分配任务 什么时候使用:\n(最简单的例子) 当知道每个任务的工作量相当的时候 当每个任务的工作量是可预测的,但不一定相等的时候 半静态分配\n场景: 当工作量会随时间发生改变,当变化比较慢时.(任务量不可预测) 做法: 定期的重新分配任务 动态分配 场景: 当每个任务的工作量或者任务的数量是不可预测的时候\n每个计算单元都要去获取任务\n但这样的实现, 每次的任务可能会很少, 会使得更多的开销在争夺锁(获取任务的锁)上面.\n有一个办法是一次性计算更多的任务.\n但分配更多的任务可能会导致负载不平衡.\n因此需要在分配任务数量上要找一个平衡, 不花费过多的时间在争夺锁上, 也不会导致负载不平衡.\nSchedule long tasks first 但如果有一个大任务在最后，将出现如下情况： 因此，如果知道有一个大任务，可以提前处理，而不是放到最后一个.\nWork stealing 当一个计算单元没有任务的时候, 从其他计算单元那里偷取任务.\n实现的一些问题:\n1.从哪个线程开始偷取任务呢? 有随机的, 也有从最后一个开始偷取的.\n2.应该偷取多少任务呢? 应该偷取尽可能多一些,这样可以减少偷取任务的次数.\n3.怎样检测一个计算单元是否有任务呢? 可能会循环遍历,\n4.使用本地队列(分布式队列)会更快(在有互斥锁的情况下)\n还有一种方式是使用特殊的数据结构来存储任务间的依赖关系, 从而可以在任务完成的时候, 自动的调度下一个任务. 缺点是额外开销 常见的并行编程模式 循环 创建显示线程 递归时的并行\n递归可以编写出简单的代码, 但是递归的并行化是比较困难的.\n因为递归的并行化需要在递归的每一层都要进行并行化, 并且需要在每一层都要进行同步.\n但只要有独立的子问题, 就可以创造很多潜在的并行性.\nFork-Join pattern cilk_spawn: 会创建一个新的线程, 并且在新的线程中执行函数, 并且不会阻塞当前的线程.\ncilk_sync: 会等待所有的子线程执行完毕, 并且会阻塞当前的线程.\n每个函数的结尾隐式的调用了cilk_sync.\nexample: 有一个主线程+fork的线程. 快排的例子: 在规模较小的时候, 使用串行的快排. 这样可以减少线程的创建和销毁的开销. 不要忽略了抽象和实现的区别. spawn不是生成一个具体的线程, 而是声明这里有一个可以并行的任务.\n任务的数量至少需要比硬件线程多,但也不能大于100倍. 8倍是一个比较好的选择. Cilk的实现 假设我们要去实现clik_spawn 和 cilk_sync 线程池的实现(CILB):\nthread1 需要找到一种方法来发现有新的任务可以执行. 所以thread 0不能简单的调用foo, 它的作用是执行foo.\n但需要在执行foo前,把特殊的东西放入工作队列中.\n此时如果另一个线程突然变得空闲, 它就可以从工作队列中获取任务.\n为什么不把foo放入队列, 直接执行bar呢?(上面是执行foo bar放入队列)\n这涉及到 continuation first(child stealing) 和 child first(continuation stealing) 的问题.\ncontinuation first会导致线程0的大量工作排队.(广度优先队列) child first会导致其他线程把下一个任务偷走时, 会导致线程0的工作队列为空.(深度优先队列)\n实际上child first是合理的.(在递归中是最合适的)\n在递归程序中,会先将所有深度的任务放入队列中.\n按照之前优先执行大任务的策略, 其他线程会优先从队列顶部(先入的)中偷取任务. 因为在分而治之的算法中, 大任务会被分解成小任务, 因此大任务会先被放入队列中.\n实际中使用了双端队列:\n从队列头部获取任务 从队列尾部放入任务 但之前有一个问题: 很多队列,该从哪个队列中获取任务呢? 也许是随机的. 偷取任务的时候, 不随机的更可能会引起负载不均衡.\n本地线程访问的是本地队列的尾部, 偷取时也是放入尾部.(偷其他队列的头部) 这样也有利于空间局部性.\n那么如何实现同步呢?\nExample1: stalling join policy 拖延政策: 所有我创建的任务都必须完成后, 我才能继续执行. Example2: greedy join policy(cilk的实现方法)\n有一个跟踪数据结构,但那个东西可以四处移动.\n最后一个完成的线程会偷走这个数据结构\n所以一旦最后一个任务完成, 就可以继续执行了.\n这样不会浪费时间等待同步.\n第一个方法实现起来更简单,但速度更慢. 因为它总是首线程只等待其他线程完成.\n总结 ","permalink":"/posts/cmu-15418cs-618/l5/","summary":"三种分配策略的总结 静态分配 优点: 几乎没有运行时的开销(关于分配) 缺点: 不总是均匀的分配任务 什么时候使用: (最简单的例子) 当知道每个任务的工作","title":"L5 Work distribution and scheduling"},{"content":"主要用三种方式实现并行程序(没有进行真正的优化)\n例子 n-body simulation\n创建并行程序的过程\n1. Decomposition 主要思想: 创造至少足够的任务让所有的处理单元都有事情做\nAmdahl\u0026rsquo;s Law: 串行部分的比例越大, 并行程序的加速比就越小,因为增加处理单元的数量并不能减少串行部分的时间\n分解的任务更多是程序员的工作, 编译器还无法很好的帮助我们\n2.Assignment 需要考虑让每个处理单元尽可能减少沟通.\n有一种方法是随机分配,但会最大化沟通 还有一个极端是全部由一个处理单元完成,但是这样就没有并行了\n这是另一个挑战\n分配可以静态也可以动态发生\n静态: 在程序开始时就确定好. 动态: 在程序运行时分配 静态分配的问题:\n无法适应不同的输入(如:工作量不均匀) 无法适应不同的处理单元数量 动态分配: 通过消息传递来实现, 每个处理单元都有一个队列, 用来存放需要处理的任务(tasks). 当一个处理单元完成了一个任务, 就从队列中取出一个任务来处理 缺点: 队列需要同步, 会有额外的开销\n3. Orchestration 编排阶段 编排的目标是: 减少沟通和同步的成本, preserve locality of data reference, reduce overhead.\n4.mapping 这是程序员最不需要关心的, 交给编译器就好了 example 顺序程序: 那么如何并行执行呢?\nStep1: identify dependencies(problem decomposition) 因为会迭代很多次,所以会引起不同迭代次数的数据竞争.\n有一种划分方法是沿着对角线: 不足之处是:\n有些对角线很短, 负载不均衡 需要额外的计算(对角线下标) 另一种方法是滚动数组: 用两个数组, 一个用来存放当前迭代的结果, 一个用来存放上一次迭代的结果\n这样计算时不会有数据竞争.\n但很多人不希望有额外的内存开销.\n事实上使用的是红黑排序.\n每次迭代只更新红色的部分, 然后再翻转. 这样就不需要复制数组了.\nStep2: assign tasks 我们不把每一个元素作为一个任务,而是把每一行作为一个任务.\n同时: 红黑排序有一个同步的步骤: 必须等待所有的红色部分都计算完毕, 才能开始计算黑色部分.\n为了最小化沟通, 相邻行作为捆包是更好的选择, 这样只在更新边界时需要沟通.\n三种实现方法 Data-parallel expression of solver 这个的特点是系统做了很多工作, 程序只需要指定哪里需要并行.\nshared-address-space code version1 : 但是有个锁会使得程序变慢 version2: 有三个barrier来保证红黑顺序 为什么是三个呢?\n每一部分都要被分割\n最后一个是为了diff的分割 第一个是为了myDiff的分割 第二个是为了diff的分割\n所以可以使用diff数组\nversion3: barrier的问题: barrier还是有点笨重, 这会强制所有线程到一个起跑线 但如果有更精确的信息, 只需要等待依赖的线程就好了\nmessage-passing code 需要有额外的划分,来存储相邻处理器的数据\n同时,在最后计算diff时,需要等待所有的处理器都计算完毕. 这里选中了一个processor zero来计算diff, 其他的处理器都发送自己的diff给它.\n但沟通时有可能发生死锁. 因为每个处理器都在等待其他处理器的消息, 但是自己的消息又没有发送出去.\n所以需要分奇偶来发送\n","permalink":"/posts/cmu-15418cs-618/l4/","summary":"主要用三种方式实现并行程序(没有进行真正的优化) 例子 n-body simulation 创建并行程序的过程 1. Decomposition 主要思想: 创造至少足够的任务让所有的处理单元都有事情做 Amdahl\u0026rsquo;s Law: 串行","title":"L4 Parallel Programing basics"},{"content":"多阶段构建docker镜像 多阶段构建的修改不会保留到下一阶段，只有COPY和ADD命令会保留到下一阶段\nusages：\n第一阶段：编译/打包程序依赖 多阶段用途：\n缩小镜像体积 ","permalink":"/posts/tools/docker/docker/","summary":"多阶段构建docker镜像 多阶段构建的修改不会保留到下一阶段，只有COPY和ADD命令会保留到下一阶段 usages： 第一阶段：编译/打包程序","title":"docker Usage"},{"content":"修改用户密码 alter user \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; identified with mysql_native_password by \u0026#39;123456\u0026#39;; 刷新权限 flush privileges; 添加一个远程用户 create user \u0026#39;remote\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;password\u0026#39; GRANT all ON *.* TO \u0026#39;remote\u0026#39;@\u0026#39;%\u0026#39;; grant all privileges on *.* to \u0026#39;remote\u0026#39;@\u0026#39;%\u0026#39; with grant option; *.*所有数据库下的所有表 创建数据库并设定中文编码 CREATE DATABASE `db_name` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; 登录格式 mysql -h #{数据库IP} -P 3306 -u #{用户名} -p -D #{数据库名} 自增id 不连续时 SET @auto_id = 0; UPDATE 表名 SET 自增字段名 = (@auto_id := @auto_id + 1); ALTER TABLE 表名 AUTO_INCREMENT = 1; 文件 source ","permalink":"/posts/tools/sql/mysql%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","summary":"修改用户密码 alter user \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; identified with mysql_native_password by \u0026#39;123456\u0026#39;; 刷新权限 flush privileges; 添加一个远程用户 create user \u0026#39;remote\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;password\u0026#39; GRANT all ON *.* TO \u0026#39;remote\u0026#39;@\u0026#39;%\u0026#39;; grant all privileges on *.* to \u0026#39;remote\u0026#39;@\u0026#39;%\u0026#39; with grant option; *.*所有数据库下的所有表 创建数据库并设","title":"MySql常用命令"},{"content":"Parallelism 加速比 Speed up 是指： 程序在单处理器上运行的时间 / 程序在多处理器上运行的时间\n我们一般会期望用两倍的硬件得到两倍的速度提升,但是实际上并不是这样的。\n制约性能提升可能的因素有:\n资源分配不均匀 通信开销 短板效应 共享资源读写冲突 为什么要去了解硬件？\n什么是限制性能的因素？ 导致性能瓶颈的原因是什么？ Efficiency fast != efficient\n什么是效率？ 尽可能地利用资源，减少浪费 比如按时间租用服务器。\n总结 并行程序的挑战：\n负载均衡 Load balance 通信延迟 Communication latency 集体工作时，真正用于计算的时间很少 ","permalink":"/posts/cmu-15418cs-618/l1-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%92%8C%E9%AB%98%E6%95%88/","summary":"Parallelism 加速比 Speed up 是指： 程序在单处理器上运行的时间 / 程序在多处理器上运行的时间 我们一般会期望用两倍的硬件得到两倍的速度提升,但是实际上并不是这样的","title":"Why parallelism? Why efficiency?"},{"content":"TL;DR 背景: 已使用nextcloud和typora写笔记 需求: 将笔记转换为博客.(且因为本人太懒,😂 所以需要全自动化) 在nextcloud中, 专门设置一个文件夹\u0026quot;笔记\u0026quot; 转换为博客文件夹 不能改变原来记笔记的方式 不能有任何新增的操作 方案: 使用hugo搭建博客 使用Github pages部署博客 使用Github Actions自动化部署 使用py脚本将笔记转换为博客 使用任务计划程序定时执行py脚本 使用hugo搭建博客 参考: hugo官网 Hugo+Github Pages+Github Action博客方案之二 Hugo+Github Pages+Github Action博客方案之三 PaperMod主题\n创建github仓库 要创建两个仓库\n一个仓库用于存放博客源码 一个仓库用于存放博客静态文件 创建博客静态文件仓库 设置仓库名为: 用户名.github.io 我的博客仓库\n创建博客源码仓库 设置仓库名为: hugo-blog // 仓库名可以自定义 我的博客源码仓库\n安装hugo scoop install hugo 创建hugo博客 hugo new site hugo-blog 安装主题 cd hugo-blog ## 进入博客目录, 这个是博客源码仓库 git init git submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod git submodule update --init --recursive ## needed when you reclone your repo (submodules may not get cloned automatically) 配置主题 这里使用yaml格式的配置文件, 也可以使用toml格式的配置文件 所以需要删除config.toml文件, 并创建config.yaml文件\nconfig.yaml:\nbaseURL: / title: ysyy\u0026#39;s blog theme: PaperMod languageCode: zh-cn 剩余配置参考\n创建文章 hugo new posts/first/hello-world.md 本地预览 hugo server -D 生成静态文件 生成静态文件, 生成的静态文件在 public文件夹中。 之后我们将这个文件夹中复制到博客静态文件仓库中\nhugo 部署到github pages 创建静态文件夹\ngit clone git@用户名.github.io.git cd 用户名.github.io cp -r hugo-blog/public/* ./ 提交到github\ngit add . git commit -m \u0026#34;first commit\u0026#34; git push origin main 配置github pages 在github中的 用户名.github.io仓库中, 点击 Settings选项卡, 找到 GitHub Pages选项, 将 Source选项设置为 main分支, 点击 Save按钮, 这样就可以通过 https://用户名.github.io访问博客了\n使用Github Actions自动化部署 参考\n如果每一次更新/发布新博客都需要手动执行上面的步骤, 那么就太麻烦了, 所以我们需要自动化部署\n在博客源码仓库的根目录下创建 .github/workflows/deploy.yml文件\nname: ysyyblog on: push: branches: - main jobs: build-deploy: runs-on: ubuntu-20.04 # runs-on: macos-latest steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;latest\u0026#39; # extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: personal_token: ${{ secrets.PERSONAL_TOKEN }} # 另外还支持 deploy_token 和 github_token external_repository: ysyyhhh/ysyyhhh.github.io # 修改为你的 静态文件GitHub Pages 仓库 publish_dir: ./public # keep_files: false publish_branch: main # 如果使用自定义域名，还需要添加下面一行配置 # cname: www 创建personal_token 在github主页的右上角点击头像, 点击 Settings选项卡, 找到 Developer settings选项,\n找到 Personal access tokens选项, 点击 Generate new token按钮, 创建一个新的token\n配置personal_token 在hugo-blog仓库中, 点击 Settings选项卡, 找到 Secrets选项, 点击 New repository secret按钮,\n新增一个名为 PERSONAL_TOKEN的secret, 值为上面创建的personal_token\n测试自动化部署 在本地的hugo-blog仓库中, 修改 content/posts/first/hello-world.md文件, 然后提交到github\n可以在 Actions选项卡中查看自动化部署的状态\n如果在 Actions选项卡中看到了 build-deploy任务, 且状态为 success, 那么就说明自动化部署成功了\n可以在 用户名.github.io仓库中查看是否已经更新.\n使用任务计划程序和py脚本实现全自动化 上面的步骤已经让我们发布笔记的过程变成:\n使用hugo new / 直接编辑 content的文件 来创建笔记 提交到hugo-blog仓库 然后hugo-blog仓库就会自动部署到用户名.github.io仓库中\n虽然已经只剩两步了,但遵循能自动化就自动化的原则, 我们还是要把这两步也自动化\n使用py脚本将笔记转换为博客 安装python这些步骤就省去了,这里直接给出py脚本\n\u0026#39;\u0026#39;\u0026#39; 每天定时更新博客内容 1.进入项目根目录: D:/program_about/hugo/hugo-blog 2. 将D:/nextcloud/笔记/下的文件同步到 ./content/posts/下 3. 执行./push.bat 或 git add . \u0026amp;\u0026amp; git commit -m \u0026#34;update\u0026#34; \u0026amp;\u0026amp; git push \u0026#39;\u0026#39;\u0026#39; import os import shutil def create_index(root, name): \u0026#39;\u0026#39;\u0026#39; name = A.md 在root下生成\u0026#39;A\u0026#39;文件夹 将A.md移动到A文件夹下，并重命名为index.md 如果 存在 root + \u0026#39;/img\u0026#39; 的文件夹 将 root + \u0026#39;/img\u0026#39; 复制到 root + \u0026#39;/A/img\u0026#39; 下 \u0026#39;\u0026#39;\u0026#39; # 生成文件夹 dir_name = name.split(\u0026#39;.\u0026#39;)[0] print(root, name, dir_name) os.mkdir(os.path.join(root, dir_name)) # 移动文件 shutil.move(os.path.join(root, name), os.path.join(root, dir_name, \u0026#39;index.md\u0026#39;)) # 处理img if os.path.exists(os.path.join(root, \u0026#39;img\u0026#39;)): shutil.copytree(os.path.join(root, \u0026#39;img\u0026#39;), os.path.join(root, dir_name, \u0026#39;img\u0026#39;)) def adjust(dir): os.chdir(dir) \u0026#39;\u0026#39;\u0026#39; 将所有下面的格式 - A.md - img - A-1.png 转换成 - A - index.md - img - A-1.png 如果遇到\u0026#34;.md\u0026#34;文件,直接删除 \u0026#39;\u0026#39;\u0026#39; for(root, dirs, files) in os.walk(\u0026#34;.\u0026#34;): root = os.path.join(dir, root) for name in files: if name == \u0026#39;.md\u0026#39;: os.remove(os.path.join(root, name)) continue if name.endswith(\u0026#39;.md\u0026#39;): create_index(root, name) for name in dirs: # 递归调用 adjust(os.path.join(root, name)) def sync(): root_path = \u0026#39;D:/program_about/hugo/hugo-blog\u0026#39; os.chdir(root_path) # 当文件已存在时，无法创建该文件。: \u0026#39;./content/posts/\u0026#39; shutil.rmtree(\u0026#39;./content/posts/\u0026#39;) # git中也要删除 os.system(\u0026#39;git rm -r ./content/posts/\u0026#39;) shutil.copytree(\u0026#39;D:/nextcloud/笔记/\u0026#39;, \u0026#39;./content/posts/\u0026#39;) # 把所有文件夹和文件的名称大写转换为小写 os.chdir(\u0026#39;./content/posts/\u0026#39;) for root, dirs, files in os.walk(\u0026#34;.\u0026#34;): for name in files: new_name = name.lower() os.rename(os.path.join(root, name), os.path.join(root, new_name)) for name in dirs: new_name = name.lower() os.rename(os.path.join(root, name), os.path.join(root, new_name)) # 调整文件夹结构 adjust(root_path+\u0026#39;./content/posts/\u0026#39;) # 上传到git # os.chdir(\u0026#39;./content/posts/\u0026#39;) os.chdir(\u0026#39;D:/program_about/hugo/hugo-blog\u0026#39;) os.system(\u0026#39;git add ./content/posts/\u0026#39;) os.system(\u0026#39;git commit -m \u0026#34;update\u0026#34;\u0026#39;) os.system(\u0026#39;git push\u0026#39;) os.chdir(\u0026#39;D:/program_about/hugo/hugo-blog\u0026#39;) print(\u0026#39;sync done\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: sync() 将上面的路径修改为自己的路径, 然后保存为 sync.py文件 可以执行py脚本,测试一下\n关于图片路径问题 参考方案\n因为我平时的图片路径是\n- A.md - img - A-1.png 但是hugo会将A.md文件转换为A文件夹, 所以此时是无法访问A-1.png的.\n这里是通过改变相对路径关系来解决的, 即代码中的adjust()\n当然如果你有图床就不需要这么麻烦了\n使用任务计划程序定时执行py脚本 参考 这里我使用的是win10自带的任务计划程序, 其他系统的任务计划程序也是类似的\n以下步骤由Claude生成\n下面是如何使用Windows任务计划程序来配置定时每天执行Python脚本的步骤: 打开任务计划程序(Windows + R 输入taskschd.msc回车) 点击\u0026#34;操作\u0026#34;栏中的\u0026#34;创建基本任务\u0026#34; 输入任务名称,选择触发器为每天定时,设置执行时间 在操作栏中,点击“新建” 选择“启动一个程序” 在“程序/脚本”框中输入Python解释器的路径,例如C:\\Python37\\python.exe 在“添加参数(可选)”中输入python脚本文件的完整路径,例如C:\\Users\\username\\script.py 点击“确定”保存此操作 在下一页中选择用户账号,例如“当前用户” 点击“确定”完成创建任务 根据需要配置触发器记录和其他选项 点击“确定”保存任务 任务将在设定的时间自动执行python脚本文件 每次修改脚本后需要停止原有任务,然后再新建一个相同的任务来加载修改后的脚本代码。 需要注意python interpreter路径和脚本路径的正确性。定时执行格式也需要正确,这样就可以实现Windows系统中的自动定时任务执行Python脚本了。 ","permalink":"/posts/tools/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","summary":"TL;DR 背景: 已使用nextcloud和typora写笔记 需求: 将笔记转换为博客.(且因为本人太懒,😂 所以需要全自动化) 在nextcloud中, 专","title":"用Hugo + Github Pages/Action + py + 任务计划程序 搭建 全自动化markdown笔记转博客"}]