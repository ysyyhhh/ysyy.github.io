<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>分布式 | Ysyy's</title><link>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/</link><atom:link href="https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/index.xml" rel="self" type="application/rss+xml"/><description>分布式</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><image><url>https://ysyyhhh.github.io/media/logo.svg</url><title>分布式</title><link>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/</link></image><item><title/><link>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</guid><description>&lt;p>分布式事务的中间件Seata&lt;/p></description></item><item><title/><link>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%A1%80/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%A1%80/</guid><description>&lt;h2 id="经典问题">经典问题&lt;/h2>
&lt;p>拜占庭将军问题
描述： 一组将军围攻一座城市，他们需要达成一致的决策，但是其中一些将军可能是叛徒，他们会向其他将军发送错误的信息。这个问题的目标是找到一种算法，使得所有忠诚的将军能够达成一致的决策，即使有叛徒存在。
经典设置：&lt;/p>
&lt;ol>
&lt;li>每个将军都是一个节点，他们之间通过消息进行通信。&lt;/li>
&lt;li>每个将军都有一个二值的决策，即攻击或者撤退。&lt;/li>
&lt;li>每个将军都知道自己是不是叛徒，但是不知道其他将军是不是叛徒。&lt;/li>
&lt;li>叛徒将军可以发送错误的消息。&lt;/li>
&lt;li>总共有m个将军，其中n个是忠诚的，m-n个是叛徒。&lt;/li>
&lt;li>问题的目标是找到一种算法，使得所有忠诚的将军能够达成一致的决策，即使有叛徒存在。&lt;/li>
&lt;/ol>
&lt;h2 id="cap--base理论">CAP &amp;amp; Base理论&lt;/h2>
&lt;h3 id="cap-理论">CAP 理论&lt;/h3>
&lt;p>CAP理论是分布式系统设计中的一个重要理论，它指出在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）这三个要素不可兼得，最多只能同时满足其中的两个。&lt;/p>
&lt;ul>
&lt;li>一致性（Consistency）：在分布式系统中的所有节点上的数据是一致的，即一个节点上的数据发生了变化，那么在其他节点上也应该立即发生变化。&lt;/li>
&lt;li>可用性（Availability）：分布式系统中的所有节点都能够正常响应客户端的请求。&lt;/li>
&lt;li>分区容错性（Partition tolerance）：分布式系统中的节点之间可能会因为网络分区而无法通信，分区容错性指的是系统能够继续工作，即使节点之间无法通信。&lt;/li>
&lt;/ul>
&lt;p>网络分区: 分布式系统中，多个节点之间的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫 网络分区。&lt;/p>
&lt;p>CAP一般要满足两个，而P是必须的，所以CAP理论一般是AP或者CP。&lt;/p>
&lt;ul>
&lt;li>CP：HBase、MongoDB等分布式数据库是CP系统，它要求数据一致性和分区容错性，但是无法保证所有节点的可用性。&lt;/li>
&lt;li>AP：Cassandra、DynamoDB等分布式数据库是AP系统，它要求可用性和分区容错性，但是无法保证数据一致性。&lt;/li>
&lt;/ul>
&lt;p>一致性与可用性的矛盾&lt;/p>
&lt;ul>
&lt;li>一致性要求所有节点看到的数据都是相同的,这意味着在更新数据时需要等待所有节点的确认。&lt;/li>
&lt;li>而可用性要求系统在出现网络分区时仍然能够对外提供服务,这就意味着不能等待所有节点的确认。
在网络分区的情况下,这两个要求是矛盾的。&lt;/li>
&lt;/ul>
&lt;p>注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。&lt;/p>
&lt;p>常见的可以作为注册中心的组件有：ZooKeeper、Eureka、Nacos&lt;/p>
&lt;p>ZooKeeper保证的是CP，Eureka保证的是AP，Nacos既可以保证CP也可以保证AP。&lt;/p>
&lt;h3 id="base-理论">Base 理论&lt;/h3>
&lt;p>Base理论是对CAP理论的一个补充，它是指在分布式系统中，基本的理论是基于CAP理论，但是在实际的分布式系统中，我们往往无法做到强一致性，而是通过牺牲强一致性来换取可用性或者分区容错性。&lt;/p>
&lt;p>BASE 是 Basically Available（基本可用）、Soft-state（软状态） 和 Eventually Consistent（最终一致性）&lt;/p>
&lt;p>什么叫允许损失部分可用性呢？&lt;/p>
&lt;ul>
&lt;li>响应时间上的损失: 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。&lt;/li>
&lt;li>系统功能上的损失：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。&lt;/li>
&lt;/ul>
&lt;p>软状态指
允许系统中的数据存在中间状态（CAP 理论中的数据不一致），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。&lt;/p>
&lt;p>分布式一致性的 3 种级别：&lt;/p>
&lt;ul>
&lt;li>强一致性：系统写入了什么，读出来的就是什么。&lt;/li>
&lt;li>弱一致性：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。&lt;/li>
&lt;li>最终一致性：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。&lt;/li>
&lt;/ul>
&lt;p>实现最终一致性的方法：&lt;/p>
&lt;ul>
&lt;li>读时修复 : 在读取数据时，检测数据的不一致，进行修复。比如 Cassandra 的 Read Repair 实现，具体来说，在向 Cassandra 系统查询数据的时候，如果检测到不同节点的副本数据不一致，系统就自动修复数据。&lt;/li>
&lt;li>写时修复 : 在写入数据，检测数据的不一致时，进行修复。比如 Cassandra 的 Hinted Handoff 实现。具体来说，Cassandra 集群的节点之间远程写数据的时候，如果写失败 就将数据缓存下来，然后定时重传，修复数据的不一致性。&lt;/li>
&lt;li>异步修复 : 这个是最常用的方式，通过定时对账检测副本数据的一致性，并修复。&lt;/li>
&lt;/ul>
&lt;h2 id="分布式算法">分布式算法&lt;/h2>
&lt;p>Paxos算法&lt;/p>
&lt;p>Raft算法&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://javaguide.cn/distributed-system/protocol/raft-algorithm.html#_2-3-%E6%97%A5%E5%BF%97" target="_blank" rel="noopener">https://javaguide.cn/distributed-system/protocol/raft-algorithm.html#_2-3-%E6%97%A5%E5%BF%97&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="分布式id">分布式ID&lt;/h2>
&lt;p>一个最基本的分布式 ID 需要满足下面这些要求：&lt;/p>
&lt;ul>
&lt;li>全局唯一：ID 的全局唯一性肯定是首先要满足的！&lt;/li>
&lt;li>高性能：分布式 ID 的生成速度要快，对本地资源消耗要小。&lt;/li>
&lt;li>高可用：生成分布式 ID 的服务要保证可用性无限接近于 100%。&lt;/li>
&lt;li>方便易用：拿来即用，使用方便，快速接入！&lt;/li>
&lt;/ul>
&lt;h3 id="解决方案">解决方案&lt;/h3>
&lt;h4 id="数据库主键自增">数据库主键自增&lt;/h4>
&lt;p>基于数据库的号段模式来生成分布式 ID。&lt;/p>
&lt;p>NoSQL 方案使用 Redis 多一些。我们通过 Redis 的 incr 命令即可实现对 id 原子顺序递增&lt;/p>
&lt;h4 id="uuid">UUID&lt;/h4>
&lt;p>UUID 是 Universally Unique Identifier（通用唯一标识符） 的缩写。UUID 包含 32 个 16 进制数字（8-4-4-4-12）。JDK 就提供了现成的生成 UUID&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">//输出示例：cb4a9ede-fa5e-4585-b9bb-d60bce986eaa&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="n">UUID&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="na">randomUUID&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="开源框架-雪花算法号段模式">开源框架 雪花算法/号段模式&lt;/h4>
&lt;ul>
&lt;li>雪花算法&lt;/li>
&lt;/ul>
&lt;p>雪花算法是 Twitter 开源的分布式 ID 生成算法，其核心思想是：使用一个 64 位的 long 型的数字作为全局唯一 ID。在雪花算法中，64 位 long 型的数字中，其中 1 位是不用的，然后用其中的 41 位作为毫秒数，用 10 位作为工作机器 id，12 位作为序列号。&lt;/p>
&lt;ul>
&lt;li>号段模式&lt;/li>
&lt;/ul>
&lt;p>号段模式是数据库号段模式的一种变种，号段模式的核心思想是：每次从数据库中取一段 id，然后在内存中递增生成 id，当这一段 id 用完了之后，再去数据库中取一段 id。&lt;/p>
&lt;h2 id="分布式锁">分布式锁&lt;/h2>
&lt;p>如何才能实现共享资源的互斥访问呢？ 锁是一个比较通用的解决方案，更准确点来说是悲观锁。&lt;/p>
&lt;p>一个最基本的分布式锁需要满足：&lt;/p>
&lt;p>互斥：任意一个时刻，锁只能被一个线程持有。
高可用：锁服务是高可用的，当一个锁服务出现问题，能够自动切换到另外一个锁服务。并且，即使客户端的释放锁的代码逻辑出现问题，锁最终一定还是会被释放，不会影响其他线程对共享资源的访问。这一般是通过超时机制实现的。
可重入：一个节点获取了锁之后，还可以再次获取锁。
除了上面这三个基本条件之外，一个好的分布式锁还需要满足下面这些条件：&lt;/p>
&lt;p>高性能：获取和释放锁的操作应该快速完成，并且不应该对整个系统的性能造成过大影响。
非阻塞：如果获取不到锁，不能无限期等待，避免对系统正常运行造成影响。&lt;/p>
&lt;h3 id="实现方式">实现方式&lt;/h3>
&lt;p>常见分布式锁实现方案如下：&lt;/p>
&lt;p>基于关系型数据库比如 MySQL 实现分布式锁。
基于分布式协调服务 ZooKeeper 实现分布式锁。
基于分布式键值存储系统比如 Redis 、Etcd 实现分布式锁。
关系型数据库的方式一般是通过唯一索引或者排他锁实现。不过，一般不会使用这种方式，问题太多比如性能太差、不具备锁失效机制。&lt;/p>
&lt;p>基于 ZooKeeper 或者 Redis 实现分布式锁这两种实现方式要用的更多一些，我专门写了一篇文章来详细介绍这两种方案：分布式锁常见实现方案总结。&lt;/p>
&lt;h2 id="分布式事务">分布式事务&lt;/h2>
&lt;p>两阶段提交是一种常用的分布式事务处理协议,它分为以下两个阶段:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>准备阶段(Phase 1):&lt;/p>
&lt;ul>
&lt;li>协调者(Coordinator)询问参与者(Participant)是否准备好提交事务。&lt;/li>
&lt;li>参与者检查自己是否准备好提交,并反馈给协调者。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>提交阶段(Phase 2):&lt;/p>
&lt;ul>
&lt;li>如果所有参与者都准备好了,协调者会发出提交命令。&lt;/li>
&lt;li>参与者执行提交操作,并向协调者发送提交完成通知。&lt;/li>
&lt;li>协调者收到所有参与者的提交完成通知后,整个事务提交成功。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>在你描述的场景中,协调者在收到参与者提交完成通知后挂掉了,这种情况下参与者可以采取以下措施:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>重试:参与者可以尝试重复发送提交完成通知,直到协调者恢复。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>超时重试:如果长时间没有收到协调者的响应,参与者可以假设协调者已经挂掉,启动超时恢复机制。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>手动介入:如果前两种方法无法解决,可能需要人工介入,检查系统状态并决定如何进行事务恢复。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用日志:参与者可以记录事务的执行状态和结果,以便在协调者恢复后重现事务处理过程。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>总之,两阶段提交协议提供了一种可靠的分布式事务处理机制,但在某些极端情况下,如协调者故障,参与者需要采取一定的措施来保证事务的一致性和完整性。&lt;/p>
&lt;p>2PC 存在的问题：
同步阻塞 ：事务参与者会在正式提交事务之前会一直占用相关的资源。比如用户小明转账给小红，那其他事务也要操作用户小明或小红的话，就会阻塞。
数据不一致 ：由于网络问题或者TM宕机都有可能会造成数据不一致的情况。比如在第2阶段（提交阶段），部分网络出现问题导致部分参与者收不到 Commit/Rollback 消息的话，就会导致数据不一致。
单点问题 ： TM在其中也是一个很重要的角色，如果TM在准备(Prepare)阶段完成之后挂掉的话，事务参与者就会一直卡在提交(Commit)阶段。&lt;/p>
&lt;h3 id="三阶段提交">三阶段提交&lt;/h3>
&lt;p>准备阶段&lt;/p>
&lt;ul>
&lt;li>协调者向所有参与者发送事务内容，询问是否可以执行事务。&lt;/li>
&lt;/ul>
&lt;p>CanCommit 阶段&lt;/p>
&lt;ul>
&lt;li>参与者收到协调者的 CanCommit 消息后，会执行事务，然后向协调者发送 Yes 消息。&lt;/li>
&lt;li>如果参与者执行事务失败，会向协调者发送 No 消息。&lt;/li>
&lt;/ul>
&lt;p>预提交阶段&lt;/p>
&lt;ul>
&lt;li>协调者收到所有参与者的 Yes 消息后，会向所有参与者发送预提交消息。&lt;/li>
&lt;li>参与者收到预提交消息后，会执行事务，并向协调者发送 Ack 消息。&lt;/li>
&lt;/ul>
&lt;p>提交阶段&lt;/p>
&lt;ul>
&lt;li>协调者收到所有参与者的 Ack 消息后，会向所有参与者发送 Commit 消息。&lt;/li>
&lt;li>参与者收到 Commit 消息后，会提交事务。&lt;/li>
&lt;/ul>
&lt;p>分布式事务的中间件Seata&lt;/p>
&lt;h2 id="todo-分布式缓存">TODO: 分布式缓存&lt;/h2>
&lt;h3 id="一致性哈希算法">一致性哈希算法&lt;/h3>
&lt;h3 id="redis使用的哈希槽">Redis使用的哈希槽&lt;/h3></description></item><item><title/><link>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%AD%98%E5%82%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%AD%98%E5%82%A8/</guid><description/></item><item><title/><link>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%A1%86%E6%9E%B6hadoop/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%A1%86%E6%9E%B6hadoop/</guid><description/></item><item><title/><link>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83/</guid><description>&lt;h2 id="nacos">Nacos&lt;/h2></description></item><item><title/><link>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid><description>&lt;h1 id="消息队列">消息队列&lt;/h1>
&lt;h2 id="mq的作用">MQ的作用&lt;/h2>
&lt;h3 id="解耦">解耦&lt;/h3>
&lt;p>场景：A订单系统，B库存系统，A下单后需要减少库存。
传统做法：A调用B的接口。
问题：&lt;/p>
&lt;ul>
&lt;li>B无法访问时，A的操作将失败&lt;/li>
&lt;li>A需要知道B的存在，如果B接口需要修改时，A也需要修改&lt;/li>
&lt;/ul>
&lt;p>消息队列：A只与消息队列交互，不直接与B交互&lt;/p>
&lt;ul>
&lt;li>B的系统崩溃和更改对A没有关系&lt;/li>
&lt;/ul>
&lt;h3 id="异步">异步&lt;/h3>
&lt;p>场景：A下单后，需要B发送短信和C发送邮件&lt;/p>
&lt;p>传统做法：&lt;/p>
&lt;ul>
&lt;li>串行：A下单后，调用B发送短信，B发送成功后调用C发送邮件&lt;/li>
&lt;li>并行：A下单后，调用B发送短信，同时调用C发送邮件&lt;/li>
&lt;/ul>
&lt;p>问题：&lt;/p>
&lt;ul>
&lt;li>A的等待时间过长，且BC不是必须的业务逻辑&lt;/li>
&lt;/ul>
&lt;p>消息队列&lt;/p>
&lt;ul>
&lt;li>A下单后，发送消息到消息队列，B和C监听消息队列，收到消息后发送短信和邮件&lt;/li>
&lt;li>这样A不需要等待BC的操作，提高了响应速度&lt;/li>
&lt;/ul>
&lt;h3 id="流量削峰">流量削峰&lt;/h3>
&lt;p>场景：秒杀活动，瞬间大量请求&lt;/p>
&lt;p>传统做法：&lt;/p>
&lt;ul>
&lt;li>直接请求，导致系统崩溃&lt;/li>
&lt;li>限流，丢弃部分请求&lt;/li>
&lt;/ul>
&lt;p>消息队列&lt;/p>
&lt;ul>
&lt;li>请求先发送到消息队列，然后慢慢处理&lt;/li>
&lt;li>如果消息队列处理不过来，可以通过增加消费者来处理&lt;/li>
&lt;li>如果消息队列过长才会丢弃部分请求&lt;/li>
&lt;/ul>
&lt;h3 id="消息通信">消息通信&lt;/h3>
&lt;p>点对点通信：客户端A和客户端B都使用同一个队列，A发送消息到队列，B从队列中取出消息&lt;/p>
&lt;p>聊天室通信：客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。&lt;/p>
&lt;h3 id="日志处理">日志处理&lt;/h3>
&lt;p>使用消息队列完成日志处理&lt;/p>
&lt;ul>
&lt;li>日志采集客户端，负责日志数据采集，定时写受写入Kafka队列&lt;/li>
&lt;li>Kafka消息队列，负责日志数据的接收，存储和转发&lt;/li>
&lt;li>日志处理应用：订阅并消费kafka队列中的日志数据&lt;/li>
&lt;/ul>
&lt;h2 id="mq的问题">MQ的问题&lt;/h2>
&lt;p>保证高可用&lt;/p>
&lt;p>重复消费消息问题&lt;/p>
&lt;p>消息丢失问题&lt;/p>
&lt;p>消费的顺序性问题&lt;/p>
&lt;p>分布式事务问题&lt;/p>
&lt;p>消息堆积问题&lt;/p>
&lt;h2 id="三个消息队列的区别">三个消息队列的区别&lt;/h2>
&lt;p>RabbitMQ、Kafka和RocketMQ是三种不同特点的开源消息队列系统，各自适用于不同的场景。总结如下：&lt;/p>
&lt;ul>
&lt;li>RabbitMQ适用于需要可靠消息传递和灵活消息模型的场景，具有丰富的插件和社区支持。&lt;/li>
&lt;li>Kafka适用于高吞吐量、低延迟的实时数据处理和事件驱动架构场景，具有良好的可伸缩性和持久性。&lt;/li>
&lt;li>RocketMQ适用于高性能、高可用性的消息传递场景，具有丰富的消息过滤和分布式事务特性。&lt;/li>
&lt;/ul>
&lt;h2 id="kafka">Kafka&lt;/h2>
&lt;p>是一个分布式流式处理平台&lt;/p>
&lt;p>RocketMQ 的消息模型和 Kafka 基本是完全一样的。唯一的区别是 Kafka 中没有队列这个概念，与之对应的是 Partition（分区）。&lt;/p>
&lt;h2 id="rocketmq">RocketMQ&lt;/h2>
&lt;p>使用主题模型&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img src="img/%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97/RocketMQ%e7%9a%84%e4%b8%bb%e9%a2%98%e6%a8%a1%e5%9e%8b.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>主题中会存在多个队列&lt;/p>
&lt;p>多个队列可以提高并发能力&lt;/p>
&lt;p>每个主题中都有多个队列(分布在不同的 Broker中，如果是集群的话，Broker又分布在不同的服务器中)，集群消费模式下，一个消费者集群多台机器共同消费一个 topic 的多个队列，一个队列只会被一个消费者消费。&lt;/p>
&lt;p>一般来讲要控制 消费者组中的消费者个数和主题中队列个数相同 。&lt;/p>
&lt;p>每个消费组在每个队列上维护一个消费位置
每次消费者组消费完会返回一个成功的响应，然后队列再把维护的消费位移加一，这样就不会出现刚刚消费过的消息再一次被消费了。&lt;/p>
&lt;h3 id="rocketmq结构">RocketMQ结构&lt;/h3>
&lt;p>Broker：主要负责消息的存储、投递和查询以及服务高可用保证。&lt;/p>
&lt;ul>
&lt;li>说白了就是消息队列服务器嘛，生产者生产消息到 Broker ，消费者从 Broker 拉取消息并消费。&lt;/li>
&lt;li>一个 Topic 分布在多个 Broker上，一个 Broker 可以配置多个 Topic ，它们是多对多的关系。&lt;/li>
&lt;/ul>
&lt;p>NameServer：注册中心&lt;/p>
&lt;ul>
&lt;li>主要提供两个功能：Broker 管理 和 路由信息管理 。&lt;/li>
&lt;li>说白了就是 Broker 会将自己的信息注册到 NameServer 中，此时 NameServer 就存放了很多 Broker 的信息(Broker 的路由表)，消费者和生产者就从 NameServer 中获取路由表然后照着路由表的信息和对应的 Broker 进行通信(生产者和消费者定期会向 NameServer 去查询相关的 Broker 的信息)。&lt;/li>
&lt;/ul>
&lt;p>Producer：消息发布的角色，支持分布式集群方式部署。说白了就是生产者。&lt;/p>
&lt;p>Consumer：消息消费的角色，支持分布式集群方式部署。支持以 push 推，pull 拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制。说白了就是消费者。&lt;/p>
&lt;h3 id="消息类型">消息类型&lt;/h3>
&lt;p>普通消息&lt;/p>
&lt;p>定时消息&lt;/p>
&lt;p>顺序消息
Apache RocketMQ 保证相同消息组的消息存储在同一个队列中，如果不同业务场景的消息都集中在少量或一个消息组中，则这些消息存储压力都会集中到服务端的少量队列或一个队列中。&lt;/p>
&lt;p>事务消息&lt;/p>
&lt;h3 id="解决顺序问题">解决顺序问题&lt;/h3>
&lt;p>普通顺序模式 ，我们从上面学习知道了在 Producer 生产消息的时候会进行轮询(取决你的负载均衡策略)来向同一主题的不同消息队列发送消息。&lt;/p>
&lt;p>如果有几个消息分别是同一个订单的创建、支付、发货，在轮询的策略下这 &lt;strong>三个消息会被发送到不同队列&lt;/strong> ，因为在不同的队列此时就无法使用 RocketMQ 带来的队列有序特性来保证消息有序性了。&lt;/p>
&lt;p>解决方法: 将同一语义下的消息放入同一个队列(比如这里是同一个订单)&lt;/p>
&lt;p>队列选择算法:&lt;/p>
&lt;ul>
&lt;li>轮询&lt;/li>
&lt;li>最小投递延迟, 选择队列时优先选择消息延时小的队列，导致消息分布不均匀,按照如下设置即可&lt;/li>
&lt;/ul>
&lt;h3 id="分布式事务">分布式事务&lt;/h3>
&lt;p>RocketMQ 提供了事务消息 + 事务反查的机制来保证分布式事务的最终一致性。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img src="img/%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97/RocketMQ%e5%ae%9e%e7%8e%b0%e5%88%86%e5%b8%83%e5%bc%8f%e4%ba%8b%e5%8a%a1.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>half消息: 在事务提交之前, 对于消费者来说是不可见的消息&lt;/p>
&lt;blockquote>
&lt;p>如何做到写入消息但是对用户不可见呢？RocketMQ 事务消息的做法是：如果消息是 half 消息，将备份原消息的主题与消息消费队列，然后 改变主题 为 RMQ_SYS_TRANS_HALF_TOPIC。由于消费组未订阅该主题，故消费端无法消费 half 类型的消息
RocketMQ 会开启一个定时任务，从 Topic 为 RMQ_SYS_TRANS_HALF_TOPIC 中拉取消息进行消费，根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息。&lt;/p>
&lt;/blockquote>
&lt;h3 id="消费堆积问题">消费堆积问题&lt;/h3>
&lt;p>产生消息堆积的原因——生产者生产太快或者消费者消费太慢&lt;/p>
&lt;p>当流量到峰值的时候是因为生产者生产太快&lt;/p>
&lt;ul>
&lt;li>可以使用一些 限流降级 的方法&lt;/li>
&lt;li>可以增加多个消费者实例去水平扩展增加消费能力来匹配生产的激增。&lt;/li>
&lt;/ul>
&lt;p>如果消费者消费过慢的话&lt;/p>
&lt;ul>
&lt;li>先检查 是否是消费者出现了大量的消费错误&lt;/li>
&lt;li>打印一下日志查看是否是哪一个线程卡死，出现了锁资源不释放等等的问题。&lt;/li>
&lt;/ul>
&lt;h4 id="rocketmq的回溯消息">RocketMQ的回溯消息&lt;/h4>
&lt;p>回溯消费是指 Consumer 已经消费成功的消息，由于业务上需求需要重新消费，在RocketMQ 中， Broker 在向Consumer 投递成功消息后，消息仍然需要保留 。并且重新消费一般是按照时间维度，例如由于 Consumer 系统故障，恢复后需要重新消费 1 小时前的数据，那么 Broker 要提供一种机制，可以按照时间维度来回退消费进度。RocketMQ 支持按照时间回溯消费，时间维度精确到毫秒。&lt;/p>
&lt;h3 id="rocketmq的刷盘时机">RocketMQ的刷盘时机&lt;/h3>
&lt;p>在同步刷盘中需要等待一个刷盘成功的 ACK ，同步刷盘对 MQ 消息可靠性来说是一种不错的保障，但是 性能上会有较大影响 ，一般地适用于金融等特定业务场景。&lt;/p>
&lt;p>异步刷盘往往是开启一个线程去异步地执行刷盘操作。消息刷盘采用后台异步线程提交的方式进行， 降低了读写延迟 ，提高了 MQ 的性能和吞吐量，一般适用于如发验证码等对于消息保证要求不太高的业务场景。一般地，异步刷盘只有在 Broker 意外宕机的时候会丢失部分数据&lt;/p>
&lt;p>同步复制和异步复制&lt;/p>
&lt;ul>
&lt;li>同步复制：也叫 “同步双写”，也就是说，只有消息同步双写到主从节点上时才返回写入成功 。&lt;/li>
&lt;li>异步复制：消息写入主节点之后就直接返回写入成功 。
&lt;ul>
&lt;li>异步复制&lt;strong>不会&lt;/strong>像异步刷盘那样影响消息的可靠性&lt;/li>
&lt;li>但无法保证 严格顺序&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="rocketmq的存储机制">RocketMQ的存储机制&lt;/h3>
&lt;p>RocketMQ 消息存储架构中的三大角色——CommitLog、ConsumeQueue 和 IndexFile&lt;/p>
&lt;p>CommitLog：消息主体以及元数据的存储主体，存储 Producer 端写入的消息主体内容&lt;/p>
&lt;p>ConsumeQueue：消息消费队列，存储消息的消费队列，存储 Consumer 端消费的消息&lt;/p>
&lt;p>IndexFile：消息索引文件，存储消息的索引信息，用于快速检索消息&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img src="img/%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97/RocketMQ%e7%9a%84%e5%ad%98%e5%82%a8%e7%bb%93%e6%9e%84.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>左边的生产者发送消息会指定 Topic、QueueId 和具体消息内容，而在 Broker 中管你是哪门子消息，他直接 &lt;strong>全部顺序存储到了 CommitLog&lt;/strong>。&lt;/p>
&lt;p>根据生产者指定的 Topic 和 QueueId 将这条消息本身在 CommitLog 的偏移(offset)，消息本身大小，和 tag 的 hash 值存入对应的 ConsumeQueue 索引文件中&lt;/p>
&lt;p>消费者拉取消息进行消费的时候只需要根据 ConsumeOffset 获取下一个未被消费的消息就行了。&lt;/p>
&lt;h2 id="rabbitmq">RabbitMQ&lt;/h2>
&lt;p>AMQP，即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件同产品、不同的开发语言等条件的限制。&lt;/p>
&lt;h3 id="底层原理">底层原理&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img src="img/%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97/RabbitMQ%e5%ba%95%e5%b1%82.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;ul>
&lt;li>Producer：消息生产者，负责生产消息，然后发送给 RabbitMQ 服务器.&lt;/li>
&lt;li>Exchange：消息交换机，接收生产者发送的消息，然后将消息发送给队列。&lt;/li>
&lt;li>Queue：消息队列，存储生产者发送的消息。&lt;/li>
&lt;li>Consumer：消息消费者，从队列中获取消息，进行消费。&lt;/li>
&lt;/ul>
&lt;p>Exchange(交换器) 有 4 种类型，不同的类型对应着不同的路由策略：direct(默认)，fanout, topic, 和 headers，&lt;/p>
&lt;p>生产者将消息发给交换器的时候，一般会指定一个 RoutingKey(路由键)，用来&lt;strong>指定这个消息的路由规则&lt;/strong>，当 BindingKey 和 RoutingKey 相匹配时，消息会被路由到对应的队列中&lt;/p>
&lt;p>多个消费者可以订阅同一个队列，这时队列中的消息会被平均分摊（Round-Robin，即轮询）给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理，这样避免消息被重复消费。RabbitMQ 不支持队列层面的广播消费,如果有广播消费的需求，需要在其上进行二次开发,这样会很麻烦，不建议这样做&lt;/p>
&lt;h3 id="死信队列">死信队列&lt;/h3>
&lt;h3 id="保证消费一致性">保证消费一致性&lt;/h3>
&lt;p>只有RocketMQ支持事务消息。&lt;/p>
&lt;h3 id="保证不重复消费幂等性问题">保证不重复消费（幂等性问题）？&lt;/h3>
&lt;p>想要保证不重复消费，其实还要结合业务来思考，这里给几个思路：&lt;/p>
&lt;p>比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update一下。&lt;/p>
&lt;p>比如你是写redis，那没问题了，反正每次都是set，天然幂等性。&lt;/p>
&lt;p>比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。&lt;/p>
&lt;p>还有比如基于数据库的唯一键来保证重复数据不会重复插入多条，我们之前线上系统就有这个问题，就是拿到数据的时候，每次重启可能会有重复，因为kafka消费者还没来得及提交offset，重复数据拿到了以后我们插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据。&lt;/p>
&lt;h3 id="保证消息的顺序性">保证消息的顺序性？&lt;/h3>
&lt;p>RabbitMQ 的问题是由于不同的消息都发送到了同一个 queue 中，多个消费者都消费同一个 queue 的消息。&lt;/p>
&lt;p>拆分多个 queue(消息队列)，每个 queue(消息队列) 一个 consumer(消费者)，就是多一些 queue (消息队列)而已，确实是麻烦点；&lt;/p>
&lt;p>或者就一个 queue (消息队列)但是对应一个 consumer(消费者)，然后这个 consumer(消费者)内部用内存队列做排队，然后分发给底层不同的 worker 来处理。&lt;/p>
&lt;h3 id="实现延迟队列">实现延迟队列&lt;/h3>
&lt;p>消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。&lt;/p>
&lt;p>RabbitMQ本身没有延迟队列的实现&lt;/p>
&lt;p>RabbitMQ实现延迟队列的两种方式：&lt;/p>
&lt;ul>
&lt;li>死信交换机（Exchange）和消息的存活时间 TTL（Time To Live）。&lt;/li>
&lt;li>3.5.7 及以上的版本提供了一个插件（rabbitmq-delayed-message-exchange）来实现延迟队列功能。同时，插件依赖 Erlang/OPT 18.0 及以上。&lt;/li>
&lt;/ul>
&lt;h3 id="推拉">推拉&lt;/h3>
&lt;p>推模式：&lt;/p>
&lt;p>推模式是服务器端根据用户需要，由目的、按时将用户感兴趣的信息主动发送到用户的客户端。&lt;/p>
&lt;p>优点：&lt;/p>
&lt;p>对用户要求低，方便用户获取需要的信息；&lt;/p>
&lt;p>及时性好，服务器端及时地向客户端推送更新动态信息，吞吐量大。&lt;/p>
&lt;p>缺点：&lt;/p>
&lt;p>不能确保发送成功，推模式采用广播方式，只有服务器端和客户端在同一个频道上，推模式才有效，用户才能接收到信息；&lt;/p>
&lt;p>没有信息状态跟踪，推模式采用开环控制技术，一个信息推送后的状态，比如客户端是否接收等，无从得知；&lt;/p>
&lt;p>针对性较差。推送的信息可能并不能满足客户端的个性化需求。&lt;/p>
&lt;p>拉模式：&lt;/p>
&lt;p>拉模式是客户端主动从服务器端获取信息。&lt;/p>
&lt;p>优点：&lt;/p>
&lt;p>针对性强，能满足客户端的个性化需求；&lt;/p>
&lt;p>信息传输量较小，网络中传输的只是客户端的请求和服务器端对该请求的响应；&lt;/p>
&lt;p>服务器端的任务轻。服务器端只是被动接收查询，对客户端的查询请求做出响应。&lt;/p>
&lt;p>缺点：&lt;/p>
&lt;p>实时性较差，针对于服务器端实时更新的信息，客户端难以获取实时信息；&lt;/p>
&lt;p>对于客户端用户的要求较高，需要对服务器端具有一定的了解。&lt;/p>
&lt;h3 id="消息队列如何保证消息不丢">消息队列如何保证消息不丢&lt;/h3>
&lt;p>丢数据一般分为两种，一种是mq把消息丢了，一种就是消费时将消息丢了。下面从rabbitmq和kafka分别说一下，丢失数据的场景。&lt;/p>
&lt;p>RabbitMQ丢失消息分为如下几种情况：&lt;/p>
&lt;h4 id="生产者丢消息">生产者丢消息&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>生产者将数据发送到RabbitMQ的时候，可能在传输过程中因为网络等问题而将数据弄丢了。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>可以选择使用RabbitMQ提供是&lt;strong>事务功能&lt;/strong>，就是生产者在发送数据之前开启事务，然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会受到异常报错，这时就可以回滚事务，然后尝试重新发送。如果收到了消息，那么就可以提交事务。这种方式有明显的缺点，即RabbitMQ事务开启后，就会变为同步阻塞操作，生产者会阻塞等待是否发送成功，太耗性能会造成吞吐量的下降。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>可以开启&lt;strong>confirm模式&lt;/strong>。在生产者那里设置开启了confirm模式之后，每次写的消息都会分配一个唯一的id，然后如何写入了RabbitMQ之中，RabbitMQ会给你回传一个ack消息，告诉你这个消息发送OK了。如果RabbitMQ&lt;strong>没能处理这个消息，会回调你一个nack接口&lt;/strong>，告诉你这个消息失败了，你可以进行重试。而且你可以结合这个机制知道自己在内存里维护每个消息的id，如果超过一定时间还没接收到这个消息的回调，那么你可以进行重发。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>事务机制是同步的，你提交了一个事物之后会阻塞住，但是confirm机制是异步的，发送消息之后可以接着发送下一个消息，然后RabbitMQ会回调告知成功与否。 一般在生产者这块避免丢失，都是用confirm机制。&lt;/p>
&lt;h4 id="rabbitmq自己丢消息">RabbitMQ自己丢消息&lt;/h4>
&lt;ul>
&lt;li>如果没有开启RabbitMQ的持久化，那么RabbitMQ一旦重启数据就丢了。&lt;/li>
&lt;li>所以必须&lt;strong>开启持久化将消息持久化到磁盘&lt;/strong>，这样就算RabbitMQ挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢失。除非极其罕见的情况，RabbitMQ还没来得及持久化自己就挂了，这样可能导致一部分数据丢失。&lt;/li>
&lt;/ul>
&lt;p>设置消息持久化到磁盘，设置持久化有两个步骤：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>创建queue的时候将其设置为持久化的，这样就可以保证RabbitMQ持久化queue的元数据，但是不会持久化queue里面的数据。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>发送消息的时候讲消息的deliveryMode设置为2，这样消息就会被设为持久化方式，此时RabbitMQ就会将消息持久化到磁盘上。 必须要同时开启这两个才可以。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>而且持久化可以跟生产的confirm机制配合起来，只有消息持久化到了磁盘之后，才会通知生产者ack，这样就算是在持久化之前RabbitMQ挂了，数据丢了，生产者收不到ack回调也会进行消息重发。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="消费端丢消息">消费端丢消息&lt;/h4>
&lt;p>主要是因为消费者消费时，刚消费到还没有处理，结果消费者就挂了，这样你重启之后，RabbitMQ就认为你已经消费过了，然后就丢了数据。&lt;/p>
&lt;p>&lt;strong>使用RabbitMQ提供的ack机制&lt;/strong>，首先关闭RabbitMQ的自动ack，然后每次在确保处理完这个消息之后，在代码里手动调用ack。这样就可以避免消息还没有处理完就ack。&lt;/p></description></item><item><title/><link>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E7%BD%91%E5%85%B3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E7%BD%91%E5%85%B3/</guid><description>&lt;h1 id="api网关">API网关&lt;/h1>
&lt;p>网关主要做了两件事情：请求转发 + 请求过滤。&lt;/p>
&lt;p>绝大部分网关可以提供下面这些功能（有一些功能需要借助其他框架或者中间件）：&lt;/p>
&lt;p>请求转发：将请求转发到目标微服务。
负载均衡：根据各个微服务实例的负载情况或者具体的负载均衡策略配置对请求实现动态的负载均衡。
安全认证：对用户请求进行身份验证并仅允许可信客户端访问 API，并且还能够使用类似 RBAC 等方式来授权。
参数校验：支持参数映射与校验逻辑。
日志记录：记录所有请求的行为日志供后续使用。
监控告警：从业务指标、机器指标、JVM 指标等方面进行监控并提供配套的告警机制。
流量控制：对请求的流量进行控制，也就是限制某一时刻内的请求数。
熔断降级：实时监控请求的统计信息，达到配置的失败阈值后，自动熔断，返回默认值。
响应缓存：当用户请求获取的是一些静态的或更新不频繁的数据时，一段时间内多次请求获取到的数据很可能是一样的。对于这种情况可以将响应缓存起来。这样用户请求可以直接在网关层得到响应数据，无需再去访问业务服务，减轻业务服务的负担。
响应聚合：某些情况下用户请求要获取的响应内容可能会来自于多个业务服务。网关作为业务服务的调用方，可以把多个服务的响应整合起来，再一并返回给用户。
灰度发布：将请求动态分流到不同的服务版本（最基本的一种灰度发布）。
异常处理：对于业务服务返回的异常响应，可以在网关层在返回给用户之前做转换处理。这样可以把一些业务侧返回的异常细节隐藏，转换成用户友好的错误提示返回。
API 文档： 如果计划将 API 暴露给组织以外的开发人员，那么必须考虑使用 API 文档，例如 Swagger 或 OpenAPI。
协议转换：通过协议转换整合后台基于 REST、AMQP、Dubbo 等不同风格和实现技术的微服务，面向 Web Mobile、开放平台等特定客户端提供统一服务。
证书管理：将 SSL 证书部署到 API 网关，由一个统一的入口管理接口，降低了证书更换时的复杂度。&lt;/p></description></item><item><title/><link>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E8%AE%A1%E7%AE%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E8%AE%A1%E7%AE%97/</guid><description>&lt;h1 id="分布式计算">分布式计算&lt;/h1>
&lt;ul>
&lt;li>MapReduce&lt;/li>
&lt;li>Spark&lt;/li>
&lt;li>Flink&lt;/li>
&lt;/ul>
&lt;h2 id="mapreduce">MapReduce&lt;/h2>
&lt;p>MapReduce是一种编程模型，用于处理大规模数据集的并行计算。它由两个主要阶段组成：Map阶段和Reduce阶段。在Map阶段，输入数据集被划分为多个独立的数据块，然后由Map函数处理。在Reduce阶段，Map阶段的输出被分组，然后由Reduce函数处理。&lt;/p>
&lt;p>相关论文：&lt;a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf" target="_blank" rel="noopener">MapReduce: Simplified Data Processing on Large Clusters&lt;/a>&lt;/p></description></item><item><title/><link>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E9%80%9A%E4%BF%A1rpc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ysyyhhh.github.io/docs/knowledge/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8F/%E9%80%9A%E4%BF%A1rpc/</guid><description>&lt;h1 id="rpc">RPC&lt;/h1>
&lt;p>RPC（Remote Procedure Call） 即远程过程调用，通过名字我们就能看出 RPC 关注的是远程调用而非本地调用。&lt;/p>
&lt;p>整个 RPC 的 核心功能看作是下面 👇 5 个部分实现的：&lt;/p>
&lt;p>客户端（服务消费端）：调用远程方法的一端。
客户端 Stub（桩）：这其实就是一代理类。代理类主要做的事情很简单，就是把你调用方法、类、方法参数等信息传递到服务端。
网络传输：网络传输就是你要把你调用的方法的信息比如说参数啊这些东西传输到服务端，然后服务端执行完之后再把返回结果通过网络传输给你传输回来。网络传输的实现方式有很多种比如最基本的 Socket 或者性能以及封装更加优秀的 Netty（推荐）。
服务端 Stub（桩）：这个桩就不是代理类了。我觉得理解为桩实际不太好，大家注意一下就好。这里的服务端 Stub 实际指的就是接收到客户端执行方法的请求后，去执行对应的方法然后返回结果给客户端的类。
服务端（服务提供端）：提供远程方法的一端。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="flex justify-center ">
&lt;div class="w-100" >&lt;img src="img/%e9%80%9a%e4%bf%a1%28RPC%29/RPC%e5%8e%9f%e7%90%86%e5%9b%be.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>&lt;a href="https://xie.infoq.cn/article/eda414b9ee0f2b11437b546d6" target="_blank" rel="noopener">https://xie.infoq.cn/article/eda414b9ee0f2b11437b546d6&lt;/a>&lt;/p></description></item></channel></rss>